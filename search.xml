<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[深入理解Redis-实战篇]]></title>
    <url>%2F2019%2F12%2F01%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-%E5%AE%9E%E6%88%98%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Redis客户端客户端通信原理客户端和服务器通过 TCP 连接来进行数据交互， 服务器默认的端口号为 6379 。 客户端和服务器发送的命令或数据一律以 \r\n (CRLF 回车+换行)结尾。如果使用 wireshark 对 jedis 抓包:环境:Jedis 连接到虚拟机 202，运行 main，对 VMnet8 抓包。过滤条件:ip.dst==192.168.8.202 and tcp.port in {6379}对 set test 111 抓包，可以看到实际发出的数据包是: 1*3\r\n$3\r\nSET\r\n$4\r\ntest\r\n$3\r\n111\r\n 对 get test 抓包，可以看到实际发出的数据包是: 1*2\r\n$3\r\nGET\r\n$4\r\ntest\r\n 客户端跟 Redis 之间 使用一种特殊的编码格式(在 AOF 文件里面我们看到了)，叫 做 Redis Serialization Protocol (Redis 序列化协议)。特点:容易实现、解析快、可读 性强。客户端发给服务端的消息需要经过编码，服务端收到之后会按约定进行解码，反之亦然。基于此，我们可以自己实现一个 Redis 客户端。 建立 Socket 连接 OutputStream 写入数据(发送到服务端) InputStream 读取数据(从服务端接口) 基于这种协议，我们可以用 Java 实现所有的 Redis 操作命令。当然，我们不需要这 么做，因为已经有很多比较成熟的 Java 客户端，实现了完整的功能和高级特性，并且提供了良好的性能。官网展示的客户端官网推荐的 Java 客户端有 3 个 Jedis，Redisson 和 Luttuce。 客户端 描述 Jedis A blazingly small and sane redis java client lettuce Advanced Redis client for thread-safe sync, async, and reactive usage. Supports Cluster, Sentinel, Pipelining, and codecs. Redisson distributed and scalable Java data structures on top of Redis server Spring 连接 Redis 用的是什么?RedisConnectionFactory 接口支持多种实现，例如 : JedisConnectionFactory 、 JredisConnectionFactory 、LettuceConnectionFactory、SrpConnectionFactory。 Jedishttps://github.com/xetorthio/jedis 特点Jedis 是我们最熟悉和最常用的客户端。轻量，简洁，便于集成和改造。Jedis 多个线程使用一个连接的时候线程不安全。可以使用连接池，为每个请求创建不同的连接，基于 Apache common pool 实现。跟数据库一样，可以设置最大连接数等参数。Jedis 中有多种连接池的子类（JedisPool、JedisSentinelPool、ShardedJedisPool）。Jedis 有4种工作模式:单节点、分片、哨兵、集群。Jedis 有3种请求模式:Client、Pipeline、事务。Client 模式就是客户端发送一个命令，阻塞等待服务端执行，然后读取 返回结果。Pipeline 模式是一次性发送多个命令，最后一次取回所有的返回结果，这种模式通过减少网络的往返时间和 io 读写次数，大幅度提高通信性能。第三种是事务模式。Transaction 模式即开启 Redis 的事务管理，事务模式开启后，所有的命令(除了 exec，discard，multi 和 watch)到达服务端以后不会立即执行，会进入一个等待队列。 Sentinel 获取连接原理问题:Jedis 连接 Sentinel 的时候，我们配置的是全部哨兵的地址。Sentinel 是如 何返回可用的 master 地址的呢?在构造方法中: 1pool = new JedisSentinelPool(masterName, sentinels); 调用了: 1HostAndPort master = initSentinels(sentinels, masterName); 查看: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859private HostAndPort initSentinels(Set&lt;String&gt; sentinels, final String masterName) &#123; HostAndPort master = null; boolean sentinelAvailable = false; log.info(&quot;Trying to find master from available Sentinels...&quot;); // 有多个 sentinels,遍历这些个 sentinels for (String sentinel : sentinels) &#123; // host:port 表示的 sentinel 地址转化为一个 HostAndPort 对象。 final HostAndPort hap = HostAndPort.parseString(sentinel); log.fine(&quot;Connecting to Sentinel &quot; + hap); Jedis jedis = null; try &#123; // 连接到 sentinel jedis = new Jedis(hap.getHost(), hap.getPort()); // 根据 masterName 得到 master 的地址，返回一个 list，host= list[0], port =// list[1] List&lt;String&gt; masterAddr = jedis.sentinelGetMasterAddrByName(masterName); sentinelAvailable = true; if (masterAddr == null || masterAddr.size() != 2) &#123; log.warning(&quot;Can not get master addr, master name: &quot; + masterName + &quot;. Sentinel: &quot; + hap + &quot;.&quot;); continue; &#125; // 如果在任何一个 sentinel 中找到了 master，不再遍历 sentinels master = toHostAndPort(masterAddr); log.fine(&quot;Found Redis master at &quot; + master); break; &#125; catch (JedisException e) &#123; // resolves #1036, it should handle JedisException there&apos;s another chance // of raising JedisDataException log.warning(&quot;Cannot get master address from sentinel running @ &quot; + hap + &quot;. Reason: &quot; + e + &quot;. Trying next one.&quot;); &#125; finally &#123; if (jedis != null) &#123; jedis.close(); &#125; &#125; &#125; // 到这里，如果 master 为 null，则说明有两种情况，一种是所有的 sentinels 节点都 down 掉了，一种是 master 节点没有被存活的 sentinels 监控到 if (master == null) &#123; if (sentinelAvailable) &#123; // can connect to sentinel, but master name seems to not // monitored throw new JedisException(&quot;Can connect to sentinel, but &quot; + masterName + &quot; seems to be not monitored...&quot;); &#125; else &#123; throw new JedisConnectionException(&quot;All sentinels down, cannot determine where is &quot; + masterName + &quot; master is running...&quot;); &#125; &#125; // 如果走到这里，说明找到了 master 的地址 log.info(&quot;Redis master running at &quot; + master + &quot;, starting Sentinel listeners...&quot;); // 启动对每个 sentinels 的监听为每个 sentinel 都启动了一个监听者 MasterListener。MasterListener 本身是一个线程，它会去订阅 sentinel 上关于 master 节点地址改变的消息。 for (String sentinel : sentinels) &#123; final HostAndPort hap = HostAndPort.parseString(sentinel); MasterListener masterListener = new MasterListener(masterName, hap.getHost(), hap.getPort()); // whether MasterListener threads are alive or not, process can be stopped masterListener.setDaemon(true); masterListeners.add(masterListener); masterListener.start(); &#125; return master;&#125; Cluster 获取连接原理问题:使用 Jedis 连接 Cluster 的时候，我们只需要连接到任意一个或者多个 redis group 中的实例地址，那我们是怎么获取到需要操作的 Redis Master 实例的?关键问题:在于如何存储 slot 和 Redis 连接池的关系。 程序启动初始化集群环境，读取配置文件中的节点配置，无论是主从，无论多少个，只拿第一个，获取 redis 连接实例(后面有个 break)。 12345678910111213141516171819// redis.clients.jedis.JedisClusterConnectionHandler#initializeSlotsCacheprivate void initializeSlotsCache(Set&lt;HostAndPort&gt; startNodes, GenericObjectPoolConfig poolConfig, String password) &#123; for (HostAndPort hostAndPort : startNodes) &#123; // 获取一个 Jedis 实例 Jedis jedis = new Jedis(hostAndPort.getHost(), hostAndPort.getPort()); if (password != null) &#123; jedis.auth(password); &#125; try &#123; // 获取 Redis 节点和 Slot 虚拟槽 cache.discoverClusterNodesAndSlots(jedis); // 直接跳出循环 break; &#125; catch (JedisConnectionException e) &#123; // try next nodes &#125; finally &#123; if (jedis != null) &#123; jedis.close(); &#125; &#125; &#125;&#125; 用获取的 redis 连接实例执行 clusterSlots ()方法，实际执行 redis 服务端 cluster slots 命令，获取虚拟槽信息。该集合的基本信息为[long, long, List, List], 第一，二个元素是该节点负责槽点的起 始位置，第三个元素是主节点信息，第四个元素为主节点对应的从节点信息。该 list 的 基本信息为[string,int,string],第一个为 host 信息，第二个为 port 信息，第三个为唯一 id。 获取有关节点的槽点信息后，调用 getAssignedSlotArray(slotinfo)来获取所有的槽点值。 再获取主节点的地址信息，调用 generateHostAndPort(hostInfo)方法，生成一个 ostAndPort 对象。 再根据节点地址信息来设置节点对应的 JedisPool，即设置 Map&lt;String,JedisPool&gt; nodes 的值。接下来判断若此时节点信息为主节点信息时，则调用 assignSlotsToNodes 方法，设置每个槽点值对应的连接池，即设置 Map&lt;Integer, JedisPool&gt; slots 的值。 12345678910111213141516171819202122232425262728293031323334353637383940// redis.clients.jedis.JedisClusterInfoCache#discoverClusterNodesAndSlotspublic void discoverClusterNodesAndSlots(Jedis jedis) &#123; w.lock();​ try &#123; reset(); // 获取节点集合 List&lt;Object&gt; slots = jedis.clusterSlots(); // 遍历3个master节点 for (Object slotInfoObj : slots) &#123; // slotInfo 槽开始，槽结束，主，从 // &#123;[0,5460,7291,7294],[5461,10922,7292,7295],[10923,16383,7293,7296]&#125; List&lt;Object&gt; slotInfo = (List&lt;Object&gt;) slotInfoObj; // 如果&lt;=2，代表没有分配 slot if (slotInfo.size() &lt;= MASTER_NODE_INDEX) &#123; continue; &#125; // 获取分配到当前 master 节点的数据槽，例如 7291 节点的&#123;0,1,2,3......5460&#125; List&lt;Integer&gt; slotNums = getAssignedSlotArray(slotInfo); ​ // hostInfos int size = slotInfo.size();// size 是 4，槽最小最大，主，从 // 第 3 位和第 4 位是主从端口的信息 for (int i = MASTER_NODE_INDEX; i &lt; size; i++) &#123; List&lt;Object&gt; hostInfos = (List&lt;Object&gt;) slotInfo.get(i); if (hostInfos.size() &lt;= 0) &#123; continue; &#125; // 根据 IP 端口生成 HostAndPort 实例 HostAndPort targetNode = generateHostAndPort(hostInfos); // 据HostAndPort解析出ip:port的key值，再根据key从缓存中查询对应的jedisPool实例。如果没有jedisPool实例，就创建 JedisPool 实例，最后放入缓存中。nodeKey 和 nodePool 的关系 setupNodeIfNotExist(targetNode); // 把 slot 和 jedisPool 缓存起来(16384 个)，key 是 slot 下标，value 是连接池 if (i == MASTER_NODE_INDEX) &#123; assignSlotsToNode(slotNums, targetNode); &#125; &#125; &#125; &#125; finally &#123; w.unlock(); &#125;&#125; 从集群环境存取值: 把 key 作为参数，执行 CRC16 算法，获取 key 对应的 slot 值。 通过该 slot 值，去 slots 的 map 集合中获取 jedisPool 实例。 通过 jedisPool 实例获取 jedis 实例，最终完成 redis 数据存取工作。 pipeline通过 Lua 脚本 set 2 万个 key 用了好几分钟，这个速度太慢了，完全没有把 Redis 10 万的 QPS 利用起来。但是单个命令的执行到底慢在哪里? 慢在哪里?Redis 使用的是客户端/服务器(C/S)模型和请求/响应协议的 TCP 服务器。这意味着通常情况下一个请求会遵循以下步骤: 客户端向服务端发送一个查询请求，并监听 Socket 返回，通常是以阻塞模式，等待服务端响应。 服务端处理命令，并将结果返回给客户端。 Redis 客户端与 Redis 服务器之间使用 TCP 协议进行连接，一个客户端可以通过一个 socket 连接发起多个请求命令。每个请求命令发出后 client 通常会阻塞并等待 redis 服务器处理，redis 处理完请求命令后会将结果通过响应报文返回给 client，因此当执行多条命令的时候都需要等待上一条命令执行完毕才能执行。Redis 本身提供了一些批量操作命令，比如 mget，mset，可以减少通信的时间，但是大部分命令是不支持 multi 操作的，例如 hash 就没有。由于通信会有网络延迟，假如 client 和 server 之间的包传输时间需要 10 毫秒，一次交互就是 20 毫秒(RTT:Round Trip Time)。这样的话，client 1 秒钟也只能也只能发送 50 个命令。这显然没有充分利用 Redis 的处理能力。另外一个，Redis 服务端执行 I/O 的次数过多。 Pipeline 管道https://redis.io/topics/pipelining那我们能不能像数据库的 batch 操作一样，把一组命令组装在一起发送给 Redis 服务端执行，然后一次性获得返回结果呢?这个就是 Pipeline 的作用。Pipeline 通过一个队列把所有的命令缓存起来，然后把多个命令在一次连接中发送给服务器。要实现 Pipeline，既要服务端的支持，也要客户端的支持。对于服务端来说，需要能够处理客户端通过一个 TCP 连接发来的多个命令，并且逐个地执行命令一起返回 。对于客户端来说，要把多个命令缓存起来，达到一定的条件就发送出去，最后才处理 Redis 的应答(这里也要注意对客户端内存的消耗)。jedis-pipeline 的 client-buffer 限制:8192bytes，客户端堆积的命令超过 8192bytes 时，会发送给服务端。源码:redis.clients.util.RedisOutputStream.java 123public RedisOutputStream(final OutputStream out) &#123; this(out, 8192);&#125; pipeline 对于命令条数没有限制，但是命令可能会受限于 TCP 包大小。如果 Jedis 发送了一组命令，而发送请求还没有结束，Redis 响应的结果会放在接收缓冲区。如果接收缓冲区满了，jedis 会通知 redis win=0，此时 redis 不会再发送结果给 jedis 端，转而把响应结果保存在 Redis 服务端的输出缓冲区中。输出缓冲区的配置:redis.conf 12# client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;client-output-buffer-limit normal 0 0 0 client-output-buffer-limit replica 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 配置 作用 class 客户端类型，分为三种。a)normal:普通客户端;b)slave:slave 客户端，用于复制;c) pubsub:发布订阅客户端 hard limit 如果客户端使用的输出缓冲区大于，客户端会被立即关闭，0 代表不限制 soft limit soft seconds 如果客户端使用的输出缓冲区超过了并且持续了秒，客户端会被立即 关闭 每个客户端使用的输出缓冲区的大小可以用 client list 命令查看 12redis&gt; client listid=5 addr=192.168.8.1:10859 fd=8 name= age=5 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=5 qbuf-free=32763 obl=16380 oll=227 omem=4654408 events=rw cmd=set obl : 输出缓冲区的长度(字节为单位， 0 表示没有分配输出缓冲区) oll : 输出列表包含的对象数量(当输出缓冲区没有剩余空间时，命令回复会以字符串对象的形式被入队到这个 队列里) omem : 输出缓冲区和输出列表占用的内存总量使用场景如果某些操作需要马上得到 Redis 操作是否成功的结果，这种场景就不适合。有些场景，例如批量写入数据，对于结果的实时性和成功性要求不高，就可以用 Pipeline。 Jedis 实现分布式锁原文地址:https://redis.io/topics/distlock中文地址:http://redis.cn/topics/distlock.html分布式锁的基本特性或者要求: 互斥性:只有一个客户端能够持有锁。 不会产生死锁:即使持有锁的客户端崩溃，也能保证后续其他客户端可以获取锁。 只有持有这把锁的客户端才能解锁。 12345678public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; // set 支持多个参数 NX(not exist) XX(exist) EX(seconds) PX(million seconds) String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); if (LOCK_SUCCESS.equals(result)) &#123; return true; &#125; return false;&#125; 参数解读: lockKey 是 Redis key 的名称，也就是谁添加成功这个 key 代表谁获取锁成功。 requestId 是客户端的 ID(设置成 value)，如果我们要保证只有加锁的客户端才能释放锁，就必须获得客户端的 ID(保证第 3 点)。 SET_IF_NOT_EXIST 是我们的命令里面加上 NX(保证第 1 点)。 SET_WITH_EXPIRE_TIME，PX 代表以毫秒为单位设置 key 的过期时间(保证第 2 点)。expireTime 是自动释放锁的时间，比如 5000 代表 5 秒。 释放锁，直接删除 key 来释放锁可以吗?就像这样: 123public static void wrongReleaseLock1(Jedis jedis, String lockKey) &#123; jedis.del(lockKey);&#125; 没有对客户端 requestId 进行判断，可能会释放其他客户端持有的锁。 先判断后删除呢? 1234567public static void wrongReleaseLock2(Jedis jedis, String lockKey, String requestId) &#123; // 判断加锁与解锁是不是同一个客户端 if (requestId.equals(jedis.get(lockKey))) &#123; // 若在此时，这把锁突然不是这个客户端的，则会误解锁 jedis.del(lockKey); &#125;&#125; 如果在释放锁的时候，这把锁已经不属于这个客户端(例如已经过期，并且被别的客户端获取锁成功了)，那就会出现释放了其他客户端的锁的情况。所以我们把判断客户端是否相等和删除 key 的操作放在 Lua 脚本里面执行。 12345678public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) &#123; String script = &quot;if redis.call(&apos;get&apos;, KEYS[1]) == ARGV[1] then return redis.call(&apos;del&apos;, KEYS[1]) else return 0 end&quot;; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); if (RELEASE_SUCCESS.equals(result)) &#123; return true; &#125; return false;&#125; 这个是 Jedis 里面分布式锁的实现。 Luttecehttps://lettuce.io/ 特点与 Jedis 相比，Lettuce 则完全克服了其线程不安全的缺点:Lettuce 是一个可伸缩的线程安全的 Redis 客户端，支持同步、异步和响应式模式(Reactive)。多个线程可以共享一个连接实例，而不必担心多线程并发问题。它基于 Netty 框架构建，支持 Redis 的高级功能，如 Pipeline、发布订阅/事务、 Sentinel、集群、支持连接池。Lettuce 是 Spring Boot 2.x 默认的客户端，替换了 Jedis。集成之后我们不需要单独使用它，直接调用 Spring 的 RedisTemplate 操作，连接和创建和关闭也不需要我们操心。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; Redissonhttps://redisson.org/https://github.com/redisson/redisson/wiki/目录 本质Redisson 是一个在 Redis 的基础上实现的 Java 驻内存数据网格(In-Memory Data Grid)，提供了分布式和可扩展的 Java 数据结构。 特点 基于 Netty 实现，采用非阻塞 IO，性能高 支持异步请求 支持连接池、pipeline、LUA Scripting、Redis Sentinel、Redis Cluster 不支持事务，官方建议以 LUA Scripting 代替事务 主从、哨兵、集群都支持。Spring 也可以配置和注入 RedissonClient。 实现分布式锁在 Redisson 里面提供了更加简单的分布式锁的实现。加锁： 123456789public static void main(String[] args) throws InterruptedException &#123; RLock rLock = redissonClient.getLock(&quot;updateAccount&quot;); // 最多等待 100 秒、上锁 10s 以后自动解锁 if (rLock.tryLock(100, 10, TimeUnit.SECONDS)) &#123; System.out.println(&quot;获取锁成功&quot;); &#125; // do something rLock.unlock();&#125; 在获得 RLock 之后，只需要一个 tryLock 方法，里面有 3 个参数: watiTime:获取锁的最大等待时间，超过这个时间不再尝试获取锁 leaseTime:如果没有调用 unlock，超过了这个时间会自动释放锁 TimeUnit:释放时间的单位 Redisson 的分布式锁是怎么实现的呢?在加锁的时候，在 Redis 写入了一个 HASH，key 是锁名称，field 是线程名称，value 是 1(表示锁的重入次数)。源码路径：tryLock()——tryAcquire()——tryAcquireAsync()——tryLockInnerAsync()最终也是调用了一段 Lua 脚本。 123456789101112131415161718192021// KEYS[1] 锁名称 updateAccount // ARGV[1] key 过期时间 10000ms // ARGV[2] 线程名称// 锁名称不存在if (redis.call(&apos;exists&apos;, KEYS[1]) == 0) then // 创建一个 hash，key=锁名称，field=线程名，value=1 redis.call(&apos;hset&apos;, KEYS[1], ARGV[2], 1); // 设置 hash 的过期时间 redis.call(&apos;pexpire&apos;, KEYS[1], ARGV[1]); return nil;end;// 锁名称存在，判断是否当前线程持有的锁if (redis.call(&apos;hexists&apos;, KEYS[1], ARGV[2]) == 1) then // 如果是，value+1，代表重入次数+1 redis.call(&apos;hincrby&apos;, KEYS[1], ARGV[2], 1); // 重新获得锁，需要重新设置 Key 的过期时间 redis.call(&apos;pexpire&apos;, KEYS[1], ARGV[1]); return nil;end;// 锁存在，但是不是当前线程持有，返回过期时间(毫秒) return redis.call(&apos;pttl&apos;, KEYS[1]); 释放锁，源码:unlock——unlockInnerAsync 1234567891011121314151617181920212223242526272829303132// KEYS[1] 锁的名称 updateAccount// KEYS[2] 频道名称 redisson_lock__channel:&#123;updateAccount&#125; // ARGV[1] 释放锁的消息 0// ARGV[2] 锁释放时间 10000// ARGV[3] 线程名称// 锁不存在(过期或者已经释放了)if (redis.call(&apos;exists&apos;, KEYS[1]) == 0) then // 发布锁已经释放的消息 redis.call(&apos;publish&apos;, KEYS[2], ARGV[1]); return 1;end;// 锁存在，但是不是当前线程加的锁if (redis.call(&apos;hexists&apos;, KEYS[1], ARGV[3]) == 0) then return nil; end;// 锁存在，是当前线程加的锁// 重入次数-1local counter = redis.call(&apos;hincrby&apos;, KEYS[1], ARGV[3], -1);// -1 后大于 0，说明这个线程持有这把锁还有其他的任务需要执行 if (counter &gt; 0) then // 重新设置锁的过期时间 redis.call(&apos;pexpire&apos;, KEYS[1], ARGV[2]); return 0;else // -1 之后等于 0，现在可以删除锁了 redis.call(&apos;del&apos;, KEYS[1]); // 删除之后发布释放锁的消息 redis.call(&apos;publish&apos;, KEYS[2], ARGV[1]); return 1;end;// 其他情况返回 nil return nil; 这个是 Redisson 里面分布式锁的实现，我们在调用的时候非常简单。Redisson 跟 Jedis 定位不同，它不是一个单纯的 Redis 客户端，而是基于 Redis 实现的分布式的服务，如果有需要用到一些分布式的数据结构，比如我们还可以基于 Redisson 的分布式队列实现分布式事务，就可以引入 Redisson 的依赖实现。 数据一致性缓存使用场景针对读多写少的高并发场景，我们可以使用缓存来提升查询速度。当我们使用 Redis 作为缓存的时候，一般流程是这样的:1、如果数据在 Redis 存在，应用就可以直接从 Redis 拿到数据，不用访问数据库。2、如果 Redis 里面没有，先到数据库查询，然后写入到 Redis，再返回给应用。 一致性问题的定义因为这些数据是很少修改的，所以在绝大部分的情况下可以命中缓存。但是，一旦 被缓存的数据发生变化的时候，我们既要操作数据库的数据，也要操作 Redis 的数据， 所以问题来了。现在我们有两种选择: 先操作 Redis 的数据再操作数据库的数据 先操作数据库的数据再操作 Redis 的数据 首先需要明确的是，不管选择哪一种方案， 我们肯定是希望两个操作要么都成功，要么都一个都不成功。不然就会发生 Redis 跟数据库的数据不一致的问题。但是，Redis 的数据和数据库的数据是不可能通过事务达到统一的，我们只能根据相应的场景和所需要付出的代价来采取一些措施降低数据不一致的问题出现的概率，在数据一致性和性能之间取得一个权衡。对于数据库的实时性一致性要求不是特别高的场合，比如 T+1 的报表，可以采用定时任务查询数据库数据同步到 Redis 的方案。由于我们是以数据库的数据为准的，所以给缓存设置一个过期时间，是保证最终一致性的解决方案。 方案选择Redis:删除还是更新?这里我们先要补充一点，当存储的数据发生变化，Redis 的数据也要更新的时候，我们有两种方案，一种就是直接更新，调用 set;还有一种是直接删除缓存，让应用在下次查询的时候重新写入。这两种方案怎么选择呢?这里我们主要考虑更新缓存的代价。更新缓存之前，是不是要经过其他表的查询、接口调用、计算才能得到最新的数据， 而不是直接从数据库拿到的值。如果是的话，建议直接删除缓存，这种方案更加简单， 而且避免了数据库的数据和缓存不一致的情况。在一般情况下，我们也推荐使用删除的方案。 先更新数据库，再删除缓存正常情况: 更新数据库，成功。 删除缓存，成功。 异常情况: 更新数据库失败，程序捕获异常，不会走到下一步，所以数据不会出现不一致。 更新数据库成功，删除缓存失败。数据库是新数据，缓存是旧数据，发生了不一致的情况。 这种问题怎么解决呢?我们可以提供一个重试的机制。比如:如果删除缓存失败，我们捕获这个异常，把需要删除的 key 发送到消息队列。 让后自己创建一个消费者消费，尝试再次删除这个 key。这种方式有个缺点，会对业务代码造成入侵。所以我们又有了第二种方案(异步更新缓存):因为更新数据库时会往 binlog 写入日志，所以我们可以通过一个服务来监听 binlog 的变化(比如阿里的 canal)，然后在客户端完成删除 key 的操作。如果删除失败的话，再发送到消息队列。总之，对于后删除缓存失败的情况，我们的做法是不断地重试删除，直到成功。无论是重试还是异步删除，都是最终一致性的思想。 先删除缓存，再更新数据库正常情况: 删除缓存，成功。 更新数据库，成功。 异常情况: 删除缓存，程序捕获异常，不会走到下一步，所以数据不会出现不一致。 删除缓存成功，更新数据库失败。 因为以数据库的数据为准，所以不存在数据不一致的情况。 看起来好像没问题，但是如果有程序并发操作的情况下: 线程 A 需要更新数据，首先删除了 Redis 缓存 线程 B 查询数据，发现缓存不存在，到数据库查询旧值，写入 Redis，返回 线程 A 更新了数据库 这个时候，Redis 是旧的值，数据库是新的值，发生了数据不一致的情况。那问题就变成了:能不能让对同一条数据的访问串行化呢?代码肯定保证不了，因为有多个线程，即使做了任务队列也可能有多个服务实例。数据库也保证不了，因为会有多个数据库的连接。只有一个数据库只提供一个连接的情况下，才能保证读写的操作是串行的，或者我们把所有的读写请求放到同一个内存队列当中，但是这种情况吞吐量 太低了。所以我们有一种延时双删的策略，在写入数据之后，再删除一次缓存。 删除缓存 更新数据库 休眠 500ms(这个时间，依据读取数据的耗时而定) 再次删除缓存 高并发问题在 Redis 存储的所有数据中，有一部分是被频繁访问的。有两种情况可能会导致热点问题的产生，一个是用户集中访问的数据，比如抢购的商品，明星结婚和明星出轨的微博。还有一种就是在数据进行分片的情况下，负载不均衡，超过了单个服务器的承受能力。热点问题可能引起缓存服务的不可用，最终造成压力堆积到数据库。出于存储和流量优化的角度，我们必须要找到这些热点数据。 热点数据发现除了自动的缓存淘汰机制之外，怎么找出那些访问频率高的 key 呢?或者说，我们可以在哪里记录 key 被访问的情况呢? 客户端第一个当然是在客户端了，比如我们可不可以在所有调用了 get、set 方法的地方，加上 key 的计数。但是这样的话，每一个地方都要修改，重复的代码也多。如果我们用的是 Jedis 的客户端，我们可以在 Jedis 的 Connection 类的 sendCommand()里面，用 一个 HashMap 进行 key 的计数。但是这种方式有几个问题: 不知道要存多少个 key，可能会发生内存泄露的问题。 会对客户端的代码造成入侵。 只能统计当前客户端的热点 key。 代理层第二种方式就是在代理端实现，比如 TwemProxy 或者 Codis，但是不是所有的项目都使用了代理的架构。 服务端第三种就是在服务端统计，Redis 有一个 monitor 的命令，可以监控到所有 Redis 执行的命令。 123456jedis.monitor(new JedisMonitor() &#123; @Override public void onCommand(String command) &#123; System.out.println(&quot;#monitor: &quot; + command); &#125;&#125;); Facebook 的开源项目 redis-faina 就是基于这个原理实现的。 它是一个 python 脚本，可以分析 monitor 的数据。 1redis-cli -p 6379 monitor | head -n 100000 | ./redis-faina.py 这种方法也会有两个问题: monitor 命令在高并发的场景下，会影响性能，所以 不适合长时间使用。 只能统计一个 Redis 节点的热点 key。 机器层面还有一种方法就是机器层面的，通过对 TCP 协议进行抓包，也有一些开源的方案，比如 ELK 的 packetbeat 插件。当我们发现了热点 key 之后，我们来看下热点数据在高并发的场景下可能会出现的问题，以及怎么去解决。 缓存雪崩什么是缓存雪崩缓存雪崩就是 Redis 的大量热点数据同时过期(失效)，因为设置了相同的过期时间，刚好这个时候 Redis 请求的并发量又很大，就会导致所有的请求落到数据库。 缓存雪崩的解决方案 加互斥锁或者使用队列，针对同一个 key 只允许一个线程到数据库查询 缓存定时预先更新，避免同时失效 通过加随机数，使 key 在不同的时间过期 缓存永不过期 缓存穿透缓存穿透何时发生我们已经知道了 Redis 使用的场景了。在缓存存在和缓存不存在的情况下的什么情况我们都了解了。还有一种情况，数据在数据库和 Redis 里面都不存在，可能是一次条件错误的查询。在这种情况下，因为数据库值不存在，所以肯定不会写入 Redis，那么下一次查询相同的 key 的时候，肯定还是会再到数据库查一次。那么这种循环查询数据库中不存在的值，并且每次使用的是相同的 key 的情况，我们有没有什么办法避免应用到数据库查询呢? 缓存空数据 缓存特殊字符串，比如&amp;&amp; 我们可以在数据库缓存一个空字符串，或者缓存一个特殊的字符串，那么在应用里 面拿到这个特殊字符串的候，就知道数据库没有值了，也没有必要再到数据库查询了。但是这里需要设置一个过期时间，不然的话数据库已经新增了这一条记录，应用也还是拿不到值。这个是应用重复查询同一个不存在的值的情况，如果应用每一次查询的不存在的值是不一样的呢?即使你每次都缓存特殊字符串也没用，因为它的值不一样，比如我们的用户系统登录的场景，如果是恶意的请求，它每次都生成了一个符合 ID 规则的账号，但是这个账号在我们的数据库是不存在的，那 Redis 就完全失去了作用。这种因为每次查询的值都不存在导致的 Redis 失效的情况，我们就把它叫做缓存穿透。这个问题我们应该怎么去解决呢? 经典面试题其实它也是一个通用的问题，关键就在于我们怎么知道请求的 key 在我们的数据库里面是否存在，如果数据量特别大的话，我们怎么去快速判断。这也是一个非常经典的面试题:如何在海量元素中(例如 10 亿无序、不定长、不重复)快速判断一个元素是否存在?如果是缓存穿透的这个问题，我们要避免到数据库查询不存的数据，肯定要把这 10 亿放在别的地方。这些数据在 Redis 里面也是没有的，为了加快检索速度，我们要把数据放到内存里面来判断，问题来了:如果我们直接把这些元素的值放到基本的数据结构(List、Map、Tree)里面，比如 一个元素 1 字节的字段，10 亿的数据大概需要 900G 的内存空间，这个对于普通的服务器来说是承受不了的。所以，我们存储这几十亿个元素，不能直接存值，我们应该找到一种最简单的最节省空间的数据结构，用来标记这个元素有没有出现。这个东西我们就把它叫做位图，他是一个有序的数组，只有两个值，0 和 1。0 代表不存在，1 代表存在。对于这个映射方法，我们有几个基本的要求: 因为我们的值长度是不固定的，我希望不同长度的输入，可以得到固定长度的输出。 转换成下标的时候，我希望他在我的这个有序数组里面是分布均匀的，不然的话 全部挤到一对去了，我也没法判断到底哪个元素存了，哪个元素没存。 这个就是哈希函数，比如 MD5、SHA-1 等等这些都是常见的哈希算法。 哈希碰撞如果发生了哈希碰撞，这个时候对于我们的容器存值肯定是有影响的，我们可以通过哪些方式去降低哈希碰撞的概率呢?第一种就是扩大维数组的长度或者说位图容量。因为我们的函数是分布均匀的，所以，位图容量越大，在同一个位置发生哈希碰撞的概率就越小。是不是位图容量越大越好呢?不管存多少个元素，都创建一个几万亿大小的位图， 可以吗？当然不行，因为越大的位图容量，意味着越多的内存消耗，所以我们要创建一个合适大小的位图容量。第二种就是进行多次哈希计算。如果两个元素经过一次哈希计算，得到的相同下标的概率比较高，我可以不可以计 算多次呢? 原来我只用一个哈希函数，现在我对于每一个要存储的元素都用多个哈希函数计算，这样每次计算出来的下标都相同的概率就小得多了。同样的，我们能不能引入很多个哈希函数呢?比如都计算 100 次，都可以吗？当然也会有问题，第一个就是它会填满位图的更多空间，第二个是计算是需要消耗时间的。所以总的来说，我们既要节省空间，又要很高的计算效率，就必须在位图容量和函数个数之间找到一个最佳的平衡。 布隆过滤器关于布隆过滤器可以参考我的另一篇博客：什么是布隆过滤器？]]></content>
      <categories>
        <category>Redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[什么是布隆过滤器？]]></title>
    <url>%2F2019%2F12%2F01%2F%E4%BB%80%E4%B9%88%E6%98%AF%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[概念布隆过滤器（英语：Bloom Filter）是1970年由一个叫布隆的小伙子提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。 原理布隆过滤器的原理是，当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。Bloom Filter跟单哈希函数Bit-Map不同之处在于：Bloom Filter使用了k个哈希函数，每个字符串跟k个bit对应。从而降低了冲突的概率。集合里面有3个元素，要把它存到布隆过滤器里面去，应该怎么做?首先是a元素，这里我们用3次计算。b、c元素也一样。元素已经存进去之后，现在我要来判断一个元素在这个容器里面是否存在，就要使用同样的三个函数进行计算。比如d元素，我用第一个函数h1()计算，发现这个位置上是1，没问题。第二个位置也是1，第三个位置也是1。如果经过三次计算得到的下标位置值都是1，这种情况下，能不能确定d元素一定 在这个容器里面呢? 实际上是不能的。比如这张图里面，这三个位置分别是把a,b,c 存进去的时候置成1的，所以即使d元素之前没有存进去，也会得到三个1，判断返回 true。我们再来看另一个元素，e元素。我们要判断它在容器里面是否存在，一样地要用这三个函数去计算。第一个位置是1，第二个位置是1，第三个位置是0。e 元素是不是一定不在这个容器里面呢? 可以确定一定不存在。如果说当时已经把e元素存到布隆过滤器里面去了，那么这三个位置肯定都是1，不可能出现0。 特点从容器的角度来说: 如果布隆过滤器判断元素在集合中存在，不一定存在 如果布隆过滤器判断不存在，一定不存在 从元素的角度来说: 如果元素实际存在，布隆过滤器一定判断存在 如果元素实际不存在，布隆过滤器可能判断存在 缺点bloom filter之所以能做到在时间和空间上的效率比较高，是因为牺牲了判断的准确率、删除的便利性 存在误判，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1。因为哈希碰撞不可避免，所以它会存在一定的误判率。这种把本来不存在布隆过滤器中的元素误判为存在的情况，我们把它叫做假阳性(False Positive Probability，FPP)。 删除困难。一个放入容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为0，可能会影响其他元素的判断。可以采用Counting Bloom Filter 实现 在使用bloom filter时，绕不过的两点是预估数据量n以及期望的误判率fpp 在实现bloom filter时，绕不过的两点就是hash函数的选取以及bit数组的大小 对于一个确定的场景，我们预估要存的数据量为n，期望的误判率为fpp，然后需要计算我们需要的Bit数组的大小m，以及hash函数的个数k，并选择hash函数 Bit数组大小选择根据预估数据量n以及误判率fpp，bit数组大小的m的计算方式：位图的容量是基于元素个数和误判率计算出来的。 1long numBits = optimalNumOfBits(expectedInsertions, fpp); 哈希函数选择由预估数据量n以及bit数组长度m，可以得到一个hash函数的个数k：哈希函数的选择对性能的影响应该是很大的，一个好的哈希函数要能近似等概率的将字符串映射到各个Bit。选择k个不同的哈希函数比较麻烦，一种简单的方法是选择一个哈希函数，然后送入k个不同的参数。哈希函数个数k、位数组大小m、加入的字符串数量n的关系可以参考Bloom Filters - the math，Bloom_filter-wikipedia根据位数组的大小，我们进一步计算出了哈希函数的个数。 1int numHashFunctions = optimalNumOfHashFunctions(expectedInsertions, numBits); 空间存储 100 万个元素只占用了 0.87M 的内存，生成了 5 个哈希函数。https://hur.st/bloomfilter/?n=1000000&amp;p=0.03&amp;m=&amp;k= 代码谷歌的 Guava 里面就提供了一个现成的布隆过滤器。 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;23.0&lt;/version&gt;&lt;/dependency&gt; 简单使用布隆过滤器: 123456789101112131415161718192021222324import com.google.common.hash.BloomFilter;import com.google.common.hash.Funnels;public class BloomFilterTest &#123; private static int total = 1000000; private static BloomFilter&lt;Integer&gt; bf = BloomFilter.create(Funnels.integerFunnel(), total); //可以设置你允许的误差率，误差范围：0&lt;fpp&lt;1 //private static BloomFilter&lt;Integer&gt; bf = BloomFilter.create(Funnels.integerFunnel(), total, 0.01); public static void main(String[] args) &#123; // 初始化1000000条数据到过滤器中 for (int i = 0; i &lt; total; i++) &#123; bf.put(i); &#125; // 获取随机数匹配在过滤器中存在 int i = (int)(1+Math.random()*(10000)); if (bf.mightContain(i)) &#123; System.out.println(&quot;BloomFilter 判定存在&quot;); &#125; &#125;&#125; 使用场景 如何在海量元素中快速判断一个元素是否存在（Redis 缓存穿透） 爬虫过滤已抓到的url 垃圾邮件过滤]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MySQL多表关联查询优化]]></title>
    <url>%2F2019%2F11%2F28%2FMySQL%E5%A4%9A%E8%A1%A8%E5%85%B3%E8%81%94%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[背景最近在对运营报表导出进行优化，总结了一些多表关联查询优化的点记录一下。 避免临时表通过 Explain 分析 SQL 语句，尽量不要使用到临时表。GROUP BY （Explain具体详解，可以看这篇博客） 最容易造成使用临时表，GROUP BY 与临时表的关系 : 1. 如果GROUP BY 的列没有索引,产生临时表. 2. 如果GROUP BY时,SELECT的列不止GROUP BY列一个,并且GROUP BY的列不是主键 ,产生临时表. 3. 如果GROUP BY的列有索引,ORDER BY的列没索引.产生临时表. 4. 如果GROUP BY的列和ORDER BY的列不一样,即使都有索引也会产生临时表. 5. 如果GROUP BY或ORDER BY的列不是来自JOIN语句第一个表.会产生临时表. 6. 如果DISTINCT 和 ORDER BY的列没有索引,产生临时表.如果业务需求没法更改，也不需要强制去掉临时表。 缩小数据范围接下来进行优化第二步，将临时表缩小到最小范围。SQL 执行过程大体如下： 执行FROM语句 执行ON过滤 添加外部行 执行where条件过滤 执行group by分组语句 执行having select列表 执行distinct去重复数据 执行order by字句 执行limit字句 当两个表进行Join操作时，主表的Where限制可以写在最后，但从表分区限制条件不要写在Where条件中，建议写在ON条件或者子查询中。主表的分区限制条件可以写在Where条件中（最好先用子查询过滤）。示例如下： 123select * from A join (select * from B where dt=20150301)B on B.id=A.id where A.dt=20150301； select * from A join B on B.id=A.id where B.dt=20150301； --不允许 select * from (select * from A where dt=20150301)A join (select * from B where dt=20150301)B on B.id=A.id； 第二个语句会先Join，后进行分区裁剪，数据量变大，性能下降。在实际使用过程中，应该尽量避免第二种用法。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 单机安装Redis Cluster（3主3从）]]></title>
    <url>%2F2019%2F11%2F26%2FCentOS%207%20%E5%8D%95%E6%9C%BA%E5%AE%89%E8%A3%85Redis%20Cluster%EF%BC%883%E4%B8%BB3%E4%BB%8E%EF%BC%89%2F</url>
    <content type="text"><![CDATA[首先，本篇要基于单实例的安装，你的机器上已经有一个Redis。（还没安装的同学请自行百度） 安装过程为了节省机器，我们直接把6个Redis实例安装在同一台机器上（3主3从），只是使用不同的端口号。机器IP 192.168.8.207 更新：新版的cluster已经不需要通过ruby脚本创建，删掉了ruby相关依赖的安装 1234cd /usr/local/soft/redis-5.0.5mkdir redis-clustercd redis-clustermkdir 7291 7292 7293 7294 7295 7296 复制redis配置文件到7291目录 1cp /usr/local/soft/redis-5.0.5/redis.conf /usr/local/soft/redis-5.0.5/redis-cluster/7291 修改7291的redis.conf配置文件，内容： 1234567port 7291dir /usr/local/soft/redis-5.0.5/redis-cluster/7291/cluster-enabled yescluster-config-file nodes-7291.confcluster-node-timeout 5000appendonly yespidfile /var/run/redis_7291.pid 把7291下的redis.conf复制到其他5个目录。 123456cd /usr/local/soft/redis-5.0.5/redis-cluster/7291cp redis.conf ../7292cp redis.conf ../7293cp redis.conf ../7294cp redis.conf ../7295cp redis.conf ../7296 批量替换内容 123456cd /usr/local/soft/redis-5.0.5/redis-clustersed -i &apos;s/7291/7292/g&apos; 7292/redis.confsed -i &apos;s/7291/7293/g&apos; 7293/redis.confsed -i &apos;s/7291/7294/g&apos; 7294/redis.confsed -i &apos;s/7291/7295/g&apos; 7295/redis.confsed -i &apos;s/7291/7296/g&apos; 7296/redis.conf 启动6个Redis节点 1234567cd /usr/local/soft/redis-5.0.5/./src/redis-server redis-cluster/7291/redis.conf./src/redis-server redis-cluster/7292/redis.conf./src/redis-server redis-cluster/7293/redis.conf./src/redis-server redis-cluster/7294/redis.conf./src/redis-server redis-cluster/7295/redis.conf./src/redis-server redis-cluster/7296/redis.conf 是否启动了6个进程 1ps -ef|grep redis 创建集群旧版本中的redis-trib.rb已经废弃了，直接用–cluster命令注意用绝对IP，不要用127.0.0.1 12cd /usr/local/soft/redis-5.0.5/src/redis-cli --cluster create 192.168.8.207:7291 192.168.8.207:7292 192.168.8.207:7293 192.168.8.207:7294 192.168.8.207:7295 192.168.8.207:7296 --cluster-replicas 1 Redis会给出一个预计的方案，对6个节点分配3主3从，如果认为没有问题，输入yes确认 12345678910111213141516171819202122&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Master[0] -&gt; Slots 0 - 5460Master[1] -&gt; Slots 5461 - 10922Master[2] -&gt; Slots 10923 - 16383Adding replica 127.0.0.1:7295 to 127.0.0.1:7291Adding replica 127.0.0.1:7296 to 127.0.0.1:7292Adding replica 127.0.0.1:7294 to 127.0.0.1:7293&gt;&gt;&gt; Trying to optimize slaves allocation for anti-affinity[WARNING] Some slaves are in the same host as their masterM: dfdc9c0589219f727e4fd0ad8dafaf7e0cfb4f1c 127.0.0.1:7291 slots:[0-5460] (5461 slots) masterM: 8c878b45905bba3d7366c89ec51bd0cd7ce959f8 127.0.0.1:7292 slots:[5461-10922] (5462 slots) masterM: aeeb7d7076d9b25a7805ac6f508497b43887e599 127.0.0.1:7293 slots:[10923-16383] (5461 slots) masterS: ebc479e609ff8f6ca9283947530919c559a08f80 127.0.0.1:7294 replicates aeeb7d7076d9b25a7805ac6f508497b43887e599S: 49385ed6e58469ef900ec48e5912e5f7b7505f6e 127.0.0.1:7295 replicates dfdc9c0589219f727e4fd0ad8dafaf7e0cfb4f1cS: 8d6227aefc4830065624ff6c1dd795d2d5ad094a 127.0.0.1:7296 replicates 8c878b45905bba3d7366c89ec51bd0cd7ce959f8Can I set the above configuration? (type &apos;yes&apos; to accept): 注意看slot的分布： 1237291 [0-5460] (5461个槽) 7292 [5461-10922] (5462个槽) 7293 [10923-16383] (5461个槽) 集群创建完成 12345678910111213141516171819202122232425262728&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join....&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7291)M: dfdc9c0589219f727e4fd0ad8dafaf7e0cfb4f1c 127.0.0.1:7291 slots:[0-5460] (5461 slots) master 1 additional replica(s)M: 8c878b45905bba3d7366c89ec51bd0cd7ce959f8 127.0.0.1:7292 slots:[5461-10922] (5462 slots) master 1 additional replica(s)M: aeeb7d7076d9b25a7805ac6f508497b43887e599 127.0.0.1:7293 slots:[10923-16383] (5461 slots) master 1 additional replica(s)S: 8d6227aefc4830065624ff6c1dd795d2d5ad094a 127.0.0.1:7296 slots: (0 slots) slave replicates aeeb7d7076d9b25a7805ac6f508497b43887e599S: ebc479e609ff8f6ca9283947530919c559a08f80 127.0.0.1:7294 slots: (0 slots) slave replicates dfdc9c0589219f727e4fd0ad8dafaf7e0cfb4f1cS: 49385ed6e58469ef900ec48e5912e5f7b7505f6e 127.0.0.1:7295 slots: (0 slots) slave replicates 8c878b45905bba3d7366c89ec51bd0cd7ce959f8[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 重置集群的方式是在每个节点上个执行cluster reset，然后重新创建集群 连接到客户端 123redis-cli -p 7291redis-cli -p 7292redis-cli -p 7293 批量写入值 12cd /usr/local/soft/redis-5.0.5/redis-cluster/vim setkey.sh 脚本内容 1234567#!/bin/bashfor ((i=0;i&lt;20000;i++))doecho -en &quot;helloworld&quot; | redis-cli -h 192.168.8.207 -p 7291 -c -x set name$i &gt;&gt;redis.logdonechmod +x setkey.sh./setkey.sh 每个节点分布的数据 123456127.0.0.1:7292&gt; dbsize(integer) 6683127.0.0.1:7293&gt; dbsize(integer) 6665127.0.0.1:7291&gt; dbsize(integer) 6652 其他命令，比如添加节点、删除节点，重新分布数据： 1234567891011121314151617181920212223242526272829303132333435363738redis-cli --cluster helpCluster Manager Commands: create host1:port1 ... hostN:portN --cluster-replicas &lt;arg&gt; check host:port --cluster-search-multiple-owners info host:port fix host:port --cluster-search-multiple-owners reshard host:port --cluster-from &lt;arg&gt; --cluster-to &lt;arg&gt; --cluster-slots &lt;arg&gt; --cluster-yes --cluster-timeout &lt;arg&gt; --cluster-pipeline &lt;arg&gt; --cluster-replace rebalance host:port --cluster-weight &lt;node1=w1...nodeN=wN&gt; --cluster-use-empty-masters --cluster-timeout &lt;arg&gt; --cluster-simulate --cluster-pipeline &lt;arg&gt; --cluster-threshold &lt;arg&gt; --cluster-replace add-node new_host:new_port existing_host:existing_port --cluster-slave --cluster-master-id &lt;arg&gt; del-node host:port node_id call host:port command arg arg .. arg set-timeout host:port milliseconds import host:port --cluster-from &lt;arg&gt; --cluster-copy --cluster-replace help For check, fix, reshard, del-node, set-timeout you can specify the host and port of any working node in the cluster. 附录集群命令 123456cluster info ：打印集群的信息cluster nodes ：列出集群当前已知的所有节点（node），以及这些节点的相关信息。cluster meet ：将 ip 和 port 所指定的节点添加到集群当中，让它成为集群的一份子。cluster forget &lt;node_id&gt; ：从集群中移除 node_id 指定的节点(保证空槽道)。cluster replicate &lt;node_id&gt; ：将当前节点设置为 node_id 指定的节点的从节点。cluster saveconfig ：将节点的配置文件保存到硬盘里面。 槽slot命令 1234567cluster addslots [slot …] ：将一个或多个槽（slot）指派（assign）给当前节点。cluster delslots [slot …] ：移除一个或多个槽对当前节点的指派。cluster flushslots ：移除指派给当前节点的所有槽，让当前节点变成一个没有指派任何槽的节点。cluster setslot node &lt;node_id&gt; ：将槽 slot 指派给 node_id 指定的节点，如果槽已经指派给另一个节点，那么先让另一个节点删除该槽&gt;，然后再进行指派。cluster setslot migrating &lt;node_id&gt; ：将本节点的槽 slot 迁移到 node_id 指定的节点中。cluster setslot importing &lt;node_id&gt; ：从 node_id 指定的节点中导入槽 slot 到本节点。cluster setslot stable ：取消对槽 slot 的导入（import）或者迁移（migrate）。 键命令 123cluster keyslot ：计算键 key 应该被放置在哪个槽上。cluster countkeysinslot ：返回槽 slot 目前包含的键值对数量。cluster getkeysinslot ：返回 count 个 slot 槽中的键]]></content>
      <categories>
        <category>Redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[深入理解Redis-集群篇]]></title>
    <url>%2F2019%2F11%2F25%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-%E9%9B%86%E7%BE%A4%E7%AF%87%2F</url>
    <content type="text"><![CDATA[为什么需要 Redis 集群？性能Redis 本身的 QPS 已经很高了，但是如果在一些并发量非常高的情况下，性能还是会受到影响。这个时候我们希望有更多的 Redis 服务来完成工作。 扩展第二个是出于存储的考虑。因为 Redis 所有的数据都放在内存中，如果数据量大，很容易受到硬件的限制。升级硬件收效和成本比太低，所以我们需要有一种横向扩展的方法。 可用性第三个是可用性和安全的问题。如果只有一个 Redis 服务，一旦服务宕机，那么所有的客户端都无法访问，会对业务造成很大的影响。另一个，如果硬件发生故障，而单 机的数据无法恢复的话，带来的影响也是灾难性的。 总结可用性、数据安全、性能都可以通过搭建多个 Reids 服务实现。其中有一个是主节点(master)，可以有多个从节点(slave)。主从之间通过数据同步，存储完全相同的数据。如果主节点发生故障，则把某个从节点改成主节点，访问新的主节点。 Redis 主从复制(replication)配置例如一主多从,203 是主节点，在每个 slave 节点的 redis.conf 配置文件增加一行 1slaveof 192.168.8.203 6379 在主从切换的时候，这个配置会被重写成: 12# Generated by CONFIG REWRITEreplicaof 192.168.8.203 6379 或者在启动服务时通过参数指定 master 节点: 1./redis-server --slaveof 192.168.8.203 6379 或在客户端直接执行 slaveof xx xx，使该 Redis 实例成为从节点。启动后，查看集群状态: 1redis&gt; info replication 从节点不能写入数据(只读)，只能从 master 节点同步数据。get 成功，set 失败。 12127.0.0.1:6379&gt; set test 666(error) READONLY You can&apos;t write against a read only replica. 主节点写入后，slave 会自动从 master 同步数据。断开主节点: 1redis&gt; slaveof no one 此时从节点会变成自己的主节点，不再复制数据。 原理连接阶段1、slave node 启动时(执行 slaveof 命令)，会在自己本地保存 master node 的信息，包括 master node 的 host 和 ip。2、slave node 内部有个定时任务 replicationCron(源码 replication.c)，每隔 1 秒钟检查是否有新的 master node 要连接和复制，如果发现，就跟 master node 建立 socket 网络接，如果连接成功，从节点为该 socket 建立一个专门处理复制工作的文件 事件处理器，负责后续的复制工作，如接收 RDB 文件、接收命令传播等。当从节点变成了主节点的一个客户端之后，会给主节点发送 ping 请求。 数据同步阶段3、master node 第一次执行全量复制，通过 bgsave 命令在本地生成一份 RDB 快照，将 RDB 快照文件发给 slave node(如果超时会重连，可以调大 repl-timeout 的值)。 slave node 首先清除自己的旧数据，然后用 RDB 文件加载数据。 生成 RDB 期间，master 接收到的命令怎么处理?开始生成 RDB 文件时，master 会把所有新的写命令缓存在内存中。在 slave node 保存了 RDB 之后，再将新的写命令复制给 slave node。 命令传播阶段4、master node 持续将写命令，异步复制给 slave node延迟是不可避免的，只能通过优化网络。 1repl-disable-tcp-nodelay no 当设置为 yes 时，TCP 会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差;具体发送频率与 Linux 内核的配置有关，默认配置为 40ms。当设置为 no 时，TCP 会立马将主节点的数据发送给从节点，带宽增加但延迟变小。一般来说，只有当应用对 Redis 数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为 yes;多数情况使用默认值 no。如果从节点有一段时间断开了与主节点的连接是不是要重新全量复制一遍? 如果可以增量复制，怎么知道上次复制到哪里?通过 master_repl_offset 记录的偏移量 12redis&gt; info replicationmaster_repl_offset:7324993 不足主从模式解决了数据备份和性能(通过读写分离)的问题，但是还是存在一些不足: RDB 文件过大的情况下，同步非常耗时。 在一主一从或者一主多从的情况下，如果主服务器挂了，对外提供的服务就不可 用了，单点问题没有得到解决。如果每次都是手动把之前的从服务器切换成主服务器， 这个比较费时费力，还会造成一定时间的服务不可用。 SentinelSentinel原理如何实现主从的自动切换?我们的思路:创建一台监控服务器来监控所有 Redis 服务节点的状态，比如，master 节点超过一定时间没有给监控服务器发送心跳报文，就把 master 标记为下线，然后把某一个 slave 变成 master。应用每一次都是从这个监控服务器拿到 master 的地址。问题是:如果监控服务器本身出问题了怎么办?那我们就拿不到 master 的地址了，应用也没有办法访问。那我们再创建一个监控服务器，来监控监控服务器……似乎陷入死循环了，这个问题 怎么解决?这个问题先放着。Redis 的 Sentinel 就是这种思路:通过运行监控服务器来保证服务的可用性。从 Redis2.8 版本起，提供了一个稳定版本的 Sentinel(哨兵)，用来解决高可用的问题。它是一个特殊状态的 redis 实例。我们会启动一个或者多个 Sentinel 的服务(通过 src/redis-sentinel)，它本质上只是一个运行在特殊模式之下的 Redis，Sentinel 通过 info 命令得到被监听 Redis 机器的 master，slave 等信息。为了保证监控服务器的可用性，我们会对 Sentinel 做集群的部署。Sentinel 既监控所有的 Redis 服务，Sentinel 之间也相互监控。注意:Sentinel 本身没有主从之分，只有 Redis 服务节点有主从之分。概念梳理:master，slave(redis group)，sentinel，sentinel 集合 服务下线Sentinel 默认以每秒钟 1 次的频率向 Redis 服务节点发送 PING 命令。如果在 down-after-milliseconds 内都没有收到有效回复，Sentinel 会将该服务器标记为下线 (主观下线)。 12# sentinel.confsentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt; 这个时候 Sentinel 节点会继续询问其他的 Sentinel 节点，确认这个节点是否下线，如果多数 Sentinel 节点都认为 master 下线，master 才真正确认被下线(客观下线)，这个时候就需要重新选举 master。 故障转移如果 master 被标记为下线，就会开始故障转移流程。既然有这么多的 Sentinel 节点，由谁来做故障转移的事情呢?故障转移流程的第一步就是在 Sentinel 集群选择一个 Leader，由 Leader 完成故障转移流程。Sentinle 通过 Raft 算法，实现 Sentinel 选举。 Ratf 算法在分布式存储系统中，通常通过维护多个副本来提高系统的可用性，那么多个节点之间必须要面对数据一致性的问题。Raft 的目的就是通过复制的方式，使所有节点达成一致，但是这么多节点，以哪个节点的数据为准呢?所以必须选出一个 Leader。大体上有两个步骤:领导选举，数据复制。Raft 是一个共识算法(consensus algorithm)。比如比特币之类的加密货币，就 需要共识算法。Spring Cloud 的注册中心解决方案 Consul 也用到了 Raft 协议。Raft 的核心思想:先到先得，少数服从多数。Raft 算法演示:http://thesecretlivesofdata.com/raft/Sentinle 的 Raft 算法和 Raft 论文略有不同。 master 客观下线触发选举，而不是过了 election timeout 时间开始选举。 Leader 并不会把自己成为 Leader 的消息发给其他 Sentinel。其他 Sentinel 等待 Leader 从 slave 选出 master 后，检测到新的 master 正常工作后，就会去掉客观下线的标识，从而不需要进入故障转移流程。 问题:怎么让一个原来的 slave 节点成为主节点? 选出 Sentinel Leader 之后，由 Sentinel Leader 向某个节点发送 slaveof no one 命令，让它成为独立节点。 然后向其他节点发送 slaveof x.x.x.x xxxx(本机服务)，让它们成为这个节点的子节点，故障转移完成。 问题:这么多从节点，选谁成为主节点?关于从节点选举，一共有四个因素影响选举的结果，分别是断开连接时长、优先级 排序、复制数量、进程id。如果与哨兵连接断开的比较久，超过了某个阈值，就直接失去了选举权。如果拥有选举权，那就看谁的优先级高，这个在配置文件里可以设置(replica-priority 100)， 数值越小优先级越高。如果优先级相同，就看谁从 master 中复制的数据最多(复制偏移量最大)，选最多的那个，如果复制数量也相同，就选择进程 id 最小的那个。 功能总结 监控:Sentinel 会不断检查主服务器和从服务器是否正常运行。 通知:如果某一个被监控的实例出现问题，Sentinel 可以通过 API 发出通知。 自动故障转移(failover):如果主服务器发生故障，Sentinel 可以启动故障转移过程。把某台服务器升级为主服务器，并发出通知。 配置管理:客户端连接到 Sentinel，获取当前的 Redis 主服务器的地址。 Sentinel实战Sentinel 配置为了保证 Sentinel 的高可用，Sentinel 也需要做集群部署，集群中至少需要三个 Sentinel 实例(推荐奇数个，防止脑裂)。 hostname IP 地址 节点角色&amp;端口 master 192.168.8.203 Master:6379 / Sentinel : 26379 slave1 192.168.8.204 Slave :6379 / Sentinel : 26379 Slave2 192.168.8.205 Slave :6379 / Sentinel : 26379 以 Redis 安装路径/usr/local/soft/redis-5.0.5/为例。 在 204 和 205 的 src/redis.conf 配置文件中添加 1slaveof 192.168.8.203 6379 在203、204、205 创建 sentinel 配置文件( 安装后根目录下默认有 sentinel.conf ): 1234cd /usr/local/soft/redis-5.0.5 mkdir logsmkdir rdbsmkdir sentinel-tmpvim sentinel.conf 三台服务器内容相同: 12345daemonize yesport 26379protected-mode nodir &quot;/usr/local/soft/redis-5.0.5/sentinel-tmp&quot;sentinel monitor redis-master 192.168.8.203 6379 2 sentinel down-after-milliseconds redis-master 30000 sentinel failover-timeout redis-master 180000 sentinel parallel-syncs redis-master 1 上面出现了 4 个’redis-master’，这个名称要统一，并且使用客户端(比如 Jedis) 连接的时候名称要正确。 hostname IP 地址 protected-mode 是否允许外部网络访问 dir sentinel 的工作目录 sentinel monitor sentinel 监控的 redis 主节点 down-after-milliseconds(毫秒) master 宕机多久，才会被 Sentinel 主观认为下线 sentinel failover-timeout(毫秒) 1 同一个 sentinel 对同一个 master 两次 failover 之间的间隔时间。2. 当一个 slave 从一个错误的 master 那里同步数据开始计算时间。直到 slave 被纠正为向正确的 master 那里同步数据时。3.当想要取消一个正在进行的 failover 所需要的时间。4.当进行 failover 时，配置所有 slaves 指向新的 master 所需的最大时间。 parallel-syncs 这个配置项指定了在发生 failover 主备切换时最多可以有多少个 slave 同 时对新的 master 进行 同步，这个数字越小，完成 failover 所需的时间就 越长，但是如果这个数字越大，就意味着越 多的 slave 因为 replication 而 不可用。可以通过将这个值设为 1 来保证每次只有一个 slave 处于不能处 理命令请求的状态。 Sentinel 验证启动 Redis 服务和 Sentinel 1234567cd /usr/local/soft/redis-5.0.5/src # 启动 Redis 节点 ./redis-server ../redis.conf# 启动 Sentinel 节点 ./redis-sentinel ../sentinel.conf # 或者./redis-server ../sentinel.conf --sentinel 查看集群状态: 1redis&gt; info replication 模拟 master 宕机，在 203 执行: 1redis&gt; shutdown 205 被选为新的 Master，只有一个 Slave 节点。注意看 sentinel.conf 里面的 redis-master 被修改了! 模拟原 master 恢复，在 203 启动 redis-server。它还是 slave，但是 master 又有 两个 slave 了。 Sentinel 连接使用Jedis 连接 Sentinel， 来自于 sentinel.conf 的配置。 123456789private static JedisSentinelPool createJedisPool() &#123; String masterName = &quot;redis-master&quot;; Set&lt;String&gt; sentinels = new HashSet&lt;String&gt;(); sentinels.add(&quot;192.168.8.203:26379&quot;); sentinels.add(&quot;192.168.8.204:26379&quot;); sentinels.add(&quot;192.168.8.205:26379&quot;); pool = new JedisSentinelPool(masterName, sentinels); return pool; &#125; Spring Boot 连接 Sentinel 1spring.redis.sentinel.master=redis-master spring.redis.sentinel.nodes=192.168.8.203:26379,192.168.8.204:26379,192.168.8.205:26379 无论是 Jedis 还是 Spring Boot(2.x 版本默认是 Lettuce)，都只需要配置全部哨 兵的地址，由哨兵返回当前的 master 节点地址。 哨兵机制的不足 主从切换的过程中会丢失数据，因为只有一个 master。 只能单点写，没有解决水平扩容的问题。 如果数据量非常大，这个时候我们需要多个 master-slave 的 group，把数据分布到不同的 group 中。 Redis 分布式方案如果要实现 Redis 数据的分片，我们有三种方案。第一种是在客户端实现相关的逻辑，例如用取模或者一致性哈希对 key 进行分片，查询和修改都先判断 key 的路由。第二种是把做分片处理的逻辑抽取出来，运行一个独立的代理服务，客户端连接到这个代理服务，代理服务做请求的转发。第三种就是基于服务端实现。 客户端 ShardingJedis 客户端提供了 Redis Sharding 的方案，并且支持连接池。 ShardedJedis1234567891011121314151617181920212223242526public class ShardingTest &#123; public static void main(String[] args) &#123; JedisPoolConfig poolConfig = new JedisPoolConfig(); ​ // Redis 服务器 JedisShardInfo shardInfo1 = new JedisShardInfo(&quot;127.0.0.1&quot;, 6379); JedisShardInfo shardInfo2 = new JedisShardInfo(&quot;192.168.8.205&quot;, 6379);​ // 连接池 List&lt;JedisShardInfo&gt; infoList = Arrays.asList(shardInfo1, shardInfo2); ShardedJedisPool jedisPool = new ShardedJedisPool(poolConfig, infoList); ShardedJedis jedis = null; try &#123; jedis = jedisPool.getResource(); for (int i = 0; i &lt; 100; i++) &#123; jedis.set(&quot;k&quot; + i, &quot;&quot; + i); &#125; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(jedis.get(&quot;k&quot; + i)); &#125; ​ &#125; finally &#123; if (jedis != null) &#123; jedis.close(); &#125; &#125; &#125;&#125; 使用 ShardedJedis 之类的客户端分片代码的优势是配置简单，不依赖于其他中间件，分区的逻辑可以自定义，比较灵活。但是基于客户端的方案，不能实现动态的服务增减，每个客户端需要自行维护分片策略，存在重复代码。 代理 Proxy第二种思路就是把分片的代码抽取出来，做成一个公共服务，所有的客户端都连接 到这个代理层。由代理层来实现请求和转发。典型的代理分区方案有 Twitter 开源的 Twemproxy 和国内的豌豆荚开源的 Codis。 Twemproxytwo-em-proxy：https://github.com/twitter/twemproxyTwemproxy 的优点:比较稳定，可用性高。不足:1、出现故障不能自动转移，架构复杂，需要借助其他组件(LVS/HAProxy + Keepalived)实现 HA2、扩缩容需要修改配置，不能实现平滑地扩缩容(需要重新分布数据)。 Codishttps://github.com/CodisLabs/codisCodis 是一个代理中间件，用 Go 语言开发的。功能:客户端连接 Codis 跟连接 Redis 没有区别。 Codis Twemproxy Redis Cluster 重新分片不需要重启 Yes No Yes pipeline Yes Yes No 多 key 操作的 hash tags {} Yes Yes Yes 重新分片时的多 key 操作 Yes - No 客户端支持 所有 所有 支持 cluster 协议的客户 端 分片原理:Codis 把所有的 key 分成了 N 个槽(例如 1024)，每个槽对应一个分组， 一个分组对应于一个或者一组 Redis 实例。Codis 对 key 进行 CRC32 运算，得到一个 32 位的数字，然后模以 N(槽的个数)，得到余数，这个就是 key 对应的槽，槽后面就 是 Redis 的实例。比如 4 个槽:Codis 的槽位映射关系是保存在 Proxy 中的，如果要解决单点的问题，Codis 也要做集群部署，多个Codis节点怎么同步槽和实例的关系呢?需要运行一个Zookeepe(r 或者 etcd/本地文件)。在新增节点的时候，可以为节点指定特定的槽位。Codis 也提供了自动均衡策略。Codis 不支持事务，其他的一些命令也不支持。不支持的命令https://github.com/CodisLabs/codis/blob/release3.2/doc/unsupported_cmds.md获取数据原理(mget):在 Redis 中的各个实例里获取到符合的 key，然后再汇总 到 Codis 中。Codis 是第三方提供的分布式解决方案，在官方的集群功能稳定之前，Codis 也得到 了大量的应用。 Redis Clusterhttps://redis.io/topics/cluster-tutorial/Redis Cluster 是在 Redis 3.0 的版本正式推出的，用来解决分布式的需求，同时也 可以实现高可用。跟 Codis 不一样，它是去中心化的，客户端可以连接到任意一个可用节点。数据分片有几个关键的问题需要解决: 数据怎么相对均匀地分片 客户端怎么访问到相应的节点和数据 重新分片的过程，怎么保证正常服务架构Redis Cluster 可以看成是由多个 Redis 实例组成的数据集合。客户端不需要关注数据的子集到底存储在哪个节点，只需要关注这个集合整体。以 3 主 3 从为例，节点之间两两交互，共享数据分片、节点状态等信息。数据分布如果是希望数据分布相对均匀的话，我们首先可以考虑哈希后取模。哈希后取模例如，hash(key)%N，根据余数，决定映射到那一个节点。这种方式比较简单，属于静态的分片规则。但是一旦节点数量变化，新增或者减少，由于取模的 N 发生变化，数据需要重新分布。为了解决这个问题，我们又有了一致性哈希算法。一致性哈希一致性哈希的原理:把所有的哈希值空间组织成一个虚拟的圆环(哈希环)，整个空间按顺时针方向组 织。因为是环形空间，0 和 2^32-1 是重叠的。假设我们有四台机器要哈希环来实现映射(分布数据)，我们先根据机器的名称或 者 IP 计算哈希值，然后分布到哈希环中(红色圆圈)。现在有 4 条数据或者 4 个访问请求，对 key 计算后，得到哈希环中的位置(绿色圆圈)。沿哈希环顺时针找到的第一个 Node，就是数据存储的节点。在这种情况下，新增了一个 Node5 节点，不影响数据的分布。删除了一个节点 Node4，只影响相邻的一个节点。谷歌的 MurmurHash 就是一致性哈希算法。在分布式系统中，负载均衡、分库分表 等场景中都有应用。一致性哈希解决了动态增减节点时，所有数据都需要重新分布的问题，它只会影响到下一个相邻的节点，对其他节点没有影响。但是这样的一致性哈希算法有一个缺点，因为节点不一定是均匀地分布的，特别是在节点数比较少的情况下，所以数据不能得到均匀分布。解决这个问题的办法是引入虚 拟节点(Virtual Node)。比如:2 个节点，5 条数据，只有 1 条分布到 Node2，4 条分布到 Node1，不均匀。Node1 设置了两个虚拟节点，Node2 也设置了两个虚拟节点(虚线圆圈)。 这时候有 3 条数据分布到 Node1，1 条数据分布到 Node2。Redis 虚拟槽分区Redis 既没有用哈希取模，也没有用一致性哈希，而是用虚拟槽来实现的。Redis 创建了 16384 个槽(slot)，每个节点负责一定区间的 slot。比如 Node1 负责 0-5460，Node2 负责 5461-10922，Node3 负责 10923-16383。Redis 的每个 master 节点维护一个 16384 位(2048bytes=2KB)的位序列，比如:序列的第 0 位是 1，代表第一个 slot 是它负责;序列的第 1 位是 0，代表第二个 slot 不归它负责。对象分布到 Redis 节点上时，对 key 用 CRC16 算法计算再%16384，得到一个 slot 的值，数据落到负责这个 slot 的 Redis 节点上。查看 key 属于哪个 slot:1redis&gt; cluster keyslot test 注意:key 与 slot 的关系是永远不会变的，会变的只有 slot 和 Redis 节点的关系。问题:怎么让相关的数据落到同一个节点上?比如有些 multi key 操作是不能跨节点的，如果要让某些数据分布到一个节点上，例 如用户 2673 的基本信息和金融信息，怎么办?在 key 里面加入{hash tag}即可。Redis 在计算槽编号的时候只会获取{}之间的字符 串进行槽编号计算，这样由于上面两个不同的键，{}里面的字符串是相同的，因此他们可 以被计算出相同的槽。 12set user&#123;2673&#125;base ... set user&#123;2673&#125;fin ... 问题:客户端连接到哪一台服务器?访问的数据不在当前节点上，怎么办?比如在 7291 端口的 Redis 的 redis-cli 客户端操作: 12127.0.0.1:7291&gt; set ts 1(error) MOVED 13724 127.0.0.1:7293 服务端返回 MOVED，也就是根据 key 计算出来的 slot 不归 7191 端口管理，而是 归 7293 端口管理，服务端返回 MOVED 告诉客户端去 7293 端口操作。这个时候更换端口，用 redis-cli –p 7293 操作，才会返回 OK。或者用./redis-cli -c -p port 的命令(c 代表 cluster)。这样客户端需要连接两次。Jedis 等客户端会在本地维护一份 slot——node 的映射关系，大部分时候不需要重 定向，所以叫做 smart jedis(需要客户端支持)。 数据迁移因为 key 和 slot 的关系是永远不会变的，当新增了节点的时候，需要把原有的 slot 分配给新的节点负责，并且把相关的数据迁移过来。添加新节点(新增一个 7297): 1redis-cli --cluster add-node 127.0.0.1:7291 127.0.0.1:7297 新增的节点没有哈希槽，不能分布数据，在原来的任意一个节点上执行: 1redis-cli --cluster reshard 127.0.0.1:7291 输入需要分配的哈希槽的数量(比如 500)，和哈希槽的来源节点(可以输入 all 或者 id)。 高可用和主从切换原理当 slave 发现自己的 master 变为 FAIL 状态时，便尝试进行 Failover，以期成为新 的 master。由于挂掉的 master 可能会有多个 slave，从而存在多个 slave 竞争成为 master 节点的过程， 其过程如下: slave 发现自己的 master 变为 FAIL 将自己记录的集群 currentEpoch 加 1，并广播 FAILOVER_AUTH_REQUEST 信息 其他节点收到该信息，只有 master 响应，判断请求者的合法性，并发送 FAILOVER_AUTH_ACK，对每一个 epoch 只发送一次 ack 尝试 failover 的 slave 收集 FAILOVER_AUTH_ACK 超过半数后变成新 Master 广播 Pong 通知其他集群节点。 Redis Cluster 既能够实现主从的角色分配，又能够实现主从切换，相当于集成了 Replication 和 Sentinal 的功能。 总结优势 无中心架构。 数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布。 可扩展性，可线性扩展到 1000 个节点(官方推荐不超过 1000 个)，节点可动态添加或删除。 高可用性，部分节点不可用时，集群仍可用。通过增加 Slave 做 standby 数据副本，能够实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制 完成 Slave 到 Master 的角色提升。 降低运维成本，提高系统的扩展性和可用性。 不足 Client 实现复杂，驱动要求实现 Smart Client，缓存 slots mapping 信息并及时 更新，提高了开发难度，客户端的不成熟影响业务的稳定性。 节点会因为某些原因发生阻塞(阻塞时间大于 clutser-node-timeout)，被判断下线，这种 failover 是没有必要的。 数据通过异步复制，不保证数据的强一致性。 多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现相互影响的情况。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[深入理解Redis-进阶篇]]></title>
    <url>%2F2019%2F11%2F19%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-%E8%BF%9B%E9%98%B6%E7%AF%87%2F</url>
    <content type="text"><![CDATA[发布订阅模式列表的局限前面我们说通过队列的 rpush 和 lpop 可以实现消息队列（队尾进队头出），但是消费者需要不停地调用 lpop 查看 List 中是否有等待处理的消息（比如写一个 while 循环）。为了减少通信的消耗，可以 sleep()一段时间再消费，但是会有两个问题： 如果生产者生产消息的速度远大于消费者消费消息的速度，List 会占用大量的内存。 消息的实时性降低。 list 还提供了一个阻塞的命令：blpop，没有任何元素可以弹出的时候，连接会被阻塞。基于 list 实现的消息队列，不支持一对多的消息分发。 发布/订阅模式除了通过 list 实现消息队列之外，Redis 还提供了一组命令实现发布/订阅模式。这种方式，发送者和接收者没有直接关联（实现了解耦），接收者也不需要持续尝试获取消息。 订阅频道首先，我们有很多的频道（channel），我们也可以把这个频道理解成 queue。订阅者可以订阅一个或者多个频道。消息的发布者（生产者）可以给指定的频道发布消息。只要有消息到达了频道，所有订阅了这个频道的订阅者都会收到这条消息。需要注意的注意是，发出去的消息不会被持久化，因为它已经从队列里面移除了，所以消费者只能收到它开始订阅这个频道之后发布的消息。下面我们来看一下发布订阅命令的使用方法。订阅者订阅频道：可以一次订阅多个，比如这个客户端订阅了 3 个频道 1subscribe channel-1 channel-2 channel-3 发布者可以向指定频道发布消息（并不支持一次向多个频道发送消息）： 1publish channel-1 2673 取消订阅（不能在订阅状态下使用）： 1unsubscribe channel-1 按规则（Pattern）订阅频道支持?和占位符。?代表一个字符，代表 0 个或者多个字符。消费端 1，关注运动信息: 1psubscribe *sport 消费端 2，关注所有新闻： 1psubscribe news* 消费端 3，关注天气新闻： 1psubscribe news-weather 生产者，发布 3 条信息 123publish news-sport yaomingpublish news-music jaychoupublish news-weather rain Redis事务为什么要用事务？我们知道 Redis 的单个命令是原子性的（比如 get set mget mset），如果涉及到多个命令的时候，需要把多个命令作为一个不可分割的处理序列，就需要用到事务。例如我们之前说的用 setnx 实现分布式锁，我们先 set，然后设置对 key 设置 expire，防止 del 发生异常的时候锁不会被释放，业务处理完了以后再 del，这三个动作我们就希望它们作为一组命令执行。Redis 的事务有两个特点： 按进入队列的顺序执行。 不会受到其他客户端的请求的影响。 Redis 的事务涉及到四个命令：multi（开启事务），exec（执行事务），discard（取消事务），watch（监视） 事务的用法通过 multi 的命令开启事务。事务不能嵌套，多个 multi 命令效果一样。 12345multiset k1 1set k2 2set k3 3exec multi 执行后，客户端可以继续向服务器发送任意多条命令， 这些命令不会立即被执行， 而是被放到一个队列中， 当 exec 命令被调用时， 所有队列中的命令才会被执行。通过 exec 的命令执行事务。如果没有执行 exec，所有的命令都不会被执行。如果中途不想执行事务了，怎么办？可以调用 discard 可以清空事务队列，放弃执行。 12345multiset k1 1set k2 2set k3 3discard watch 命令在 Redis 中还提供了一个 watch 命令。它可以为 Redis 事务提供 CAS 乐观锁行为（Check and Set / Compare and Swap），也就是多个线程更新变量的时候，会跟原值做比较，只有它没有被其他线程修改的情况下，才更新成新的值。我们可以用 watch 监视一个或者多个 key，如果开启事务之后，至少有一个被监视 key 键在 exec 执行之前被修改了， 那么整个事务都会被取消（key 提前过期除外）。可以用 unwatch 取消。 事务可能遇到的问题我们把事务执行遇到的问题分成两种，一种是在执行 exec 之前发生错误，一种是在执行 exec 之后发生错误。 在执行 exec 之前发生错误比如：入队的命令存在语法错误，包括参数数量，参数名等等（编译器错误）。 12345678127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set test 666QUEUED127.0.0.1:6379&gt; hset test1 2673(error) ERR wrong number of arguments for &apos;hset&apos; command127.0.0.1:6379&gt; exec(error) EXECABORT Transaction discarded because of previous errors 在这种情况下事务会被拒绝执行，也就是队列中所有的命令都不会得到执行。 在执行 exec 之后发生错误比如，类型错误，比如对 String 使用了 Hash 的命令，这是一种运行时错误。 12345678910111213127.0.0.1:6379&gt; flushallOK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set k1 1QUEUED127.0.0.1:6379&gt; hset k1 a bQUEUED127.0.0.1:6379&gt; exec1) OK2) (error) WRONGTYPE Operation against a key holding the wrong kind of value127.0.0.1:6379&gt; get k1&quot;1&quot; 最后我们发现 set k1 1 的命令是成功的，也就是在这种发生了运行时异常的情况下，只有错误的命令没有被执行，但是其他命令没有受到影响。这个显然不符合我们对原子性的定义，也就是我们没办法用 Redis 的这种事务机制来实现原子性，保证数据的一致。Redis这样做，主要是因为: 只有当发生语法错误(这个问题在命令队列时无法检测到)，Redis命令才会执行失败, 或对keys赋予了一个类型错误的数据：这意味着这些都是程序性错误，这类错误在开发的过程中就能够发现并解决掉，几乎不会出现在生产环境。 由于不需要回滚，这使得Redis内部更加简单，而且运行速度更快。 有种观点认为 Redis 处理事务的做法会产生 bug ， 然而需要注意的是， 在通常情况下， 回滚并不能解决编程错误带来的问题。 举个例子， 如果你本来想通过 INCR 命令将键的值加上 1 ， 却不小心加上了 2 ， 又或者对错误类型的键执行了 INCR ， 回滚是没有办法处理这些情况的。鉴于没有任何机制能避免程序员自己造成的错误， 并且这类错误通常不会在生产环境中出现， 所以 Redis 选择了更简单、更快速的无回滚方式来处理事务。 Lua脚本Lua/ˈluə/是一种轻量级脚本语言，它是用 C 语言编写的，跟数据的存储过程有点类似。 使用 Lua 脚本来执行 Redis 命令的好处： 一次发送多个命令，减少网络开销。 Redis 会将整个脚本作为一个整体执行，不会被其他请求打断，保持原子性。 对于复杂的组合命令，我们可以放在文件中，可以实现程序之间的命令集复用。在 Redis 中调用 Lua 脚本使用 eval /ɪ’væl/ 方法，语法格式：1redis&gt; eval lua-script key-num [key1 key2 key3 ....] [value1 value2 value3 ....] eval 代表执行 Lua 语言的命令。 lua-script 代表 Lua 语言脚本内容。 key-num 表示参数中有多少个 key，需要注意的是 Redis 中 key 是从 1 开始的，如果没有 key 的参数，那么写 0。 [key1 key2 key3…]是 key 作为参数传递给 Lua 语言，也可以不填，但是需要和 key-num 的个数对应起来。 [value1 value2 value3 ….]这些参数传递给 Lua 语言，它们是可填可不填的。 示例，返回一个字符串，0 个参数： 1redis&gt; eval &quot;return &apos;Hello World&apos;&quot; 0 在 Lua 脚本中调用 Redis 命令使用 redis.call(command, key [param1, param2…])进行操作。语法格式： 1redis&gt; eval &quot;redis.call(&apos;set&apos;,KEYS[1],ARGV[1])&quot; 1 lua-key lua-value command 是命令，包括 set、get、del 等。 key 是被操作的键。 param1,param2…代表给 key 的参数。 注意跟 Java 不一样，定义只有形参，调用只有实参。Lua 是在调用时用 key 表示形参，argv 表示参数值（实参）。 设置键值对在 Redis 中调用 Lua 脚本执行 Redis 命令 1redis&gt; eval &quot;return redis.call(&apos;set&apos;,KEYS[1],ARGV[1])&quot; 1 test 123 以上命令等价于 set test 123在 redis-cli 中直接写 Lua 脚本不够方便，也不能实现编辑和复用，通常我们会把脚本放在文件里面，然后执行这个文件。 Redis调用Lua脚本创建 Lua 脚本文件： 12345vim test.lua脚本内容：redis.call(&apos;set&apos;,&apos;test&apos;,&apos;1&apos;)return redis.call(&apos;get&apos;,&apos;test&apos;) 在 Redis 客户端中调用 Lua 脚本 1redis-cli --eval test.lua 0 得到返回值 1 案例：对 IP 进行限流需求：在 X 秒内只能访问 Y 次。设计思路：用 key 记录 IP，用 value 记录访问次数。拿到 IP 以后，对 IP+1。如果是第一次访问，对 key 设置过期时间（参数 1）。否则判断次数，超过限定的次数（参数 2），返回 0。如果没有超过次数则返回 1。超过时间，key 过期之后，可以再次访问。KEY[1]是 IP， ARGV[1]是过期时间 X，ARGV[2]是限制访问的次数 Y。 1234567891011-- ip_limit.lua-- IP 限流，对某个 IP 频率进行限制 ，6 秒钟访问 10 次local num=redis.call(&apos;incr&apos;,KEYS[1])if tonumber(num)==1 then redis.call(&apos;expire&apos;,KEYS[1],ARGV[1]) return 1 elseif tonumber(num)&gt;tonumber(ARGV[2]) then return 0 else return 1end 6 秒钟内限制访问 10 次，调用测试（连续调用 10 次）： 1./redis-cli --eval &quot;ip_limit.lua&quot; app:ip:limit:192.168.0.1 , 6 10 app:ip:limit:192.168.0.1 是 key 值 ，后面是参数值，中间要加上一个空格 和一个逗号，再加上一个 空格 。即：./redis-cli –eval [lua 脚本] [key…]空格,空格[args…] 多个参数之间用一个 空格 分割 。缓存 Lua 脚本在脚本比较长的情况下，如果每次调用脚本都需要把整个脚本传给 Redis 服务端，会产生比较大的网络开销。为了解决这个问题，Redis 提供了 EVALSHA 命令，允许开发者通过脚本内容的 SHA1 摘要来执行脚本。Redis 在执行 script load 命令时会计算脚本的 SHA1 摘要并记录在脚本缓存中，执行 EVALSHA 命令时 Redis 会根据提供的摘要从脚本缓存中查找对应的脚本内容，如果找到了则执行脚本，否则会返回错误：”NOSCRIPT No matching script. Please use EVAL.” 123127.0.0.1:6379&gt; script load &quot;return &apos;Hello World&apos;&quot;&quot;470877a599ac74fbfda41caa908de682c5fc7d4b&quot; 127.0.0.1:6379&gt; evalsha &quot;470877a599ac74fbfda41caa908de682c5fc7d4b&quot; 0&quot;Hello World&quot; 脚本超时Redis 的指令执行本身是单线程的，这个线程还要执行客户端的 Lua 脚本，如果 Lua 脚本执行超时或者陷入了死循环，是不是没有办法为客户端提供服务了呢？ 1eval &apos;while(true) do end&apos; 0 为 了防 止 某个 脚本 执 行时 间 过长 导 致 Redis 无 法提 供 服务 ， Redis 提 供 了 lua-time-limit 参数限制脚本的最长运行时间，默认为 5 秒钟。 1lua-time-limit 5000（redis.conf 配置文件中） 当脚本运行时间超过这一限制后，Redis 将开始接受其他命令但不会执行（以确保脚本的原子性，因为此时脚本并没有被终止），而是会返回“BUSY”错误。Redis 提供了一个 script kill 的命令来中止脚本的执行。新开一个客户端： 1script kill 如果当前执行的 Lua 脚本对 Redis 的数据进行了修改（SET、DEL 等），那么通过 script kill 命令是不能终止脚本运行的。 1eval &quot;redis.call(&apos;set&apos;,&apos;gupao&apos;,&apos;666&apos;) while true do end&quot; 0 因为要保证脚本运行的原子性，如果脚本执行了一部分终止，那就违背了脚本原子性的要求。最终要保证脚本要么都执行，要么都不执行。遇到这种情况，只能通过 shutdown nosave 命令来强行终止 redis。shutdown nosave 和 shutdown 的区别在于 shutdown nosave 不会进行持久化操作，意味着发生在上一次快照后的数据库修改都会丢失。Redis 不是只有一个线程吗？它已经卡死了，怎么接受 spript kill 指令的？Redis 单线程指的是网络请求模块使用了一个线程（所以不需考虑并发安全性），即一个线程处理所有网络请求，其他模块仍用了多个线程。总结：如果我们有一些特殊的需求，可以用 Lua 来实现，但是要注意那些耗时的操作。 Redis 为什么这么快？进入Redis安装目录的src文件夹下，执行 1redis-benchmark -t set,lpush -n 100000 -q 结果（本地虚拟机）：SET: 51813.47 requests per second —— 每秒钟处理 5 万多次 set 请求LPUSH: 51706.31 requests per second —— 每秒钟处理 5 万多次 lpush 请求 1redis-benchmark -n 100000 -q script load &quot;redis.call(&apos;set&apos;,&apos;foo&apos;,&apos;bar&apos;)&quot; 结果（本地虚拟机）：script load redis.call(‘set’,’foo’,’bar’): 46816.48 requests per second —— 每秒钟 46000 次 lua 脚本调用 横轴：连接数；纵轴：QPS 根据官方的数据，Redis 的 QPS 可以达到 10 万左右（每秒请求数）。 Redis为什么这么快？ 纯内存结构 单线程 多路复用 内存KV 结构的内存数据库，时间复杂度 O(1)。 单线程要实现这么高的并发性能，是不是要创建非常多的线程？恰恰相反，Redis 是单线程的。单线程有什么好处呢？ 没有创建线程、销毁线程带来的消耗 避免了上线文切换导致的 CPU 消耗 避免了线程之间带来的竞争问题，例如加锁释放锁死锁等等 Redis为什么是单线程的？不是白白浪费了 CPU 的资源吗？因为单线程已经够用了，CPU 不是 redis 的瓶颈。Redis 的瓶颈最有可能是机器内存或者网络带宽。既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了。 异步非阻塞异步非阻塞 I/O，多路复用处理并发连接。 单线程为什么这么快？因为 Redis 是基于内存的操作，我们先从内存开始说起。 虚拟存储器（虚拟内存 Vitual Memory）名词解释：主存：内存；辅存：磁盘（硬盘） 计算机主存（内存）可看作一个由 M 个连续的字节大小的单元组成的数组，每个字节有一个唯一的地址，这个地址叫做物理地址（PA）。早期的计算机中，如果 CPU 需要内存，使用物理寻址，直接访问主存储器。这种方式有几个弊端： 在多用户多任务操作系统中，所有的进程共享主存，如果每个进程都独占一块物理地址空间，主存很快就会被用完。我们希望在不同的时刻，不同的进程可以共用同一块物理地址空间。 如果所有进程都是直接访问物理内存，那么一个进程就可以修改其他进程的内存数据，导致物理地址空间被破坏，程序运行就会出现异常。 为了解决这些问题，我们就想了一个办法，在 CPU 和主存之间增加一个中间层。CPU不再使用物理地址访问，而是访问一个虚拟地址，由这个中间层把地址转换成物理地址，最终获得数据。这个中间层就叫做虚拟存储器（Virtual Memory）。在每一个进程开始创建的时候，都会分配一段虚拟地址，然后通过虚拟地址和物理地址的映射来获取真实数据，这样进程就不会直接接触到物理地址，甚至不知道自己调用的哪块物理地址的数据。目前，大多数操作系统都使用了虚拟内存，如 Windows 系统的虚拟内存、Linux 系统的交换空间等等。Windows 的虚拟内存（pagefile.sys）是磁盘空间的一部分。在 32 位的系统上，虚拟地址空间大小是 2^32bit=4G。在 64 位系统上，最大虚拟地址空间大小是多少？是不是 2^64bit=1024*1014TB=1024PB=16EB？实际上没有用到 64 位，因为用不到这么大的空间，而且会造成很大的系统开销。Linux 一般用低 48 位来表示虚拟地址空间，也就是 2^48bit=256T。 总结：引入虚拟内存，可以提供更大的地址空间，并且地址空间是连续的，使得程序编写、链接更加简单。并且可以对物理内存进行隔离，不同的进程操作互不影响。还可以通过把同一块物理内存映射到不同的虚拟地址空间实现内存共享。 用户空间和内核空间为了避免用户进程直接操作内核，保证内核安全，操作系统将虚拟内存划分为两部分，一部分是内核空间（Kernel-space），一部分是用户空间（User-space）。内核是操作系统的核心，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的权限。内核空间中存放的是内核代码和数据，而进程的用户空间中存放的是用户程序的代码和数据。不管是内核空间还是用户空间，它们都处于虚拟空间中，都是对物理地址的映射。在 Linux 系统中, 内核进程和用户进程所占的虚拟内存比例是 1:3。当进程运行在内核空间时就处于内核态，而进程运行在用户空间时则处于用户态。进程在内核空间以执行任意命令，调用系统的一切资源；在用户空间只能执行简单的运算，不能直接调用系统资源，必须通过系统接口（又称 system call），才能向内核发出指令。 top命令：us 代表 CPU 消耗在 User space 的时间百分比;sy 代表 CPU 消耗在 Kernel space 的时间百分比。 进程切换（上下文切换）多任务操作系统是怎么实现运行远大于 CPU 数量的任务个数的？当然，这些任务实际上并不是真的在同时运行，而是因为系统通过时间片分片算法，在很短的时间内，将 CPU 轮流分配给它们，造成多任务同时运行的错觉。为了控制进程的执行，内核必须有能力挂起正在 CPU 上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。 什么叫上下文？ 在每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要系统事先帮它设置好 CPU 寄存器和程序计数器(Program Counter)，这个叫做CPU 的上下文。而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。在切换上下文的时候，需要完成一系列的工作，这是一个很消耗资源的操作。 进程的阻塞正在运行的进程由于提出系统服务请求（如 I/O 操作），但因为某种原因未得到操作系统的立即响应，该进程只能把自己变成阻塞状态，等待相应的事件出现后才被唤醒。进程在阻塞状态不占用 CPU 资源。 文件描述符 FDLinux 系统将所有设备都当作文件来处理，而 Linux 用文件描述符来标识每个文件对象。文件描述符（File Descriptor）是内核为了高效管理已被打开的文件所创建的索引，用于指向被打开的文件，所有执行 I/O 操作的系统调用都通过文件描述符；文件描述符是一个简单的非负整数，用以表明每个被进程打开的文件。Linux 系统里面有三个标准文件描述符。0：标准输入（键盘）；1：标准输出（显示器）；2：标准错误输出（显示器）。 传统 I/O 数据拷贝当应用程序执行 read 系统调用读取文件描述符（FD）的时候，如果这块数据已经存在于用户进程的页内存中，就直接从内存中读取数据。如果数据不存在，则先将数据从磁盘加载数据到内核缓冲区中，再从内核缓冲区拷贝到用户进程的页内存中。（两次拷贝，两次 user 和 kernel 的上下文切换）。 Blocking I/O当使用 read 或 write 对某个文件描述符进行过读写时，如果当前 FD 不可读，系统就不会对其他的操作做出响应。从设备复制数据到内核缓冲区是阻塞的，从内核缓冲区拷贝到用户空间，也是阻塞的，直到 copy complete，内核返回结果，用户进程才解除 block 的状态。I/O 的阻塞是指等待数据和从内核空间复制数据到用户空间两个步骤上。 为了解决阻塞的问题，我们有几个思路。 在服务端创建多个线程或者使用线程池，但是在高并发的情况下需要的线程会很多，系统无法承受，而且创建和释放线程都需要消耗资源。 由请求方定期轮询，在数据准备完毕后再从内核缓存缓冲区复制数据到用户空间（非阻塞式 I/O），这种方式会存在一定的延迟。 I/O 多路复用（I/O Multiplexing）I/O 指的是网络 I/O。多路指的是多个 TCP 连接（Socket 或 Channel）。复用指的是复用一个或多个线程。它的基本原理就是不再由应用程序自己监视连接，而是由内核替应用程序监视文件描述符。客户端在操作的时候，会产生具有不同事件类型的 socket。在服务端，I/O 多路复用程序（I/O Multiplexing Module）会把消息放入队列中，然后通过文件事件分派器（File event Dispatcher），转发到不同的事件处理器中。多路复用有很多的实现，以 select 为例，当用户进程调用了多路复用器，进程会被阻塞。内核会监视多路复用器负责的所有 socket，当任何一个 socket 的数据准备好了，多路复用器就会返回。这时候用户进程再调用 read 操作，把数据从内核缓冲区拷贝到用户空间。所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪（readable）状态，select()函数就可以返回。Redis 的多路复用， 提供了 select, epoll, evport, kqueue 几种选择，在编译的时候来选择一种。evport 是 Solaris 系统内核提供支持的；epoll 是 LINUX 系统内核提供支持的；kqueue 是 Mac 系统提供支持的；select 是 POSIX 提供的，一般的操作系统都有支撑（保底方案）；源码 ae_epoll.c、ae_select.c、ae_kqueue.c、ae_evport.c 内存回收Reids 所有的数据都是存储在内存中的，在某些情况下需要对占用的内存空间进行回收。内存回收主要分为两类，一类是 key 过期，一类是内存使用达到上限（max_memory）触发内存淘汰。 过期策略定时过期（主动淘汰）每个设置过期时间的 key 都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的 CPU 资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。 惰性过期（被动淘汰）只有当访问一个 key 时，才会判断该 key 是否已过期，过期则清除。该策略可以最大化地节省 CPU 资源，却对内存非常不友好。极端情况可能出现大量的过期 key 没有再次被访问，从而不会被清除，占用大量内存。第二种情况，每次写入 key 时，发现内存不够，调用 activeExpireCycle 释放一部分内存。 定期过期每隔一定的时间，会扫描一定数量的数据库的 expires 字典中一定数量的 key，并清除其中已过期的 key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得 CPU 和内存资源达到最优的平衡效果。Redis 中同时使用了惰性过期和定期过期两种过期策略。 淘汰策略Redis 的内存淘汰策略，是指当内存使用达到最大内存极限时，需要使用淘汰算决定清理掉哪些数据，以保证新数据的存入。 最大内存设置redis.conf 参数配置： 1# maxmemory &lt;bytes&gt; 如果不设置 maxmemory 或者设置为 0，64 位系统不限制内存，32 位系统最多使用 3GB 内存。动态修改： 1redis&gt; config set maxmemory 2GB 策略类型redis.conf 淘汰策略设置：maxmemory-policy noeviction 12345678volatile-lru -&gt; Evict using approximated LRU among the keys with an expire set. allkeys-lru -&gt; Evict any key using approximated LRU. volatile-lfu -&gt; Evict using approximated LFU among the keys with an expire set. allkeys-lfu -&gt; Evict any key using approximated LFU. volatile-random -&gt; Remove a random key among the ones with an expire set. allkeys-random -&gt; Remove a random key, any key. volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)noeviction -&gt; Don&apos;t evict anything, just return an error on write operations. LRU，Least Recently Used：最近最少使用。判断最近被使用的时间，目前最远的数据优先被淘汰。LFU，Least Frequently Used，最不常用，4.0 版本新增。random，随机删除。 策略 含义 volatile-lru 根据 LRU 算法删除设置了超时属性（expire）的键，直到腾出足够内存为止。如果没有可删除的键对象，回退到 noeviction 策略。 allkeys-lru 根据 LRU 算法删除键，不管数据有没有设置超时属性，直到腾出足够内存为止。 volatile-lfu 在带有过期时间的键中选择最不常用的。 allkeys-lfu 在所有的键中选择最不常用的，不管数据有没有设置超时属性。 volatile-random 在带有过期时间的键中随机选择。 allkeys-random 随机删除所有键，直到腾出足够内存为止。 volatile-ttl 根据键值对象的 ttl 属性，删除最近将要过期数据。如果没有，回退到 noeviction 策略。 noeviction 默认策略，不会删除任何数据，拒绝所有写入操作并返回客户端错误信息（error）OOM command not allowed when used memory，此时 Redis 只响应读操作。 如果没有符合前提条件的 key 被淘汰，那么 volatile-lru、volatile-random 、volatile-ttl 相当于 noeviction（不做内存回收）。 动态修改淘汰策略： 1redis&gt; config set maxmemory-policy volatile-lru 建议使用 volatile-lru，在保证正常服务的情况下，优先删除最近最少使用的 key。 LRU 淘汰原理如果基于传统 LRU 算法实现 Redis LRU 会有什么问题？ 需要额外的数据结构存储，消耗内存。 Redis LRU 对传统的 LRU 算法进行了改良，通过随机采样来调整算法的精度。 如果淘汰策略是 LRU，则根据配置的采样值maxmemory_samples（默认是 5 个）, 随机从数据库中选择 m 个 key, 淘汰其中热度最低的 key 对应的缓存数据。所以采样参数m配置的数值越大, 就越能精确的查找到待淘汰的缓存数据,但是也消耗更多的CPU计算,执行效率降低。 如何找出热度最低的数据？Redis 中所有对象结构都有一个 lru 字段, 且使用了 unsigned 的低 24 位，这个字段用来记录对象的热度。对象被创建时会记录 lru 值。在被访问的时候也会更新 lru 的值。但是不是获取系统当前的时间戳，而是设置为全局变量 server.lruclock 的值。 123456789 typedef struct redisObject &#123; unsigned type:4; unsigned encoding:4; unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or * LFU data (least significant 8 bits frequency * and most significant 16 bits access time). */ int refcount; void *ptr;&#125; robj; server.lruclock 的值怎么来的？Redis 中 有 个 定 时 处 理 的 函 数serverCron ， 默 认 每 100 毫 秒 调 用 函数 updateCachedTime 更新一次全局变量的 server.lruclock 的值，它记录的是当前 unix时间戳。 为什么不获取精确的时间而是放在全局变量中？不会有延迟的问题吗？这样函数 lookupKey 中更新数据的 lru 热度值时,就不用每次调用系统函数 time，可以提高执行效率 函数 estimateObjectIdleTime 评估指定对象的 lru 热度，思想就是对象的 lru 值和全局的 server.lruclock 的差值越大（越久没有得到更新）， 该对象热度越低。 为什么不用常规的哈希表+双向链表的方式实现？需要额外的数据结构，消耗资源。而 Redis LRU 算法在 sample 为 10 的情况下，已经能接近传统 LRU 算法了。 除了消耗资源之外，传统 LRU 还有什么问题？如图，假设 A 在 10 秒内被访问了 5 次，而 B 在 10 秒内被访问了 3 次。因为 B 最后一次被访问的时间比 A 要晚，在同等的情况下，A 反而先被回收。 LFU 淘汰原理 123456789 typedef struct redisObject &#123; unsigned type:4; unsigned encoding:4; unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or * LFU data (least significant 8 bits frequency * and most significant 16 bits access time). */ int refcount; void *ptr;&#125; robj; 当这 24 bits 用作 LFU 时，其被分为两部分： 高 16 位用来记录访问时间（单位为分钟，ldt，last decrement time） 低 8 位用来记录访问频率，简称 counter（logc，logistic counter） counter 是用基于概率的对数计数器实现的，8 位可以表示百万次的访问频率。对象被读写的时候，lfu 的值会被更新。 12345void updateLFU(robj *val) &#123; unsigned long counter = LFUDecrAndReturn(val); counter = LFULogIncr(counter); val-&gt;lru = (LFUGetTimeInMinutes()&lt;&lt;8) | counter;&#125; 增长的速率由，lfu-log-factor 越大，counter 增长的越慢redis.conf 配置文件 1# lfu-log-factor 10 如果计数器只会递增不会递减，也不能体现对象的热度。没有被访问的时候，计数器怎么递减呢？减少的值由衰减因子 lfu-decay-time（分钟）来控制，如果值是 1 的话，N 分钟没有访问就要减少 N。redis.conf 配置文件 1# lfu-decay-time 1 持久化机制Redis 速度快，很大一部分原因是因为它所有的数据都存储在内存中。如果断电或者宕机，都会导致内存中的数据丢失。为了实现重启后数据不丢失，Redis 提供了两种持久化的方案，一种是 RDB 快照（Redis DataBase），一种是 AOF（Append Only File）。 RDBRDB 是 Redis 默认的持久化方案。当满足一定条件的时候，会把当前内存中的数据写入磁盘，生成一个快照文件 dump.rdb。Redis 重启会通过加载 dump.rdb 文件恢复数据。 自动触发redis.conf， SNAPSHOTTING，其中定义了触发把数据保存到磁盘的触发频率。如果不需要 RDB 方案，注释 save 或者配置成空字符串””。 123save 900 1 # 900 秒内至少有一个 key 被修改（包括添加）save 300 10 # 400 秒内至少有 10 个 key 被修改save 60 10000 # 60 秒内至少有 10000 个 key 被修改 注意上面的配置是不冲突的，只要满足任意一个都会触发。RDB 文件位置和目录： 12345678# 文件路径，dir ./# 文件名称dbfilename dump.rdb# 是否是 LZF 压缩 rdb 文件rdbcompression yes# 开启数据校验rdbchecksum yes 参数 说明 dir rdb 文件默认在启动目录下（相对路径） config get dir 获取 dbfilename 文件名称 rdbcompression 开启压缩可以节省存储空间，但是会消耗一些 CPU 的计算时间，默认开启 rdbchecksum 使用 CRC64 算法来进行数据校验，但是这样做会增加大约 10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。 为什么停止 Redis 服务的时候没有 save，重启数据还在？RDB 还有两种触发方式： shutdown 触发，保证服务器正常关闭。 flushall，RDB 文件是空的，没什么意义（删掉 dump.rdb 演示一下）。手动触发如果我们需要重启服务或者迁移数据，这个时候就需要手动触 RDB 快照保存。Redis提供了两条命令：a）savesave 在生成快照的时候会阻塞当前 Redis 服务器， Redis 不能处理其他命令。如果内存中的数据比较多，会造成 Redis 长时间的阻塞。生产环境不建议使用这个命令。为了解决这个问题，Redis 提供了第二种方式。b）bgsave执行 bgsave 时，Redis 会在后台异步进行快照操作，快照同时还可以响应客户端请求。 具体操作是 Redis 进程执行 fork 操作创建子进程（copy-on-write），RDB 持久化过程由子进程负责，完成后自动结束。它不会记录 fork 之后后续的命令。阻塞只发生在 fork 阶段，一般时间很短。用 lastsave 命令可以查看最近一次成功生成快照的时间。 RDB 数据的恢复可以通过将 dump.rdb 放到指定位置，即可恢复备份的数据。 RDB 文件的优势和劣势优势 RDB 是一个非常紧凑(compact)的文件，它保存了 redis 在某个时间点上的数据集。这种文件非常适合用于进行备份和灾难恢复。 生成 RDB 文件的时候，redis 主进程会 fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘 IO 操作。 RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 劣势 RDB 方式数据没办法做到实时持久化/秒级持久化。因为 bgsave 每次运行都要执行 fork 操作创建子进程，频繁执行成本过高。 在一定间隔时间做一次备份，所以如果 redis 意外 down 掉的话，就会丢失最后一次快照之后的所有修改（数据有丢失）。 如果数据相对来说比较重要，希望将损失降到最小，则可以使用 AOF 方式进行持久化。 AOFAOF：Redis 默认不开启。AOF 采用日志的形式来记录每个写操作，并追加到文件中。开启后，执行更改 Redis 数据的命令时，就会把命令写入到 AOF 文件中。Redis 重启时会根据日志文件的内容把写指令从前到后执行一次以完成数据的恢复工作。 AOF 配置配置文件 redis.conf 1234# 开关appendonly no# 文件名appendfilename &quot;appendonly.aof&quot; 参数 说明 appendonly Redis 默认只开启 RDB 持久化，开启 AOF 需要修改为 yes appendfilename “appendonly.aof” 路径也是通过 dir 参数配置 config get dir 数据都是实时持久化到磁盘吗？由于操作系统的缓存机制，AOF 数据并没有真正地写入硬盘，而是进入了系统的硬盘缓存。什么时候把缓冲区的内容写入到 AOF 文件？配置文件 redis.conf 1appendfsync everysec AOF 持久化策略（硬盘缓存到磁盘），默认 everysec no 表示不执行 fsync，由操作系统保证数据同步到磁盘，速度最快，但是不太安全； always 表示每次写入都执行 fsync，以保证数据同步到磁盘，效率很低； everysec 表示每秒执行一次 fsync，可能会导致丢失这 1s 数据。通常选择 everysec ，兼顾安全性和效率。 “appendonly.aof” 文件越来越大，怎么办？由于 AOF 持久化是 Redis 不断将写命令记录到 AOF 文件中，随着 Redis 不断的进行，AOF 的文件会越来越大，文件越大，占用服务器内存越大以及 AOF 恢复要求时间越长。例如 set gupao 666，执行 1000 次，结果都是 gupao=666。为了解决这个问题，Redis 新增了重写机制，当 AOF 文件的大小超过所设定的阈值时，Redis 就会启动 AOF 文件的内容压缩，只保留可以恢复数据的最小指令集。可以使用命令 bgrewriteaof 来重写。AOF 文件重写并不是对原文件进行重新整理，而是直接读取服务器现有的键值对，然后用一条命令去代替之前记录这个键值对的多条命令，生成一个新的文件后去替换原来的 AOF 文件。 123# 重写触发机制auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb 参数 说明 auto-aof-rewrite-percentage 默认值为 100。aof 自动重写配置，当目前 aof 文件大小超过上一次重写的 aof 文件大小的百分之多少进行重写，即当 aof 文件增长到一定大小的时候，Redis 能够调用 bgrewriteaof 对日志文件进行重写。当前 AOF 文件大小是上次日志重写得到 AOF 文件大小的二倍（设置为 100）时，自动启动新的日志重写过程。 auto-aof-rewrite-min-size 默认 64M。设置允许重写的最小 aof 文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写。 重写过程中，AOF 文件被更改了怎么办？ 另外有两个与 AOF 相关的参数：|参数| 说明|| — | — ||no-appendfsync-on-rewrite|在 aof 重写或者写入 rdb 文件的时候，会执行大量 IO，此时对于 everysec 和 always 的 aof模式来说，执行 fsync 会造成阻塞过长时间，no-appendfsync-on-rewrite 字段设置为默认设置为 no。如果对延迟要求很高的应用，这个字段可以设置为 yes，否则还是设置为 no，这样对持久化特性来说这是更安全的选择。设置为 yes 表示 rewrite 期间对新写操作不 fsync, 暂时存在内存中,等 rewrite 完成后再写入，默认为 no，建议修改为 yes。Linux 的默认 fsync策略是 30 秒。可能丢失 30 秒数据。|| aof-load-truncated |aof 文件可能在尾部是不完整的，当 redis 启动的时候，aof 文件的数据被载入内存。重启可能发生在 redis 所在的主机操作系统宕机后，尤其在 ext4 文件系统没有加上 data=ordered 选项，出现这种现象。redis 宕机或者异常终止不会造成尾部不完整现象，可以选择让 redis 退出，或者导入尽可能多的数据。如果选择的是 yes，当截断的 aof 文件被导入的时候，会自动发布一个 log 给客户端然后 load。如果是 no，用户必须手动 redis-check-aof 修复 AOF 文件才可以。默认值为 yes。| AOF 数据恢复重启 Redis 之后就会进行 AOF 文件的恢复。 AOF 优势与劣势优势 AOF 持久化的方法提供了多种的同步频率，即使使用默认的同步频率每秒同步一次，Redis 最多也就丢失 1 秒的数据而已。 劣势 对于具有相同数据的的 Redis，AOF 文件通常会比 RDF 文件体积更大（RDB存的是数据快照）。 虽然 AOF 提供了多种同步的频率，默认情况下，每秒同步一次的频率也具有较高的性能。在高并发的情况下，RDB 比 AOF 具好更好的性能保证。 两种方案比较那么对于 AOF 和 RDB 两种持久化方式，我们应该如何选择呢？如果可以忍受一小段时间内数据的丢失，毫无疑问使用 RDB 是最好的，定时生成RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快。否则就使用 AOF 重写。但是一般情况下建议不要单独使用某一种持久化机制，而是应该两种一起用，在这种情况下,当 redis 重启的时候会优先载入 AOF 文件来恢复原始的数据，因为在通常情况下 AOF 文件保存的数据集要比 RDB 文件保存的数据集要完整。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[深入理解Redis-基础篇]]></title>
    <url>%2F2019%2F11%2F18%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-%E5%9F%BA%E7%A1%80%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Redis介绍硬件层面有 CPU 的缓存;浏览器也有缓存;手机的应用也有缓存。我们把数据缓存起来的原因就是从原始位置取数据的代价太大了，放在一个临时位置存储起来，取回就可以快一些。 Redis特性 支持多种编程语言 高可用、支持集群 能够存储丰富的数据类型 可以实现跨进程、服务器实现数据共享 功能丰富：支持持久化机制、过期策略等 Redis数据类型Redis一共有8种数据类型： String Hash Set List Zset BitMap Hyperloglog Geo Streams 接下来我们深入分析每一种数据类型。 String（字符串）存储类型可以用来存储字符串、整数、浮点数。 常见的操作设置单个值 1set key value 设置多个值(批量操作，原子性) 1mset key1 value1 key2 value2 删除值 1del key 基于此可实现分布式锁，用 del key 释放锁。 但如果释放锁的操作失败了，导致其他节点永远获取不到锁，怎么办? 加过期时间。单独用 expire 加过期，也失败了，无法保证原子性，怎么办?可以使用多参数 1234set key value [expiration EX seconds|PX milliseconds][NX|XX]使用参数的方式set lock 1 EX 10 NX (整数)值递增 12incr key incrby key 100 (整数)值递减 12decr key decrby key 100 浮点数增量 1incrbyfloat key 7.3 获取多个值 1mget key1 key2 获取值长度 1strlen key 字符串追加内容 1append key content 获取指定范围的字符 1getrange key 0 8 数据模型set hello word 为例，因为 Redis 是 KV 的数据库，它是通过 hashtable 实现的(我们把这个叫做外层的哈希)。所以每个键值对都会有一个 dictEntry(源码位置:dict.h)， 里面指向了 key 和 value 的指针。next 指向下一个 dictEntry。 12345678typedef struct dictEntry &#123; void *key; /* key 关键字定义 */ union &#123; void *val; uint64_t u64; /* value 定义 */ int64_t s64; double d; &#125; v; struct dictEntry *next; /* 指向下一个键值对节点 */&#125; dictEntry; key 是字符串，但是 Redis 没有直接使用 C 的字符数组，而是存储在自定义的 SDS 中。value 既不是直接作为字符串存储，也不是直接存储在 SDS 中，而是存储在 redisObject 中。实际上五种常用的数据类型的任何一种，都是通过 redisObject 来存储的。 redisObjectredisObject 定义在 src/server.h 文件中。 123456typedef struct redisObject &#123; unsigned type:4; /* 对象的类型，包括:OBJ_STRING、OBJ_LIST、OBJ_HASH、OBJ_SET、OBJ_ZSET */ unsigned encoding:4; /* 具体的数据结构 */ unsigned lru:LRU_BITS; /* 24 位，对象最后一次被命令程序访问的时间，与内存回收有关 */ int refcount; /* 引用计数。当 refcount 为 0 的时候，表示该对象已经不被任何对象引用，则可以进行垃圾回收了*/ void *ptr; /* 指向对象实际的数据结构 */&#125; robj; 可以使用 type 命令来查看对外的类型。 1type key 内部编码 1object encoding key 字符串类型的内部编码有三种: int，存储 8 个字节的长整型(long，2^63-1)。 embstr, 代表 embstr 格式的 SDS(Simple Dynamic String 简单动态字符串)，存储小于 44 个字节的字符串。 raw，存储大于 44 个字节的字符串(3.2 版本之前是 39 字节)。 SDSRedis 中字符串的实现。在 3.2 以后的版本中，SDS 又有多种结构(sds.h):sdshdr5、sdshdr8、sdshdr16、sdshdr32、sdshdr64，用于存储不同的长度的字符串，分别代表 2^5=32byte， 2^8=256byte，2^16=65536byte=64KB，2^32byte=4GB。 1234567/* sds.h */struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; /* 当前字符数组的长度 */ uint8_t alloc; /*当前字符数组总共分配的内存大小 */ unsigned char flags; /* 当前字符数组的属性、用来标识到底是 sdshdr8 还是 sdshdr16 等 */ char buf[]; /* 字符串真正的值 */&#125;; SDS 的特点: 不用担心内存溢出问题，如果需要会对 SDS 进行扩容。 获取字符串长度时间复杂度为 O(1)，因为定义了 len 属性。 通过“空间预分配”( sdsMakeRoomFor)和“惰性空间释放”，防止多次重分配内存。 判断是否结束的标志是 len 属性(它同样以’\0’结尾是因为这样就可以使用 C语言中函数库操作字符串的函数了)，可以包含’\0’。 数据类型int 什么时候转化为 raw? 当 int 类型被数据被修改为不再是整数或大小超过了 long 的范围 (2^63-1=9223372036854775807)时，自动转化为 raw。 embstr 和 raw 的区别? embstr 的使用只分配一次内存空间(因为 RedisObject 和 SDS 是连续的)，而 raw 需要分配两次内存空间(分别为 RedisObject 和 SDS 分配空间)。 因此与 raw 相比，embstr 的好处在于创建时少分配一次空间，删除时少释放一次空间，以及对象的所有数据连在一起，寻找方便。 而 embstr 的坏处也很明显，如果字符串的长度增加需要重新分配内存时，整个 RedisObject 和 SDS 都需要重新分配空间。因此 Redis 中的 embstr 实现为只读，只要进行修改就会转换为 raw，无论是否达到了 44 个字节。 当长度小于阈值时，会还原吗? Redis 内部编码的转换，都符合以下规律:编码转换在 Redis 写入数据时完 成，且转换过程不可逆，只能从小内存编码向大内存编码转换(但是不包括重新 set)。 为什么要对底层的数据结构进行一层包装呢? 通过封装，可以根据对象的类型动态地选择存储结构和可以使用的命令，实现节省空间和优化查询速度。应用场景 缓存 数据共享 分布式锁 全局ID 计数器 限流 Hash（哈希）存储类型包含键值对的无序散列表。value 只能是字符串，不能嵌套其他类型。 同样是存储字符串，Hash 与 String 的主要区别? 把所有相关的值聚集到一个 key 中，节省内存空间 只使用一个 key，减少 key 冲突 当需要批量获取值的时候，只需要使用一个命令，减少内存/IO/CPU 的消耗 Hash 不适合的场景: Field 不能单独设置过期时间 没有 bit 操作 需要考虑数据量分布的问题(value 值非常大的时候，无法分布到多个节点)常用命令123456789101112131415161718192021222324252627282930单个设置值：hset h1 f 6hset h1 e 5批量设置值：hmset h1 a 1 b 2 c 3 d 4获取单个值：hget h1 a批量获取值：hmget h1 a b c d 获取所有key：hkeys h1获取所有value：hvals h1获取所有值：hgetall h1判断哈希是否存在：hget exists h1 删除哈希：hdel h1获取哈希长度：hlen h1 存储原理Redis 的 Hash 本身也是一个 KV 的结构，类似于 Java 中的 HashMap。外层的哈希(Redis KV 的实现)只用到了 hashtable。当存储 hash 数据类型时， 我们把它叫做内层的哈希。内层的哈希底层可以使用两种数据结构实现:ziplist:OBJ_ENCODING_ZIPLIST(压缩列表) hashtable:OBJ_ENCODING_HT(哈希表) ziplist 压缩列表ziplist 是一个经过特殊编码的双向链表，它不存储指向上一个链表节点和指向下一个链表节点的指针，而是存储上一个节点长度和当前节点长度，通过牺牲部分读写性能，来换取高效的内存空间利用率，是一种时间换空间的思想。只用在字段个数少，字段值小的场景里面。 ziplist的内部结构 123456789typedef struct zlentry &#123; unsigned int prevrawlensize; /* 上一个链表节点占用的长度 */ unsigned int prevrawlen; /* 存储上一个链表节点的长度数值所需要的字节数 */ unsigned int lensize; /* 存储当前链表节点长度数值所需要的字节数 */ unsigned int len; /* 当前链表节点占用的长度 */ unsigned int headersize; /* 当前链表节点的头部大小(prevrawlensize + lensize)，即非数据域的大小 */ unsigned char encoding;/* 编码方式 */ unsigned char *p;/* 压缩链表以字符串的形式保存，该指针指向当前节点起始位置 */&#125; zlentry; 编码 encoding #define ZIP_STR_06B (0 &lt;&lt; 6) //长度小于等于 63 字节 #define ZIP_STR_14B (1 &lt;&lt; 6) //长度小于等于 16383 字节 #define ZIP_STR_32B (2 &lt;&lt; 6) //长度小于等于 4294967295 字节 什么时候使用 ziplist 存储?当 hash 对象同时满足以下两个条件的时候，使用 ziplist 编码: 所有的键值对的健和值的字符串长度都小于等于 64byte(一个英文字母一个字节); 哈希对象保存的键值对数量小于 512 个。 一个哈希对象超过配置的阈值(键和值的长度有&gt;64byte，键值对个数&gt;512 个)时， 会转换成哈希表(hashtable)。 hashtable(dict)在 Redis 中，hashtable 被称为字典(dictionary)，它是一个数组+链表的结构。前面我们知道了，Redis 的 KV 结构是通过一个 dictEntry 来实现的。Redis 又对 dictEntry 进行了多层的封装。 12345678typedef struct dictEntry &#123; void *key; /* key 关键字定义 */ union &#123; void *val; uint64_t u64; /* value 定义 */ int64_t s64; double d; &#125; v; struct dictEntry *next; /* 指向下一个键值对节点 */&#125; dictEntry; dictEntry 放到了 dictht（hashtable 里面）： 123456typedef struct dictht &#123; dictEntry **table; /* 哈希表数组 */ unsigned long size; /* 哈希表大小 */ unsigned long sizemask; /* 掩码大小，用于计算索引值。总是等于 size-1 */ unsigned long used; /* 已有节点数 */&#125; dictht; ht 放到了 dict 里面： 1234567typedef struct dict &#123; dictType *type; /* 字典类型 */ void *privdata; /* 私有数据 */ dictht ht[2]; /* 一个字典有两个哈希表 */ long rehashidx; /* rehash 索引 */ unsigned long iterators; /* 当前正在使用的迭代器数量 */&#125; dict; 从最底层到最高层 dictEntry——dictht——dict——OBJ_ENCODING_HT总结：哈希的存储结构注意：dictht 后面是 NULL 说明第二个 ht 还没用到。dictEntry* 后面是 NULL 说明没有 hash 到这个地址。dictEntry 后面是NULL 说明没有发生哈希冲突。 为什么要定义两个哈希表呢？ht[2] redis 的 hash 默认使用的是 ht[0]，ht[1]不会初始化和分配空间。哈希表 dictht 是用链地址法来解决碰撞问题的。在这种情况下，哈希表的性能取决于它的大小（size 属性）和它所保存的节点的数量（used 属性）之间的比率： 比率在 1:1 时（一个哈希表 ht 只存储一个节点 entry），哈希表的性能最好； 如果节点数量比哈希表的大小要大很多的话（这个比例用 ratio 表示，5 表示平均一个 ht 存储 5 个 entry），那么哈希表就会退化成多个链表，哈希表本身的性能优势就不再存在。 在这种情况下需要扩容。Redis 里面的这种操作叫做 rehash。rehash 的步骤： 为字符 ht[1]哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及 ht[0]当前包含的键值对的数量。扩展：ht[1]的大小为第一个大于等于ht[0].used * 2。 将所有的 ht[0]上的节点 rehash 到 ht[1]上，重新计算 hash 值和索引，然后放入指定的位置。 当 ht[0]全部迁移到了 ht[1]之后，释放 ht[0]的空间，将 ht[1]设置为 ht[0]表，并创建新的 ht[1]，为下次 rehash 做准备。 什么时候触发扩容？取决于负载因子，根据负载因子也会自动进行缩容。 12static int dict_can_resize = 1;static unsigned int dict_force_resize_ratio = 5; ratio = used / size，已使用节点与字典大小的比例dict_can_resize 为 1 并且 dict_force_resize_ratio 已使用节点数和字典大小之间的比率超过 1：5，触发扩容 应用场景 字符串类型的应用都满足 存储对象类型数据 List（列表）存储有序的字符串（从左到右），元素可以重复。可以充当队列和栈的角色。 操作命令1234567891011121314151617181920从队列左边入值：lpush queue a从队列右边入值：rpush queue b从队列左边出值：lpop queue从队列右边出值：rpop queue查看队列长度：llen queue展示队列指定范围值：lrange queue 0 10取指定下标值：lindex queue 0 存储原理在早期的版本中，数据量较小时用 ziplist 存储，达到临界值时转换为 linkedlist 进行存储，分别对应 OBJ_ENCODING_ZIPLIST 和OBJ_ENCODING_LINKEDLIST 。3.2 版本之后，统一用 quicklist 来存储。quicklist 存储了一个双向链表，每个节点都是一个 ziplist。 quicklistquicklist（快速列表）是 ziplist 和 linkedlist 的结合体。quicklist.h，head 和 tail 指向双向列表的表头和表尾 12345678typedef struct quicklist &#123; quicklistNode *head; /* 指向双向列表的表头 */ quicklistNode *tail; /* 指向双向列表的表尾 */ unsigned long count; /* 所有的 ziplist 中一共存了多少个元素 */ unsigned long len; /* 双向链表的长度，node 的数量 */ int fill : 16; /* fill factor for individual nodes */ unsigned int compress : 16; /* 压缩深度，0：不压缩； */&#125; quicklist; redis.conf 相关参数： 参数 含义 list-max-ziplist-size（fill） 正数表示单个 ziplist 最多所包含的 entry 个数。负数代表单个 ziplist 的大小，默认 8k。-1：4KB；-2：8KB；-3：16KB；-4：32KB；-5：64KB list-compress-depth（compress） 压缩深度，默认是 0。1：首尾的 ziplist 不压缩；2：首尾第一第二个 ziplist 不压缩，以此类推 quicklistNode 中的 * zl 指向一个 ziplist，一个 ziplist 可以存放多个元素。 123456789101112typedef struct quicklistNode &#123; struct quicklistNode *prev; /* 前一个节点 */ struct quicklistNode *next; /* 后一个节点 */ unsigned char *zl; /* 指向实际的 ziplist */ unsigned int sz; /* 当前 ziplist 占用多少字节 */ unsigned int count : 16; /* 当前 ziplist 中存储了多少个元素，占 16bit（下同），最大 65536 个 */ unsigned int encoding : 2; /* 是否采用了 LZF 压缩算法压缩节点，1：RAW 2：LZF */ unsigned int container : 2; /* 2：ziplist，未来可能支持其他结构存储 */ unsigned int recompress : 1; /* 当前 ziplist 是不是已经被解压出来作临时使用 */ unsigned int attempted_compress : 1; /* 测试用 */ unsigned int extra : 10; /* 预留给未来使用 */&#125; quicklistNode; 应用场景 用户消息时间线 消息队列 Set（集合）String 类型的无序集合，最大存储数量 2^32-1（40 亿左右）。 操作命令1234567891011121314151617181920添加一个或者多个元素:sadd myset a b c d e f g获取所有元素:smembers myset统计元素个数:scard myset随机获取一个元素:srandmember key随机弹出一个元素:spop myset移除一个或者多个元素:srem myset d e f查看元素是否存在:sismember myset a 存储原理Redis 用 intset 或 hashtable 存储 set。如果元素都是整数类型，就用 inset 存储。如果不是整数类型，就用 hashtable（数组+链表的存来储结构）。KV 怎么存储 set 的元素？key 就是元素的值，value 为 null。如果元素个数超过 512 个，也会用 hashtable 存储。 应用场景 抽奖 点赞、签到、打卡 商品标签 商品筛选 ZSet（有序集合）sorted set，有序的 set，每个元素有个 score。score 相同时，按照 key 的 ASCII 码排序。数据结构对比： 数据结构 是否允许重复元素 是否有序 有序实现方式 列表list 是 是 索引下标 集合set 否 否 无 有序集合zset 否 是 分值score 操作命令123456789101112131415161718192021222324252627添加元素:zadd myzset 10 java 20 php 30 ruby 40 cpp 50 python获取全部元素:zrange myzset 0 -1 withscoreszrevrange myzset 0 -1 withscores根据分值区间获取元素:zrangebyscore myzset 20 30移除元素,也可以根据 score rank 删除:zrem myzset php cpp统计元素个数:zcard myzset分值递增:zincrby myzset 5 python根据分值统计个数:zcount myzset 20 60获取元素 rank:zrank myzset java获取元素 score:zsocre myzset java 存储原理同时满足以下条件时使用 ziplist 编码： 元素数量小于 128 个 所有 member 的长度都小于 64 字节 在 ziplist 的内部，按照 score 排序递增来存储。插入的时候要移动之后的数据。 对应 redis.conf 参数：zset-max-ziplist-entries 128zset-max-ziplist-value 64 超过阈值之后，使用 skiplist+dict 存储。 skiplist我们先来看一下有序链表：在这样一个链表中，如果我们要查找某个数据，那么需要从头开始逐个进行比较，直到找到包含数据的那个节点，或者找到第一个比给定数据大的节点为止（没找到）。也就是说，时间复杂度为 O(n)。同样，当我们要插入新数据的时候，也要经历同样的查找过程，从而确定插入位置。而二分查找法只适用于有序数组，不适用于链表。假如我们每相邻两个节点增加一个指针（或者理解为有三个元素进入了第二层），让指针指向下下个节点。这样所有新增加的指针连成了一个新的链表，但它包含的节点个数只有原来的一半（上图中是 7, 19, 26）。在插入一个数据的时候，决定要放到那一层，取决于一个算法（在 redis 中 t_zset.c 有一个 zslRandomLevel 这个方法）。现在当我们想查找数据的时候，可以先沿着这个新链表进行查找。当碰到比待查数据大的节点时，再回到原来的链表中的下一层进行查找。比如，我们想查找 23，查找的路径是沿着下图中标红的指针所指向的方向进行的： 23 首先和 7 比较，再和 19 比较，比它们都大，继续向后比较。 但 23 和 26 比较的时候，比 26 要小，因此回到下面的链表（原链表），与 22比较。 23 比 22 要大，沿下面的指针继续向后和 26 比较。23 比 26 小，说明待查数据 23 在原链表中不存在。 在这个查找过程中，由于新增加的指针，我们不再需要与链表中每个节点逐个进行比较了。需要比较的节点数大概只有原来的一半。这就是跳跃表。 为什么不用 AVL 树或者红黑树？因为 skiplist 更加简洁。 123456789101112131415161718192021typedef struct zskiplistNode &#123; sds ele; /* zset 的元素 */ double score; /* 分值 */ struct zskiplistNode *backward; /* 后退指针 */ struct zskiplistLevel &#123; struct zskiplistNode *forward; /* 前进指针，对应 level 的下一个节点 */ unsigned long span; /* 从当前节点到下一个节点的跨度（跨越的节点数） */ &#125; level[]; /* 层 */&#125; zskiplistNode;typedef struct zskiplist &#123; struct zskiplistNode *header, *tail; /* 指向跳跃表的头结点和尾节点 */ unsigned long length; /* 跳跃表的节点数 */ int level; /* 最大的层数 */&#125; zskiplist;typedef struct zset &#123; dict *dict; zskiplist *zsl;&#125; zset; 随机获取层数的函数： 123456int zslRandomLevel(void) &#123; int level = 1; while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF)) level += 1; return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;&#125; 应用场景 排行榜 其他数据介绍常用的是以上五种数据类型，其他四种在这里就简单介绍。 BitMapBitMap 就是通过一个 bit 位来表示某个元素对应的值或者状态, 其中的 key 就是对应元素本身，实际上底层也是通过对字符串的操作来实现。Redis 从 2.2 版本之后新增了setbit, getbit, bitcount 等几个 bitmap 相关命令。虽然是新命令，但是本身都是对字符串的操作，一个字节由 8 个二进制位组成。 常用命令1234567891011121314151617设置值：set k1 a获取 value 在 offset 处的值（a 对应的 ASCII 码是 97，转换为二进制数据是 01100001）：getbit k1 0修改二进制数据（b 对应的 ASCII 码是 98，转换为二进制数据是 01100010）：setbit k1 6 1setbit k1 7 0get k1统计二进制位中 1 的个数：bitcount k1获取第一个 1 或者 0 的位置：bitpos k1 1bitpos k1 0 BITOP 命令支持 AND 、 OR 、 NOT 、 XOR 这四种操作中的任意一种参数：BITOP AND destkey srckey1 … srckeyN ，对一个或多个 key 求逻辑与，并将结果保存到 destkeyBITOP OR destkey srckey1 … srckeyN，对一个或多个 key 求逻辑或，并将结果保存到 destkeyBITOP XOR destkey srckey1 … srckeyN，对一个或多个 key 求逻辑异或，并将结果保存到 destkeyBITOP NOT destkey srckey，对给定 key 求逻辑非，并将结果保存到 destkey 应用场景 用户访问统计 在线用户统计 HyperloglogsRedis 的基数统计，这个结构可以非常省内存的去统计各种计数，比如注册 IP 数、每日访问 IP 数、页面实时UV）、在线用户数等。但是它也有局限性，就是只能统计数量，而没办法去知道具体的内容是什么并且存在一定的误差。 GeoRedis 的 GEO 特性在 Redis 3.2 版本中推出， 这个功能可以将用户给定的地理位置信息储存起来， 并对这些信息进行操作。 Streams5.0 推出的数据类型。支持多播的可持久化的消息队列，用于实现发布订阅功能，借鉴了 kafka 的设计。 总结数据对象总结 对象 对象 type 属性值 type 命令输出 底层可能的存储结构 object encoding 字符串对象 OBJ_STRING “string” OBJ_ENCODING_INT OBJ_ENCODING_EMBSTR OBJ_ENCODING_RAW int embstr raw 列表对象 OBJ_LIST “list” OBJ_ENCODING_QUICKLIST quicklist 哈希对象 OBJ_HASH “hash” OBJ_ENCODING_ZIPLIST OBJ_ENCODING_HT ziplist hashtable 集合对象 OBJ_SET “set” OBJ_ENCODING_INTSET OBJ_ENCODING_HT intset hashtable 有序集合对象 OBJ_ZSET “zset” OBJ_ENCODING_ZIPLIST OBJ_ENCODING_SKIPLIST ziplist skiplist（包含 ht） 编码转换总结 应用场景总结 缓存——提升热点数据的访问速度 共享数据——数据的存储和共享的问题 全局 ID —— 分布式全局 ID 的生成方案（分库分表） 分布式锁——进程间共享数据的原子操作保证 在线用户统计和计数 队列、栈——跨进程的队列/栈 消息队列——异步解耦的消息机制 服务注册与发现 —— RPC 通信机制的服务协调中心（Dubbo 支持 Redis） 购物车 新浪/Twitter 用户消息时间线 抽奖逻辑（礼物、转发） 点赞、签到、打卡 商品标签 用户（商品）关注（推荐）模型 电商产品筛选 排行榜]]></content>
      <categories>
        <category>Redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SqlSessionTemplate为什么线程安全]]></title>
    <url>%2F2019%2F11%2F06%2FSqlSessionTemplate%E4%B8%BA%E4%BB%80%E4%B9%88%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[最近在看Mybatis源码，对于理解SqlSessionTemplate是如何保证线程安全的网上的文章不多。希望通过本文能够帮助大家清楚理解，类关系图如下： DefaultSqlSession与SqlSessionManager解析在Mybatis中SqlSession默认有DefaultSqlSession和SqlSessionManager两个实现类 DefaultSqlSession是真正的实现类调用Executor，但不是线程安全的。 Mybatis又实现了对SqlSession和SQLSessionFactory的封装类SqlSessionManager，线程安全并通过localSqlSession实现复用从而提高性能。 1private ThreadLocal&lt;SqlSession&gt; localSqlSession = new ThreadLocal(); SqlSessionManager通过SqlSessionInterceptor实现对DefaultSqlSession代理调用。 123456789101112131415161718192021222324252627282930313233private class SqlSessionInterceptor implements InvocationHandler &#123; public SqlSessionInterceptor() &#123; &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //由调用者决定当前线程是否复用 SqlSession SqlSession sqlSession = (SqlSession)SqlSessionManager.this.localSqlSession.get(); if (sqlSession != null) &#123; try &#123; return method.invoke(sqlSession, args); &#125; catch (Throwable var12) &#123; throw ExceptionUtil.unwrapThrowable(var12); &#125; &#125; else &#123; //如果不复用，则每次调用都新建 SqlSession 并使用后销毁 SqlSession autoSqlSession = SqlSessionManager.this.openSession(); Object var7; try &#123; Object result = method.invoke(autoSqlSession, args); autoSqlSession.commit(); var7 = result; &#125; catch (Throwable var13) &#123; autoSqlSession.rollback(); throw ExceptionUtil.unwrapThrowable(var13); &#125; finally &#123; autoSqlSession.close(); &#125; return var7; &#125; &#125; &#125; DefaultSqlSession和SqlSessionManager之间的区别： 1、单例模式下DefaultSqlSession是线程不安全的，而SqlSessionManager是线程安全的； 2、SqlSessionManager可以选择通过localSqlSession这个ThreadLocal变量，记录与当前线程绑定的SqlSession对象，供当前线程循环使用，从而避免在同一个线程多次创建SqlSession对象造成的性能损耗； 3、使用DefaultSqlSession为了保证线程安全需要为每一个操作都创建一个SqlSession对象，其性能可想而知； SqlSessionTemplate是怎么保证线程安全SqlSessionTemplate是MyBatis专门为Spring提供的，支持Spring框架的一个SqlSession获取接口。主要是为了继承Spring，并同时将是否共用SqlSession的权限交给Spring去管理。 1、通过创建sqlSessionProxy代理类，将调用导向SqlSessionInterceptor的invoke方法。 12345678public SqlSessionTemplate(SqlSessionFactory sqlSessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) &#123; Assert.notNull(sqlSessionFactory, &quot;Property &apos;sqlSessionFactory&apos; is required&quot;); Assert.notNull(executorType, &quot;Property &apos;executorType&apos; is required&quot;); this.sqlSessionFactory = sqlSessionFactory; this.executorType = executorType; this.exceptionTranslator = exceptionTranslator; this.sqlSessionProxy = (SqlSession)Proxy.newProxyInstance(SqlSessionFactory.class.getClassLoader(), new Class[]&#123;SqlSession.class&#125;, new SqlSessionTemplate.SqlSessionInterceptor()); &#125; 2、获取线程私有的SqlSession，调用DefaultSqlSession对应的实际方法上 1234567891011121314151617181920212223242526272829303132333435363738394041private class SqlSessionInterceptor implements InvocationHandler &#123; private SqlSessionInterceptor() &#123; &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //获取同一个线程的复用sqlSession，如果没有则新生成一个并存到线程私有存储中 SqlSession sqlSession = SqlSessionUtils.getSqlSession(SqlSessionTemplate.this.sqlSessionFactory, SqlSessionTemplate.this.executorType, SqlSessionTemplate.this.exceptionTranslator); Object unwrapped; try &#123; //实际调用DefaultSession的对应方法 Object result = method.invoke(sqlSession, args); //判断当前sqlSession是否被Spring管理，如果没有直接commit if (!SqlSessionUtils.isSqlSessionTransactional(sqlSession, SqlSessionTemplate.this.sqlSessionFactory)) &#123; sqlSession.commit(true); &#125; unwrapped = result; &#125; catch (Throwable var11) &#123; unwrapped = ExceptionUtil.unwrapThrowable(var11); if (SqlSessionTemplate.this.exceptionTranslator != null &amp;&amp; unwrapped instanceof PersistenceException) &#123; SqlSessionUtils.closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); sqlSession = null; Throwable translated = SqlSessionTemplate.this.exceptionTranslator.translateExceptionIfPossible((PersistenceException)unwrapped); if (translated != null) &#123; unwrapped = translated; &#125; &#125; throw (Throwable)unwrapped; &#125; finally &#123; if (sqlSession != null) &#123; //正常返回将线程私有sqlSession调用次数减一 SqlSessionUtils.closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); &#125; &#125; return unwrapped; &#125; &#125; 3、查看getSqlSession()方法就知道每个线程对应的SqlSession都是私有的不会被共用，所以SqlSessionTemplate是线程安全的。 12345678910111213141516171819public static SqlSession getSqlSession(SqlSessionFactory sessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) &#123; Assert.notNull(sessionFactory, &quot;No SqlSessionFactory specified&quot;); Assert.notNull(executorType, &quot;No ExecutorType specified&quot;); //从线程私有存储中获取SqlSession SqlSessionHolder holder = (SqlSessionHolder)TransactionSynchronizationManager.getResource(sessionFactory); SqlSession session = sessionHolder(executorType, holder); if (session != null) &#123; return session; &#125; else &#123; if (LOGGER.isDebugEnabled()) &#123; LOGGER.debug(&quot;Creating a new SqlSession&quot;); &#125; //没有则新建一个DefaultSqlSession session = sessionFactory.openSession(executorType); //存到线程私有存储中 registerSessionHolder(sessionFactory, executorType, exceptionTranslator, session); return session; &#125; &#125; 总结究其根本SqlSession真正的实现类只有DefaultSqlSession，SqlSessionManager和SqlSessionTemplate都是通过代理转发到DefaultSqlSession对应方法。 单例模式下的DefaultSqlSession不是线程安全的，SqlSessionManager和SqlSessionTemplate线程安全的根本就是每一个线程对应的SqlSession都是不同的。如果每一个操作都创建一个SqlSession对象，操作完又进行销毁导致性能极差。通过线程私有ThreadLocal存储SqlSession进行复用，从而提高性能。 参考：https://blog.csdn.net/bntx2jsqfehy7/article/details/79441545#commentsedit]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JVM性能调优监测工具]]></title>
    <url>%2F2019%2F11%2F05%2FJVM%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%9B%91%E6%B5%8B%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[查看正在运行的程序jps主要用来输出JVM中运行的进程状态信息。语法格式如下： 123456789jps [options] [hostid]options:-q 不输出类名、Jar名和传入main方法的参数-m 输出传入main方法的参数-l 输出main类或Jar的全限名-v 输出传入JVM的参数hostid：不填，默认为本机 CPU飙升排查jstack主要用来查看某个Java进程内的线程堆栈信息。 通过 top 命令找到 CPU 消耗最高的进程，并记住进程 ID。 再次通过 top -Hp [进程 ID] 找到 CPU 消耗最高的线程 ID，并记住线程 ID. 通过 JDK 提供的 jstack 工具 dump 线程堆栈信息到指定文件中。具体命令：jstack -l [进程 ID] &gt;jstack.log。 由于刚刚的线程 ID 是十进制的，而堆栈信息中的线程 ID 是16进制的，因此我们需要将10进制的转换成16进制的，并用这个线程 ID 在堆栈中查找。使用 printf “%x\n” [十进制数字] ，可以将10进制转换成16进制。 通过刚刚转换的16进制数字从堆栈信息里找到对应的线程堆栈。就可以从该堆栈中看出端倪。 C2 编译器执行编译时也会抢占 CPU，什么是 C2编译器呢？当 Java 某一段代码执行次数超过10000次（默认）后，就会将该段代码从解释执行改为编译执行，也就是编译成机器码以提高速度。而这个 C2编译器就是做这个的。如何解决呢？项目上线后，可以先通过压测工具进行预热，这样，等用户真正访问的时候，C2编译器就不会干扰应用程序了。如果是 GC 线程导致的，那么极有可能是 Full GC ，那么就要进行 GC 的优化。 内存使用情况监测jmap用来查看堆内存使用状况。 使用jmap -heap pid查看进程堆内存使用情况，包括使用的GC算法、堆配置参数和各代中堆内存使用情况。 使用jmap -histo[:live] pid查看堆内存中的对象数目、大小统计直方图，如果带上live则只统计活对象。 使用jmap -permstat pid 打印classload和jvm heap长久层的信息. 包含每个classloader的名字,活泼性,地址,父classloader和加载的class数量. 另外,内部String的数量和占用内存数也会打印出来。 JVM统计监测 jstat命令可以查看堆内存各部分的使用量，以及加载类的数量。 1jstat [ generalOption | outputOptions vmid [interval[s|ms] [count]] ] 比如下面输出的是GC信息，采样时间间隔为250ms，采样数为4： 123456 jstat -gc 14157 250 4S0C S1C S0U S1U EC EU OC OU PC PU YGC YGCT FGC FGCT GCT 192.0 192.0 64.0 0.0 6144.0 1854.9 32000.0 4111.6 55296.0 25472.7 702 0.431 3 0.218 0.649192.0 192.0 64.0 0.0 6144.0 1972.2 32000.0 4111.6 55296.0 25472.7 702 0.431 3 0.218 0.649192.0 192.0 64.0 0.0 6144.0 1972.2 32000.0 4111.6 55296.0 25472.7 702 0.431 3 0.218 0.649192.0 192.0 64.0 0.0 6144.0 2109.7 32000.0 4111.6 55296.0 25472.7 702 0.431 3 0.218 0.649 我们知道堆内存 = 年轻代 + 年老代 + 永久代年轻代 = Eden区 + 两个Survivor区（From和To） 1234567S0C、S1C、S0U、S1U：Survivor 0/1区容量（Capacity）和使用量（Used）EC、EU：Eden区容量和使用量OC、OU：年老代容量和使用量PC、PU：永久代容量和使用量YGC、YGT：年轻代GC次数和GC耗时FGC、FGCT：Full GC次数和Full GC耗时GCT：GC总耗时 查看文件字节码这里扩展一下如何查看文件字节码 12345Javac Foo.java 将文件解析成class字节码文件Javap Foo.class 打印所有非私有的字段和方法Javap -p Foo.class 还将打印私有的字段和方法Javap -v Foo.class 尽可能打印所有信息Javap -c Foo.class 打印方法对应的字节码 参考链接：https://mp.weixin.qq.com/s/-5vdgexMyoiMRVPlOO88Swhttps://mp.weixin.qq.com/s/LJGWPRBc_BJLTfopi7Lttg]]></content>
      <categories>
        <category>JVM</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux基础指令基础]]></title>
    <url>%2F2019%2F11%2F01%2Flinux%E5%9F%BA%E7%A1%80%E6%8C%87%E4%BB%A4%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[常用命令1查看指令帮助：help 文件相关123456789101112131415161718192021查看当前目录内容：ls、ll清除终端内容：clear进入下一级目录：cd创建文件：touch 1.txt创建文件夹：mkdir 11复制文件或文件夹：cp 被复制的文件 复制的路径查看当前路径：pwd看当前用户所有历史指令(~/.bash_history,注：系统退出后才会保存)：history从历史指令中找最后一条以xx开头的指令并执行：!xx强制删除指定文件或文件夹：rm -rf 文件名查看文件内容并显示行号：cat -n 文件名 或 nl 文件名统计文件行数：wc -l 文件名查看文件前10行内容：head -10 文件名 查看文件后10行并实时展示最增内容：tail -10 -f 文件名分页查看文件内容：more 文件名（下一页：空格、上一页：b）分页查询并且搜索文件内容：less 文件名 （进入后按q退出，/加搜索内容并且高亮显示）比较两个文档不同：diff 文件1 文件2为路径创建短连接：ls -s 路径 短连接名(可以通过 cd 短连接名 直接进入对应路径)按100行分割一次，a表示分割后的文件名前缀，后缀是自动生成的：split -100 文件名 aaa文件按固定大小分割：split -b 1M 文件名文本合并，可以借助cat：cat a* &gt; a.txt 用户相关123456增加用户：useradd 用户名设置密码：passwd 用户名删除用户：userdel 用户名查看当前系统用户：uname -a给当前用户文件增加读写执行权限：chmod u+rwx 文件名 （u表示当前用户，还有g(group)、o(others)；如果省略，则表示给u、g、o均添加权限）给所有用户增加全部权限：chmod 777 文件名 系统相关123456789101112查看cpu、内存实时状态：top查看磁盘使用情况：df -h查看内存使用情况：free -h查看当前执行进程：ps -ef查看网络系统的状态信息：netstat -a强制终止指定某个进程：kill -9 pid查看系统时间：date查询命令位置：which java查看ip、网卡等信息：ifconfig系统日志的位置：/var/log/messages向系统日志写消息：logger &quot;xxxxx&quot; 安装程序命令：yum、wget、rpm、apt-get...(有的适用于CentOS，有的RedHat，有的Ubuntu) 指令123456789输出从2-10：seq 2 10保存脚本执行结果并同时并查看：sh a.sh | tee b.txt退出脚本：exit (正常退出返回0，异常退出返回非零)为指令设置别名：alias 1=&apos;df -h&apos;(重启终端还能使用别名需要将别名设置放到 ~/.bashrc文件中)接触别名：unalias 1定时执行某脚本：crontab 1 * * * * ~/1.sh（每小时1分的时候执行1.sh这个脚本）查看当前用户定时器设置：crontab -l删除当前用户定时器设置：crontab -r vim指令插入模式1234567891011G：跳到文档最后一行gg：调到文档第一行x：删除当前光标所在的字符nx：从光标向后删除n个字符dd：删除当前行ndd：删除当前及后n行D：删除当前行光标后边所有字符r：replace，替换当前光标的字符yy：粘贴p：paste复制u：撤销 命令行模式1234567i：从当前行进入插入模式o：从下一行进入插入模式q：退出vim模式q!：退出并不保存更改内容wq：退出并保持更改内容/**：查询字符串所在的位置，按下回车后用n进行搜索下一个，N返回上一个nu：设置行号 打包/压缩123456789打包当前目录所有文件：tar -cvf a.tar * 压缩包：gzip a.tar打包并压缩当前文件夹内容：tar -czvf a.tar.gz * 解压：tar -xvf a.tar查看内部文件列表：tar -tf a.tar解压并解包：tar -zxvf a.tar.gzzip压缩：zip target.zip sourceFilezip解压到指定目录：unzip zipFile -d dir Shell解释器1脚本开头：#!/bin/bash 或 #!/bin/sh(默认可以不写) 执行脚本12./shell.sh(需要执行权限)sh shell.sh 或 bash shell.sh(读取执行～只需要读取权限) 变量1234567a=3：声明变量a，并赋值3$a：等价于$&#123;a&#125;。但是 $&#123;a&#125;ook 和 $aook就不一样$?：上一个指令是否正确执行，上一个脚本是否正常退出(1-不正确，0-正确)$0：文件名$1～$9：第几个参数值(echo $&#123;1:-daily&#125;，取脚本第一个参数，如果没有，则赋值daily)$#：一共几个参数$*：所有入参 符号12345678910111213141516171819202122|：管道符号：把前边的输出作为后边的输入ls -s|sort -nr&gt;：覆盖输出；echo &quot;abc&quot; &gt; a.txt&gt;&gt;：拼接输出；echo &quot;abc&quot; &gt;&gt; a.txt;：一行执行多条语句的分隔符 cat a.txt ; ls&amp;&amp;：前边语句成功才会执行后边语句 cat a.txt &amp;&amp; ls||：前边语句失败才会执行后边语句lo || ls$$：输出当前脚本的执行进程idecho $$&quot;&quot;：输出变量值 a=10;echo &quot;$a&quot; -&gt; 10&apos;&apos;：输出本身 a=10;echo &apos;$a&apos; -&gt; $a``：执行内部语法。echo `date` 等价于 date&amp;&gt;filename：把标准输出和错误输出都重定向到文件filenamesh abc.sh &amp;&gt; a.txt read输入12345678910-t 阻塞时间-s 隐藏输入的字符-p 给出提示符-n 读取字符的个数，个数到达临界之后会自动执行把接下来输入的数据赋值给abc：read abc在10秒内最多输入3个字符：read -t 10 -n 3 -p &apos;请输入密码：&apos; passecho &quot;密码是：$pass&quot; 计算器123456789整数： expr 10 + 20 #注意+号两边的空格 echo $[10 + 20] echo $((10 + 20)) echo $[10 % 3] 取余 echo $[10 \* 2] 乘法需要对*转义bc计算器： echo &quot;scale=2;(1.2+2.3)/1&quot; | bc #把前边的输出作为后边的输入,scale只对乘除有效所以需要/1（2;表示保留两位小数） 条件判断1234567891011121314151617181920212223[ -e a.txt ] ：方括号必须有左右空格。[ ! -e a.txt ] ：感叹号！表示取反文件判断： -e exist 文件是否存在 -d directory 是不是目录 -f file 是不是文件权限： -r 是否有读权限 -w 是否有写权限 -x 是否有执行权限整数比较： -eq（equal） -ne (not equal) -gt (greater than) -lt (lesser than) -ge (greater or equal) -le (lesser or equal)小数比较：借助bc计算器 bc判断true返回1，false返回0 [ `echo &quot;1.2 &gt; 1&quot; | bc` -eq 1 ] &amp;&amp; echo &apos;大于&apos;字符串： 直接用 = 或 != 进行判断 [ &quot;1&quot; = &quot;1&quot; ] &amp;&amp; echo &quot;相等&quot; if判断123456789101112131415161718格式1：if [ 条件 ];then echo &quot;xxx&quot;fi格式2：if [ 条件1 ];then echo &quot;xxx&quot;elif [ 条件2 ];then echo &quot;yyy&quot;else echo &quot;zzz&quot;fi#拓展：[]和[[]]的其中一点区别（双括号要强大的多）if [ $a -ne 1] &amp;&amp; [ $a != 2 ] 等价于： if [[ $a != 1 &amp;&amp; $a != 2 ]] 等价于： if [ $a -ne 1 -a $a != 2 ] （其中-a是and，-o是or） for循环123456789101112131415161718192021222324示例1： for i in 1 2 3 4 5 do if [ $i -eq 2 ];then continue else echo &quot;$i&quot; sleep 1 fi done示例2： for i in $(cat 1.txt) do ping -c 2 $i done 注：-c表示最多ping几次。windows上是-n示例3：（(条件)） for (( i=1;i&lt;11;i++ )) do echo $i sleep 1 done 注：i++相当于i=i+1，只能在(())中使用，等价于：let &apos;i+=1&apos; case选择12345678910111213141516171819202122echo &apos;请输入城市：&apos;read citycase $city in &apos;上海&apos;) echo &apos;上海：35度&apos; ;; &apos;北京&apos;) echo &apos;北京：20度&apos; ;; *) echo &apos;未知城市&apos;esac #注：case倒叙 示例2：case接受简单正则case $1 in [a-z]|[A-Z]) echo &quot;字母&quot; ;; [0-9]) echo &quot;数字&quot; ;;esac while循环123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566示例1：输入数字，并求1到该数字的和 sum=0 i=0 while [ $i -lt $1 ] do sum=$(($sum+$i)) i=$[$i+1] done echo &quot;从1加到$1的和是：$sum&quot; 示例2：模拟菜单 while [ 1 ] do cat &lt;&lt;EOF #&lt;&lt;叫输入重定向,EOF是随便定义的（成对即可） 1.执行1.sh 2.执行2.sh q.退出EOF #末尾的EOF必须顶行写，且前后均不能有空格或tab read -p &apos;请选择：&apos; key case $key in 1) clear echo &apos;执行1.sh&apos; ;; 2) clear echo &apos;执行2.sh&apos; ;; q) clear echo &apos;退出&apos; break ;; esac done 示例3： num=0 while [ $# -gt 0 ] do num=$(($1+num)) echo &quot;剩余参数：$*&quot; shift #将参数向左偏移一个 done echo &quot;总和：$num&quot; 结果如下： [root@localhost xuan]# sh 5.sh 1 2 3 4 5 剩余参数：1 2 3 4 5 剩余参数：2 3 4 5 剩余参数：3 4 5 剩余参数：4 5 剩余参数：5 总和：15示例4：死循环 while true # 或 while : 或 while [ 1 ] do let i++ echo $i sleep 1 done 函数123456789101112131415161718示例1：两数求和function add()&#123; echo $(($1+$2))&#125;add 10 20示例2：遍历指定目录下所有目录function listFiles() &#123; for file in `ls $1` do dir=$1&quot;/&quot;$file if [ -d $dir ];then ls $dir listFiles $dir fi done&#125;listFiles $1 字体颜色和特效1234567echo -e &quot;\033[背景颜色;字体颜色;特效 \033[0m&quot;示例1：echo -e &quot;\033[32;41;5m 文本字体 \033[0m&quot; #注：最后的0m表示关闭属性，&quot;\033[&quot;是固定前缀和后缀示例2：read -t 10 -p &quot;`echo -e &quot;\033[32;41;5m 请输入密码 \033[0m&quot;`&quot; pass 去重/排序12345678相邻行去重：cat a.txt | uniq 相邻行去重并统计次数：cat a.txt | uniq -c所有行排序，然后相邻行去重并统计次数：cat a.txt | sort | uniq -c -t:表示以:为分隔符(默认空格),-k3表示以第3列排序(默认整行),-r表示反转：cat a.txt | sort -t: -k3 -r 文件搜索123456789101112简单正则+通配符：find . -name &quot;a[0-9]*&quot;有的大写，有的小写：find / -size 10c/10k/10M/10G d表示目录，f表示文件，l表示链接：find . -type d/f/l -mtime表示修改时间；-3表示3天以内，+3表示3天前：find . -mtime -3/+3 指定用户：find . -user rootxargs是将管道前的搜索作为参数传给后边，此处如果不加xargs，则后边的指令是没有意义的：find . -name &quot;[a-b]*.sh&quot; | xargs rm -rf 文本·行搜索1234567891011121314151617-v invert 反向选择-i ignore 忽略大小写-w word 单词匹配-n 显示行号&quot;^xx&quot; 某行以xx开头（行首匹配） grep &quot;^user&quot; a.txt 或：grep -E &quot;^user&quot; a.txt &quot;xx$&quot; 某行以xx结尾 grep &quot;user$&quot; a.txt-E regex 正则 grep -E &quot;sbi*&quot; /etc/passwd grep -Ein &quot;(linux)&#123;2&#125;&quot; a.txt #注：()表示单元 grep -Ein &quot;(linux)+&quot; a.txt grep -Ein &quot;[0-9]+&quot; a.txt grep -E &quot;\*&quot; a.txt #注：\转义等价于：grep &quot;*&quot; a.txt (默认不支持正则) grep -E &quot;[0-9]+\.+[0-9]+\.[0-9]+\.[0-9]+&quot; a.txt #注：搜索ip grep -E &quot;^$&quot; a.txt #注：找空行 grep -E &quot;^[^d]&quot; a.txt #注：找不是d开头的行。^放在[]外边表示&quot;以xx开头&quot;，放在[]中表示&quot;除了&quot; 文本·列操作1234567891011121314151617181920-d 指定分隔符，delimiter-f 指定第几列-c 按字符截取示例1：以冒号分割后，取第1列和第3列 cut -d &apos;:&apos; -f 1,3 /etc/passwd #注：1,3表示第1列和第3列；1-3表示第1列到第3列；3-表示第3列以后。示例2： cut -c 1-4 /etc/passwd #截取第1列到第4列字符，以字符为单位示例3：查找linux系统中所有不能登录的用户名 cat /etc/passwd | grep /sbin/nologin | cut -d &apos;:&apos; -f 1 #注1： cat /etc/passwd | cut -d &apos;:&apos; -f 1 等价于cut -d &apos;:&apos; -f 1 /etc/passwd #注2：/bin/bash结尾的用户是可以登录的；/sbin/nologin结尾的是系统默认用户，不可以登录 #注3：cut用空格分割的话，每一个空格都会计数1次。 Mem: 1837 107 298 0 1431 1532 free -m | grep -i mem | cut -d &quot; &quot; -f 12 -&gt; 1837 free -m | grep -i mem | cut -d &quot; &quot; -f 2 -&gt; 空格 文本操作123456789101112131415161718192021222324252627awk是一门语言，是3个创始人的姓名首字母缩写而成printf不换行打印；print 换行打印 printf &apos;%3s %3s\n&apos; 11 12 -&gt; %ns是字符串，n默认是1可省略 printf &apos;%2i %2i\n&apos; 11 12 -&gt; %ni是数字 printf &apos;%.2f\n&apos; 0.1234 -&gt; 0.12 &quot;%.nf&quot;是格式化浮点数3.1 awk (默认分隔符是空格)3.2 awk &apos;条件1 &#123;动作1&#125; 条件2 &#123;动作2&#125;&apos; 文件名 echo &quot;0.123+0.123&quot; | bc | awk &apos;&#123;printf &quot;%.2f\n&quot;, $0&#125;&apos; #注：$0表示整行，$1表示第一列... df -h | grep /dev/sda2 | awk &apos;&#123;print &quot;sda2的磁盘使用率：&quot; $3&#125;&apos; free -m | sed -n &apos;2p&apos; | awk &apos;&#123;print &quot;total:&quot;$2&quot;\n&quot; &quot;userd:&quot;$3&quot;\n&quot;&#125;&apos;3.3 awk 选项 &apos;条件1 &#123;动作1&#125; 条件2 &#123;动作2&#125;&apos; 文件名 cat /etc/passwd | awk -F &quot;:&quot; &apos;&#123;printf $1&#125;&apos; #注：-F指定分隔符，field-separator cat /etc/passwd | awk &apos;BEGIN &#123;FS=&quot;:&quot;&#125;&#123;print $1&#125; END &#123;print &quot;结束了&quot;&#125;&apos; #注1：FS是field separator #注2：BEGIN是在awk之前执行，一般用于修改内置变量；END是awk执行完之后执行3.4 NR 行号，是awk中的一个常量（num row）；NF列号（num field） df -h | awk &apos;NR==2 &#123;print $1&#125;&apos; df -h | awk &apos;(NR&gt;=2 &amp;&amp; NR &lt;=4) &#123;printf $1&quot;\n&quot;&#125;&apos; cat a.txt | awk &apos;END&#123;print NR&#125;&apos; #统计有多少行 cat a.txt | awk &apos;&#123;if(NR==1)&#123;print $0&#125;&#125;&apos; #打印第一行 cat a.txt | awk &apos;$0~/java/&apos; #$0表示整行，~表示匹配，/被匹配文本/ cat a.txt | awk &apos;$0!~/java/&apos; # !~表示不匹配 文本·行操作1234567891011121314151617181920-n和p一块使用： df -h | sed -n &apos;2&apos;p #查询第2行，p表示print，也可以写成sed -n &apos;2p&apos;d：删除 df -f | sed &apos;2&apos;d #删除第2行eg: cat a.txt | sed -n &apos;1,/java/&apos;p #搜索第1行到包含java的那一行。 cat a.txt | sed -n &apos;10,$&apos;p #搜索第10行到最后一行。等价于：sed -n &apos;10,$&apos;p a.txt cat a.txt | sed &apos;2,3&apos;d #搜索除了第2行到第3行的数据a：在下边插入 df -h | sed &apos;2a xuan&apos;i：在上边插入 df -h | sed &apos;2i xuan&apos;c：替换 df -h | sed &apos;2c xuan&apos; #把第2行替换成xuans/旧串/新串/g df -h | sed &apos;s/oldStr/newStr/g&apos;-i：对源文件进行修改(危险) sed -i &apos;s/oldStr/newStr/g&apos; a.txt sed -i &apos;2i 玄&apos; 5.txt-e：指定多个条件 简单例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748491.判断两个数是否相等 if [ $1 -eq $2 ];then 注：if后有空格 echo &quot;$1等于$2&quot; else echo &quot;$1不等于$2&quot; fi 等价于： [ $1 -eq $2 ] &amp;&amp; echo &quot;$1等于$2&quot; [ $1 -eq $2 ] &amp;&amp; echo &quot;$1不等于$2&quot; #注：多条件 if [ &quot;a&quot; = &quot;a&quot; ] &amp;&amp; [ &quot;b&quot; = &quot;b&quot; ]2.判断上一个指令是否执行成功 fName=22.txt touch $fName if [ $? -eq 0 ];then echo &quot;$fName创建成功&quot; fi3.判断输入的数字是否大于10 echo &apos;请输入一个数字：&apos; read number if [ $number -eq 10 ];then echo &apos;等于10&apos; elif [ $number -lt 10 ];then echo &apos;小于10&apos; else echo &apos;大于10&apos; fi 4.越过交互：给用户xuan设置密码。需要交互两次 方式1： passwd xuan &lt; password.txt #注：password.txt文件中有两行相同的密码 方式2： passwd xuan &lt;&lt;EOF #注：&lt;&lt;前是指令。heredoc语法 123 123 EOF #注：末尾的EOF必须顶行写，不能有空格或tab sh a.sh &lt;&lt;EOF 土豆 root EOF 方式3： echo 123 | passwd --stdin xuan #注：passwd的--stdin参数ubuntu不支持，centos才可以 巡检内存1234567891011121314total=`free -m | sed -n &apos;2p&apos; | awk &apos;&#123;printf $2&#125;&apos;` #注：awk &apos;&#123;&#125;&apos;别漏了单引号；printf别漏了fused=`free -m | grep -i mem | awk &apos;&#123;printf $3&#125;&apos;`percent_used=`echo &quot;scale=2;$used/$total&quot; | bc | awk &apos;&#123;printf &quot;%.2f&quot;,$1&#125;&apos;`echo -e &quot;总共：$&#123;total&#125;m&quot;echo &quot;已用：$&#123;used&#125;m&quot;echo &quot;内存使用率：$percent_used&quot;threshold=0.04flag=`echo &quot;$percent_used &gt; $threshold&quot; | bc`if [ $flag -eq 1 ];then echo -e &quot;\033[31m内存使用率超过$threshold \033[0m&quot; #注：31m后边如果有空格，则打印出来也有fi 批量创建用户12345678910111213141516read -p &apos;请输入用户名前缀：&apos; userread -p &apos;请输入创建用户个数：&apos; numecho &quot;$user $num&quot;for i in `seq 1 $num` #注：seq默认从1开始，所以1可以省略do #创建用户:先判断用户是否存在 newUser=$user$i cat /etc/passwd | awk -F&quot;:&quot; &apos;&#123;printf $1&quot;\n&quot;&#125;&apos; | grep $newUser if [ $? -eq 1 ];then #注：上边搜不到则$?=1 useradd $newUser echo &quot;创建用户$user$i&quot; #设置8位随机密码. /dev/urandom文件中会随机产生一些乱码数据，使用md5sum可以得到随机字符串 password=`head -1 /dev/urandom | md5sum | cut -c 1-8` echo &quot;用户名：$newUser\t密码：$password&quot; &gt;&gt; user_passwd.txt fidone 从mysql查询数据12345read -p &apos;请输入你要查询的商品名称：&apos; nameread -p &apos;请输入数据库用户名：&apos; username/usr/bin/mysql -u$&#123;username&#125; -p -e &quot;use test;select * from item where name = &apos;$name&apos;;&quot;#注：-e表示excute，不进入mysql命令窗口，直接执行语句 高效登录远程服务器12345ip=`cat ip.txt | grep $1 | awk &apos;&#123;printf $2&#125;&apos;`ssh $ip执行：sh aaa.sh beijing #注：beijing赋值给$1，ip.txt文件中地址和ip使用空格隔开 最后推荐大家一个常用搜索Linux命名的网站：https://man.linuxde.net/，可以查看Linux命令的选项参数]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[spring retry 重试机制]]></title>
    <url>%2F2019%2F07%2F10%2Fspring-retry-%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[当我们调用一个接口可能由于网络等原因造成第一次失败，再去尝试就成功了，这就是重试机制，spring支持重试机制，并且在Spring Cloud中可以与Hystaix结合使用，可以避免访问到已经不正常的实例。 但是切记非幂等情况下慎用重试 加入依赖 org.springframework.retry spring-retry #### 在主类上加入 @EnableRetry 注解 123456789@EnableRetry //开启重试机制@EnableAutoConfiguration //开启自动配置@SpringBootApplicationpublic class SpringBootApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootApplication.class, args); &#125;&#125; 测试用例12345678910111213141516171819202122232425262728293031323334353637import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.retry.annotation.Backoff;import org.springframework.retry.annotation.Recover;import org.springframework.retry.annotation.Retryable;import org.springframework.stereotype.Service;import java.time.LocalTime;@Servicepublic class RetryService &#123; private final static Logger logger = LoggerFactory.getLogger(RetryService.class); private final int totalNum = 100000; @Retryable(value = Exception.class, maxAttempts = 3, backoff = @Backoff(delay = 2000L, multiplier = 1.5)) public void retry(int num) &#123; logger.info(&quot;减库存开始&quot; + LocalTime.now()); try &#123; int i = 1 / 0; &#125; catch (Exception e) &#123; logger.error(&quot;illegal&quot;); &#125; if (num &lt;= 0) &#123; throw new IllegalArgumentException(&quot;数量不对&quot;); &#125; logger.info(&quot;减库存执行结束&quot; + LocalTime.now()); &#125; @Recover public void recover(Exception e) &#123; logger.warn(&quot;减库存失败！！！&quot; + LocalTime.now()); &#125;&#125; 1234567891011public class RetryServiceTest extends BaseTest &#123; @Autowired private RetryService retryService; @Test public void retry() &#123; int count = retryService.retry(-1); System.out.println(&quot;库存为 ：&quot; + count); &#125;&#125; 结果： 1234567892019-07-10 09:52:08.691 INFO 21433 --- [ XNIO-2 task-1] c.c.c.serviceImpl.TestServiceImpl : 减库存开始09:52:08.6912019-07-10 09:52:08.691 ERROR 21433 --- [ XNIO-2 task-1] c.c.c.serviceImpl.TestServiceImpl : illegal2019-07-10 09:52:10.695 INFO 21433 --- [ XNIO-2 task-1] c.c.c.serviceImpl.TestServiceImpl : 减库存开始09:52:10.6952019-07-10 09:52:10.696 ERROR 21433 --- [ XNIO-2 task-1] c.c.c.serviceImpl.TestServiceImpl : illegal2019-07-10 09:52:13.701 INFO 21433 --- [ XNIO-2 task-1] c.c.c.serviceImpl.TestServiceImpl : 减库存开始09:52:13.7012019-07-10 09:52:13.709 ERROR 21433 --- [ XNIO-2 task-1] c.c.c.serviceImpl.TestServiceImpl : illegal2019-07-10 09:52:18.212 INFO 21433 --- [ XNIO-2 task-1] c.c.c.serviceImpl.TestServiceImpl : 减库存开始09:52:18.2122019-07-10 09:52:18.214 ERROR 21433 --- [ XNIO-2 task-1] c.c.c.serviceImpl.TestServiceImpl : illegal2019-07-10 09:52:18.214 WARN 21433 --- [ XNIO-2 task-1] c.c.c.serviceImpl.TestServiceImpl : 减库存失败！！！09:52:18.214 注解说明@Retryable的参数说明： value：抛出指定异常才会重试 include：和value一样，默认空，当exclude也为空时，所有异常都重试 exclude：指定不处理的异常 maxAttempts：最大重试次数，默认3次 backoff：重试等待策略，默认使用@Backoff @Backoff注解 delay:指定延迟后重试 multiplier（指定延迟倍数）默认为0，表示固定暂停1秒后进行重试，如果把multiplier设置为1.5，则第一次重试为2秒，第二次为3秒，第三次为4.5秒。 @Recover注解 当重试到达指定次数时，被注解的方法将被回调，可以在该方法中进行日志处理。需要注意的是发生的异常和入参类型一致时才会回调。 注意 使用了@Retryable的方法不能在本类被调用，不然重试机制不会生效。也就是要标记为@Service，然后在其它类使用@Autowired注入或者@Bean去实例才能生效。 要触发@Recover方法，那么在@Retryable方法上不能有返回值，只能是void才能生效。 非幂等情况下慎用 使用了@Retryable的方法里面不能使用try…catch包裹，要在方法上抛出异常，不然不会触发。 参考：https://my.oschina.net/wangjunBlog/blog/1889015]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HTTPS加密过程]]></title>
    <url>%2F2019%2F05%2F29%2FHTTPS%E5%8A%A0%E5%AF%86%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[认证服务器浏览器内置一个受信任的CA机构列表，并保存了这些CA机构的证书。第一阶段服务器会提供经CA机构认证颁发的服务器证书，如果认证该服务器证书的CA机构，存在于浏览器的受信任CA机构列表中，并且服务器证书中的信息与当前正在访问的网站（域名等）一致，那么浏览器就认为服务端是可信的，并从服务器证书中取得服务器公钥，用于后续流程。否则，浏览器将提示用户，根据用户的选择，决定是否继续。当然，我们可以管理这个受信任CA机构列表，添加我们想要信任的CA机构，或者移除我们不信任的CA机构。 协商会话密钥客户端在认证完服务器，获得服务器的公钥之后，利用该公钥与服务器进行加密通信，协商出两个会话密钥，分别是用于加密客户端往服务端发送数据的客户端会话密钥，用于加密服务端往客户端发送数据的服务端会话密钥。在已有服务器公钥，可以加密通讯的前提下，还要协商两个对称密钥的原因，是因为非对称加密相对复杂度更高，在数据传输过程中，使用对称加密，可以节省计算资源。另外，会话密钥是随机生成，每次协商都会有不一样的结果，所以安全性也比较高。 加密通讯此时客户端服务器双方都有了本次通讯的会话密钥，之后传输的所有的Http数据，都通过会话密钥加密。这样网路上的其它用户，将很难窃取和篡改客户端和服务端之间传输的数据，从而保证了数据的私密性和完整性。]]></content>
      <categories>
        <category>Https</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[快速了解23种设计模式]]></title>
    <url>%2F2019%2F05%2F15%2F%E5%BF%AB%E9%80%9F%E4%BA%86%E8%A7%A323%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[设计模式的分类设计模式有两种分类方法，即根据模式的目的来分和根据模式的作用的范围来分。 根据目的来分根据模式是用来完成什么工作来划分，这种方式可分为创建型模式、结构型模式和行为型模式3种。 创建型模式：用于描述“怎样创建对象”，它的主要特点是“将对象的创建与使用分离”。GoF 中提供了单例、原型、工厂方法、抽象工厂、建造者等 5 种创建型模式。 结构型模式：用于描述如何将类或对象按某种布局组成更大的结构，GoF 中提供了代理、适配器、桥接、装饰、外观、享元、组合等 7 种结构型模式。 行为型模式：用于描述类或对象之间怎样相互协作共同完成单个对象都无法单独完成的任务，以及怎样分配职责。GoF 中提供了模板方法、策略、命令、职责链、状态、观察者、中介者、迭代器、访问者、备忘录、解释器等 11 种行为型模式。 根据作用范围来分根据模式是主要用于类上还是主要用于对象上来分，这种方式可分为类模式和对象模式两种。 类模式：用于处理类与子类之间的关系，这些关系通过继承来建立，是静态的，在编译时刻便确定下来了。GoF中的工厂方法、（类）适配器、模板方法、解释器属于该模式。 对象模式：用于处理对象之间的关系，这些关系可以通过组合或聚合来实现，在运行时刻是可以变化的，更具动态性。GoF 中除了以上 4 种，其他的都是对象模式。 设计模式的六大原则总原则：开闭原则（Open Close Principle）开闭原则就是说对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，而是要扩展原有代码，实现一个热插拔的效果。所以一句话概括就是：为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类等。 单一职责原则不要存在多于一个导致类变更的原因，也就是说每个类应该实现单一的职责，如若不然，就应该把类拆分。 里氏替换原则（Liskov Substitution Principle）里氏代换原则(Liskov Substitution Principle LSP)面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。 LSP是继承复用的基石，只有当衍生类可以替换掉基类，软件单位的功能不受到影响时，基类才能真正被复用，而衍生类也能够在基类的基础上增加新的行为。里氏代换原则是对“开-闭”原则的补充。实现“开-闭”原则的关键步骤就是抽象化。而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。—— From Baidu 百科 历史替换原则中，子类对父类的方法尽量不要重写和重载。因为父类代表了定义好的结构，通过这个规范的接口与外界交互，子类不应该随便破坏它。 依赖倒转原则（Dependence Inversion Principle）这个是开闭原则的基础，具体内容：面向接口编程，依赖于抽象而不依赖于具体。写代码时用到具体类时，不与具体类交互，而与具体类的上层接口交互。 接口隔离原则（Interface Segregation Principle）这个原则的意思是：每个接口中不存在子类用不到却必须实现的方法，如果不然，就要将接口拆分。使用多个隔离的接口，比使用单个接口（多个接口方法集合到一个的接口）要好。 迪米特法则（最少知道原则）（Demeter Principle）就是说：一个类对自己依赖的类知道的越少越好。也就是说无论被依赖的类多么复杂，都应该将逻辑封装在方法的内部，通过public方法提供给外部。这样当被依赖的类变化时，才能最小的影响该类。 最少知道原则的另一个表达方式是：只与直接的朋友通信。类之间只要有耦合关系，就叫朋友关系。耦合分为依赖、关联、聚合、组合等。我们称出现为成员变量、方法参数、方法返回值中的类为直接朋友。局部变量、临时变量则不是直接的朋友。我们要求陌生的类不要作为局部变量出现在类中。 合成复用原则（Composite Reuse Principle）原则是尽量首先使用合成/聚合的方式，而不是使用继承。 Java的23中设计模式 单例（Singleton）模式：某个类只能生成一个实例，该类提供了一个全局访问点供外部获取该实例，其拓展是有限多例模式。 原型（Prototype）模式：将一个对象作为原型，通过对其进行复制而克隆出多个和原型类似的新实例。 工厂方法（Factory Method）模式：定义一个用于创建产品的接口，由子类决定生产什么产品。 抽象工厂（AbstractFactory）模式：提供一个创建产品族的接口，其每个子类可以生产一系列相关的产品。 建造者（Builder）模式：将一个复杂对象分解成多个相对简单的部分，然后根据不同需要分别创建它们，最后构建成该复杂对象。 代理（Proxy）模式：为某对象提供一种代理以控制对该对象的访问。即客户端通过代理间接地访问该对象，从而限制、增强或修改该对象的一些特性。 适配器（Adapter）模式：将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。 桥接（Bridge）模式：将抽象与实现分离，使它们可以独立变化。它是用组合关系代替继承关系来实现，从而降低了抽象和实现这两个可变维度的耦合度。 装饰（Decorator）模式：动态的给对象增加一些职责，即增加其额外的功能。 外观（Facade）模式：为多个复杂的子系统提供一个一致的接口，使这些子系统更加容易被访问。 享元（Flyweight）模式：运用共享技术来有效地支持大量细粒度对象的复用。 组合（Composite）模式：将对象组合成树状层次结构，使用户对单个对象和组合对象具有一致的访问性。 模板方法（TemplateMethod）模式：定义一个操作中的算法骨架，而将算法的一些步骤延迟到子类中，使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。 策略（Strategy）模式：定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的改变不会影响使用算法的客户。 命令（Command）模式：将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。 职责链（Chain of Responsibility）模式：把请求从链中的一个对象传到下一个对象，直到请求被响应为止。通过这种方式去除对象之间的耦合。 状态（State）模式：允许一个对象在其内部状态发生改变时改变其行为能力。 观察者（Observer）模式：多个对象间存在一对多关系，当一个对象发生改变时，把这种改变通知给其他多个对象，从而影响其他对象的行为。 中介者（Mediator）模式：定义一个中介对象来简化原有对象之间的交互关系，降低系统中对象间的耦合度，使原有对象之间不必相互了解。 迭代器（Iterator）模式：提供一种方法来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。 访问者（Visitor）模式：在不改变集合元素的前提下，为一个集合中的每个元素提供多种访问方式，即每个元素有多个访问者对象访问。 备忘录（Memento）模式：在不破坏封装性的前提下，获取并保存一个对象的内部状态，以便以后恢复它。 解释器（Interpreter）模式：提供如何定义语言的文法，以及对语言句子的解释方法，即解释器。 总结设计模式的本质是面向对象设计原则的实际运用，是对类的封装性、继承性和多态性以及类的关联关系和组合关系的充分理解。正确使用设计模式具有以下优点。 可以提高程序员的思维能力、编程能力和设计能力。 使程序设计更加标准化、代码编制更加工程化，使软件开发效率大大提高，从而缩短软件的开发周期。 使设计的代码可重用性高、可读性强、可靠性高、灵活性好、可维护性强。 当然，软件设计模式只是一个引导。在具体的软件幵发中，必须根据设计的应用系统的特点和要求来恰当选择。对于简单的程序开发，苛能写一个简单的算法要比引入某种设计模式更加容易。但对大项目的开发或者框架设计，用设计模式来组织代码显然更好。 参考博客：https://blog.csdn.net/tsite/article/details/62420091https://www.cnblogs.com/geek6/p/3951677.htmlhttp://c.biancheng.net/view/1320.html]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基准测试神器-JMH]]></title>
    <url>%2F2019%2F05%2F14%2F%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E7%A5%9E%E5%99%A8-JMH%2F</url>
    <content type="text"><![CDATA[原文地址：https://sq.163yun.com/blog/article/179671960481783808 概述性能测试这个话题非常庞大，我们可以从网络聊到操作系统，再从操作系统聊到内核，再从内核聊到你怀疑人生有木有。 先拍几个砖出来吧，我在写代码的时候经常有这种怀疑：写法A快还是写法B快，某个位置是用ArrayList还是LinkedList，HashMap还是TreeMap，HashMap的初始化size要不要指定，指定之后究竟比默认的DEFAULT_SIZE性能好多少。。。 如果你还是通过for循环或者手撸method来测试你的内容的话，那么JMH就是你必须要明白的内容了，因为已经有人把基准测试的轮子造好了，接下来我们就一起看看这个轮子怎么用： JMH只适合细粒度的方法测试，并不适用于系统之间的链路测试！JMH只适合细粒度的方法测试，并不适用于系统之间的链路测试！JMH只适合细粒度的方法测试，并不适用于系统之间的链路测试！ JMH入门JMH是一个工具包，如果我们要通过JMH进行基准测试的话，直接在我们的pom文件中引入JMH的依赖即可： 12345678910&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jmh&lt;/groupId&gt; &lt;artifactId&gt;jmh-core&lt;/artifactId&gt; &lt;version&gt;1.19&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jmh&lt;/groupId&gt; &lt;artifactId&gt;jmh-generator-annprocess&lt;/artifactId&gt; &lt;version&gt;1.19&lt;/version&gt;&lt;/dependency&gt; 通过一个HelloWorld程序来看一下JMH如果工作： @Warmup(iterations = 5, time = 1, timeUnit = TimeUnit.SECONDS)@Measurement(iterations = 5, time = 1, timeUnit = TimeUnit.SECONDS)public class JMHSample_01_HelloWorld { static class Demo { int id; String name; public Demo(int id, String name) { this.id = id; this.name = name; } } static List&lt;Demo&gt; demoList; static { demoList = new ArrayList(); for (int i = 0; i &lt; 10000; i ++) { demoList.add(new Demo(i, &quot;test&quot;)); } } @Benchmark @BenchmarkMode(Mode.AverageTime) @OutputTimeUnit(TimeUnit.MICROSECONDS) public void testHashMapWithoutSize() { Map map = new HashMap(); for (Demo demo : demoList) { map.put(demo.id, demo.name); } } @Benchmark @BenchmarkMode(Mode.AverageTime) @OutputTimeUnit(TimeUnit.MICROSECONDS) public void testHashMap() { Map map = new HashMap((int)(demoList.size() / 0.75f) + 1); for (Demo demo : demoList) { map.put(demo.id, demo.name); } } public static void main(String[] args) throws RunnerException { Options opt = new OptionsBuilder() .include(JMHSample_01_HelloWorld.class.getSimpleName()) .forks(1) .build(); new Runner(opt).run(); }} ======================================执行结果======================================Benchmark Mode Cnt Score Error UnitschargeProject.List.JMHSample_01_HelloWorld.testHashMap avgt 5 130.865 ± 5.851 us/opchargeProject.List.JMHSample_01_HelloWorld.testHashMapWithoutSize avgt 5 172.087 ± 66.252 us/op======================================执行结果====================================== 上面的代码用中文翻译一下：分别定义两个基准测试的方法testHashMapWithoutSize和 testHashMap，这两个基准测试方法执行流程是：每个方法执行前都进行5次预热执行，每隔1秒进行一次预热操作，预热执行结束之后进行5次实际测量执行，每隔1秒进行一次实际执行，我们此次基准测试测量的是平均响应时长，单位是us。 预热？为什么要预热？因为 JVM 的 JIT 机制的存在，如果某个函数被调用多次之后，JVM 会尝试将其编译成为机器码从而提高执行速度。为了让 benchmark 的结果更加接近真实情况就需要进行预热。 从上面的执行结果我们看出，针对一个Map的初始化参数的给定其实有很大影响，当我们给定了初始化参数执行执行的速度是没给定参数的2/3，这个优化速度还是比较明显的，所以以后大家在初始化Map的时候能给定参数最好都给定了，代码是处处优化的，积少成多。 通过上面的内容我们已经基本可以看出来JMH的写法雏形了，后面的介绍主要是一些注解的使用： @Benchmark@Benchmark标签是用来标记测试方法的，只有被这个注解标记的话，该方法才会参与基准测试，但是有一个基本的原则就是被@Benchmark标记的方法必须是public的。 @Warmup@Warmup用来配置预热的内容，可用于类或者方法上，越靠近执行方法的地方越准确。一般配置warmup的参数有这些： iterations：预热的次数。 time：每次预热的时间。 timeUnit：时间单位，默认是s。 batchSize：批处理大小，每次操作调用几次方法。（后面用到） @Measurement用来控制实际执行的内容，配置的选项本warmup一样。 @BenchmarkMode@BenchmarkMode主要是表示测量的纬度，有以下这些纬度可供选择： Mode.Throughput 吞吐量纬度 Mode.AverageTime 平均时间 Mode.SampleTime 抽样检测 Mode.SingleShotTime 检测一次调用 Mode.All 运用所有的检测模式 在方法级别指定@BenchmarkMode的时候可以一定指定多个纬度，例如： @BenchmarkMode({Mode.Throughput, Mode.AverageTime, Mode.SampleTime, Mode.SingleShotTime})，代表同时在多个纬度对目标方法进行测量。 @OutputTimeUnit@OutputTimeUnit代表测量的单位，比如秒级别，毫秒级别，微妙级别等等。一般都使用微妙和毫秒级别的稍微多一点。该注解可以用在方法级别和类级别，当用在类级别的时候会被更加精确的方法级别的注解覆盖，原则就是离目标更近的注解更容易生效。 @State在很多时候我们需要维护一些状态内容，比如在多线程的时候我们会维护一个共享的状态，这个状态值可能会在每隔线程中都一样，也有可能是每个线程都有自己的状态，JMH为我们提供了状态的支持。该注解只能用来标注在类上，因为类作为一个属性的载体。 @State的状态值主要有以下几种： Scope.Benchmark 该状态的意思是会在所有的Benchmark的工作线程中共享变量内容。 Scope.Group 同一个Group的线程可以享有同样的变量 Scope.Thread 每隔线程都享有一份变量的副本，线程之间对于变量的修改不会相互影响。 下面看两个常见的@State的写法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253541.直接在内部类中使用@State作为“PropertyHolder”public class JMHSample_03_States &#123; @State(Scope.Benchmark) public static class BenchmarkState &#123; volatile double x = Math.PI; &#125; @State(Scope.Thread) public static class ThreadState &#123; volatile double x = Math.PI; &#125; @Benchmark public void measureUnshared(ThreadState state) &#123; state.x++; &#125; @Benchmark public void measureShared(BenchmarkState state) &#123; state.x++; &#125; public static void main(String[] args) throws RunnerException &#123; Options opt = new OptionsBuilder() .include(JMHSample_03_States.class.getSimpleName()) .threads(4) .forks(1) .build(); new Runner(opt).run(); &#125;&#125;2.在Main类中直接使用@State作为注解，是Main类直接成为“PropertyHolder”@State(Scope.Thread)public class JMHSample_04_DefaultState &#123; double x = Math.PI; @Benchmark public void measure() &#123; x++; &#125; public static void main(String[] args) throws RunnerException &#123; Options opt = new OptionsBuilder() .include(JMHSample_04_DefaultState.class.getSimpleName()) .forks(1) .build(); new Runner(opt).run(); &#125;&#125; 我们试想以下@State的含义，它主要是方便框架来控制变量的过程逻辑，通过@State标示的类都被用作属性的容器，然后框架可以通过自己的控制来配置不同级别的隔离情况。被@Benchmark标注的方法可以有参数，但是参数必须是被@State注解的，就是为了要控制参数的隔离。 但是有些情况下我们需要对参数进行一些初始化或者释放的操作，就像Spring提供的一些init和destory方法一样，JHM也提供有这样的钩子： @Setup 必须标示在@State注解的类内部，表示初始化操作 @TearDown 必须表示在@State注解的类内部，表示销毁操作 初始化和销毁的动作都只会执行一次。 1234567891011121314151617181920212223242526272829@State(Scope.Thread)public class JMHSample_05_StateFixtures &#123; double x; @Setup public void prepare() &#123; x = Math.PI; &#125; @TearDown public void check() &#123; assert x &gt; Math.PI : &quot;Nothing changed?&quot;; &#125; @Benchmark public void measureRight() &#123; x++; &#125; public static void main(String[] args) throws RunnerException &#123; Options opt = new OptionsBuilder() .include(JMHSample_05_StateFixtures.class.getSimpleName()) .forks(1) .jvmArgs(&quot;-ea&quot;) .build(); new Runner(opt).run(); &#125;&#125; 虽然我们可以执行初始化和销毁的动作，但是总是感觉还缺点啥？对，就是初始化的粒度。因为基准测试往往会执行多次，那么能不能保证每次执行方法的时候都初始化一次变量呢？ @Setup和@TearDown提供了以下三种纬度的控制： Level.Trial 只会在个基础测试的前后执行。包括Warmup和Measurement阶段，一共只会执行一次。 Level.Iteration 每次执行记住测试方法的时候都会执行，如果Warmup和Measurement都配置了2次执行的话，那么@Setup和@TearDown配置的方法的执行次数就4次。 Level.Invocation 每个方法执行的前后执行（一般不推荐这么用） @Param在很多情况下，我们需要测试不同的参数的不同结果，但是测试的了逻辑又都是一样的，因此如果我们编写镀铬benchmark的话会造成逻辑的冗余，幸好JMH提供了@Param参数来帮助我们处理这个事情，被@Param注解标示的参数组会一次被benchmark消费到。 1234567891011121314151617181920@State(Scope.Benchmark)public class ParamTest &#123; @Param(&#123;&quot;1&quot;, &quot;2&quot;, &quot;3&quot;&#125;) int testNum; @Benchmark public String test() &#123; return String.valueOf(testNum); &#125; public static void main(String[] args) throws RunnerException &#123; Options opt = new OptionsBuilder() .include(ParamTest.class.getSimpleName()) .forks(1) .build(); new Runner(opt).run(); &#125;&#125; @Threads测试线程的数量，可以配置在方法或者类上，代表执行测试的线程数量。 通常看到这里我们会比较迷惑Iteration和Invocation区别，我们在配置Warmup的时候默认的时间是的1s，即1s的执行作为一个Iteration，假设每次方法的执行是100ms的话，那么1个Iteration就代表10个Invocation。 JMH进阶通过以上的内容我们已经基本可以掌握JMH的使用了，下面就主要介绍一下JMH提供的一些高级特性了。 不要编写无用代码 因为现代的编译器非常聪明，如果我们在代码使用了没有用处的变量的话，就容易被编译器优化掉，这就会导致实际的测量结果可能不准确，因为我们要在测量的方法中避免使用void方法，然后记得在测量的结束位置返回结果。这么做的目的很明确，就是为了与编译器斗智斗勇，让编译器不要改变这段代码执行的初衷。 Blackhole介绍Blackhole会消费传进来的值，不提供任何信息来确定这些值是否在之后被实际使用。 Blackhole处理的事情主要有以下几种： 死代码消除：入参应该在每次都被用到，因此编译器就不会把这些参数优化为常量或者在计算的过程中对他们进行其他优化。 处理内存壁：我们需要尽可能减少写的量，因为它会干扰缓存，污染写缓冲区等。 这很可能导致过早地撞到内存壁 我们在上面说到需要消除无用代码，那么其中一种方式就是通过Blackhole，我们可以用Blackhole来消费这些返回的结果。 1234567891011121:返回测试结果，防止编译器优化@Benchmarkpublic double measureRight_1() &#123; return Math.log(x1) + Math.log(x2);&#125;2.通过Blackhole消费中间结果，防止编译器优化@Benchmarkpublic void measureRight_2(Blackhole bh) &#123; bh.consume(Math.log(x1)); bh.consume(Math.log(x2));&#125; 循环处理我们虽然可以在Benchmark中定义循环逻辑，但是这么做其实是不合适的，因为编译器可能会将我们的循环进行展开或者做一些其他方面的循环优化，所以JHM建议我们不要在Beanchmark中使用循环，如果我们需要处理循环逻辑了，可以结合@BenchmarkMode(Mode.SingleShotTime)和@Measurement(batchSize = N)来达到同样的效果. 123456789101112131415161718192021222324252627282930@State(Scope.Thread)public class JMHSample_26_BatchSize &#123; List&lt;String&gt; list = new LinkedList&lt;&gt;(); // 每个iteration中做5000次Invocation @Benchmark @Warmup(iterations = 5, batchSize = 5000) @Measurement(iterations = 5, batchSize = 5000) @BenchmarkMode(Mode.SingleShotTime) public List&lt;String&gt; measureRight() &#123; list.add(list.size() / 2, &quot;something&quot;); return list; &#125; @Setup(Level.Iteration) public void setup()&#123; list.clear(); &#125; public static void main(String[] args) throws RunnerException &#123; Options opt = new OptionsBuilder() .include(JMHSample_26_BatchSize.class.getSimpleName()) .forks(1) .build(); new Runner(opt).run(); &#125;&#125; 方法内联方法内联：如果JVM监测到一些小方法被频繁的执行，它会把方法的调用替换成方法体本身。比如说下面这个： 1234567private int add4(int x1, int x2, int x3, int x4) &#123; return add2(x1, x2) + add2(x3, x4); &#125; private int add2(int x1, int x2) &#123; return x1 + x2; &#125; 运行一段时间后JVM会把add2方法去掉，并把你的代码翻译成： 123private int add4(int x1, int x2, int x3, int x4) &#123; return x1 + x2 + x3 + x4; &#125; JMH提供了CompilerControl注解来控制方法内联，但是实际上我感觉比较有用的就是两个了： CompilerControl.Mode.DONT_INLINE：强制限制不能使用内联 CompilerControl.Mode.INLINE：强制使用内联 看一下官方提供的例子把： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@State(Scope.Thread)@BenchmarkMode(Mode.AverageTime)@OutputTimeUnit(TimeUnit.NANOSECONDS)public class JMHSample_16_CompilerControl &#123; public void target_blank() &#123; &#125; @CompilerControl(CompilerControl.Mode.DONT_INLINE) public void target_dontInline() &#123; &#125; @CompilerControl(CompilerControl.Mode.INLINE) public void target_inline() &#123; &#125; @Benchmark public void baseline() &#123; &#125; @Benchmark public void dontinline() &#123; target_dontInline(); &#125; @Benchmark public void inline() &#123; target_inline(); &#125; public static void main(String[] args) throws RunnerException &#123; Options opt = new OptionsBuilder() .include(JMHSample_16_CompilerControl.class.getSimpleName()) .warmupIterations(0) .measurementIterations(3) .forks(1) .build(); new Runner(opt).run(); &#125;&#125;======================================执行结果==============================Benchmark Mode Cnt Score Error UnitsJMHSample_16_CompilerControl.baseline avgt 3 0.896 ± 3.426 ns/opJMHSample_16_CompilerControl.dontinline avgt 3 0.344 ± 0.126 ns/opJMHSample_16_CompilerControl.inline avgt 3 0.391 ± 2.622 ns/op======================================执行结果==============================]]></content>
      <categories>
        <category>JMH</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[八大排序算法总结基于java实现]]></title>
    <url>%2F2019%2F05%2F13%2F%E5%85%AB%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93%E5%9F%BA%E4%BA%8Ejava%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[原文链接：https://github.com/iTimeTraveler/SortAlgorithms 概述对常用的八大排序算法进行总结。 直接插入排序 希尔排序 简单选择排序 堆排序 冒泡排序 快速排序 归并排序 基数排序 它们都属于内部排序，也就是只考虑数据量较小仅需要使用内存的排序算法，他们之间关系如下： 直接插入排序（Insertion Sort）插入排序的设计初衷是往有序的数组中快速插入一个新的元素。它的算法思想是：把要排序的数组分为了两个部分, 一部分是数组的全部元素(除去待插入的元素), 另一部分是待插入的元素; 先将第一部分排序完成, 然后再插入这个元素.。其中第一部分的排序也是通过再次拆分为两部分来进行的。 插入排序由于操作不尽相同, 可分为 直接插入排序 , 折半插入排序(又称二分插入排序), 链表插入排序 , 希尔排序 。我们先来看下直接插入排序。 基本思想直接插入排序的基本思想是：将数组中的所有元素依次跟前面已经排好的元素相比较，如果选择的元素比已排序的元素小，则交换，直到全部元素都比较过为止。 算法描述一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下： ①. 从第一个元素开始，该元素可以认为已经被排序②. 取出下一个元素，在已经排序的元素序列中从后向前扫描③. 如果该元素（已排序）大于新元素，将该元素移到下一位置④. 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置⑤. 将新元素插入到该位置后⑥. 重复步骤②~⑤ 算法实现中比较有意思的一点是，在每次比较操作发现取出来的新元素小于等于已排序的元素时，可以将已排序的元素移到下一位置，然后将取出来的新元素插入该位置（即相邻位置对调），接着再与前面的已排序的元素进行比较，如上图所示，这样做缺点是交换操作代价比较大。另一种做法是：将新元素取出（挖坑），从左到右依次与已排序的元素比较，如果已排序的元素大于取出的新元素，那么将该元素移动到下一个位置（填坑），接着再与前面的已排序的元素比较，直到找到已排序的元素小于等于新元素的位置，这时再将新元素插入进去。就像基本思想中的动图演示的那样。 如果比较操作的代价比交换操作大的话，可以采用二分查找法来减少比较操作的数目。可以认为是插入排序的一个变种，称为二分查找插入排序。 代码实现1234567891011121314151617181920212223242526272829303132333435/** * 插入排序 * * 1. 从第一个元素开始，该元素可以认为已经被排序 * 2. 取出下一个元素，在已经排序的元素序列中从后向前扫描 * 3. 如果该元素（已排序）大于新元素，将该元素移到下一位置 * 4. 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置 * 5. 将新元素插入到该位置后 * 6. 重复步骤2~5 * @param arr 待排序数组 */public static void insertionSort(int[] arr)&#123; for( int i = 1; i &lt; arr.length; i++ ) &#123; int temp = arr[i]; // 取出下一个元素，在已经排序的元素序列中从后向前扫描 for( int j = i; j &gt;= 0; j-- ) &#123; if( j &gt; 0 &amp;&amp; arr[j-1] &gt; temp ) &#123; arr[j] = arr[j-1]; // 如果该元素（已排序）大于取出的元素temp，将该元素移到下一位置 System.out.println(&quot;Temping: &quot; + Arrays.toString(arr)); &#125; else &#123; // 将新元素插入到该位置后 arr[j] = temp; System.out.println(&quot;Sorting: &quot; + Arrays.toString(arr)); break; &#125; &#125; &#125;&#125;// 交换次数较多的实现public static void insertionSort(int[] arr)&#123; for( int i=0; i&lt;arr.length-1; i++ ) &#123; for( int j=i+1; j&gt;0; j-- ) &#123; if( arr[j-1] &lt;= arr[j] ) break; int temp = 复杂度直接插入排序复杂度如下： 最好情况下，排序前对象已经按照要求的有序。比较次数(KCN)：[Math Processing Error]；移动次数(RMN)为[Math Processing Error]。则对应的时间复杂度为[Math Processing Error]。 最坏情况下，排序前对象为要求的顺序的反序。第i趟时第i个对象必须与前面i个对象都做排序码比较，并且每做1次比较就要做1次数据移动（从上面给出的代码中看出）。比较次数(KCN)：[Math Processing Error] ; 移动次数(RMN)为：[Math Processing Error]。则对应的时间复杂度为[Math Processing Error]。 如果排序记录是随机的，那么根据概率相同的原则，在平均情况下的排序码比较次数和对象移动次数约为[Math Processing Error]，因此，直接插入排序的平均时间复杂度为[Math Processing Error]。 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(n²) O(n) O(n²) O(1) Tips: 由于直接插入排序每次只移动一个元素的位， 并不会改变值相同的元素之间的排序， 因此它是一种稳定排序。 希尔排序（Shell Sort）希尔排序，也称递减增量排序算法，1959年Shell发明。是插入排序的一种高速而稳定的改进版本。 希尔排序是先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行依次直接插入排序。 第一个突破O(n^2)的排序算法；是简单插入排序的改进版；它与插入排序的不同之处在于，它会优先比较距离较远的元素。基本思想将待排序数组按照步长gap进行分组，然后将每组的元素利用直接插入排序的方法进行排序；每次再将gap折半减小，循环上述操作；当gap=1时，利用直接插入，完成排序。 可以看到步长的选择是希尔排序的重要部分。只要最终步长为1任何步长序列都可以工作。一般来说最简单的步长取值是初次取数组长度的一半为增量，之后每次再减半，直到增量为1。更好的步长序列取值可以参考维基百科。 算法描述①. 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；（一般初次取数组半长，之后每次再减半，直到增量为1）②. 按增量序列个数k，对序列进行k 趟排序；③. 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 代码实现以下是我自己的实现，可以看到实现很幼稚，但是好处是理解起来很简单。因为没有经过任何的优化，所以不建议大家直接使用。建议对比下方的维基百科官方实现代码，特别是步长取值策略部分。 123456789101112131415161718192021222324/** * 希尔排序 * * 1. 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；（一般初次取数组半长，之后每次再减半，直到增量为1） * 2. 按增量序列个数k，对序列进行k 趟排序； * 3. 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。 * 仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 * @param arr 待排序数组 */public static void shellSort(int[] arr)&#123; int gap = arr.length / 2; for (; gap &gt; 0; gap /= 2) &#123; //不断缩小gap，直到1为止 for (int j = 0; (j+gap) &lt; arr.length; j++)&#123; //使用当前gap进行组内插入排序 for(int k = 0; (k+gap)&lt; arr.length; k += gap)&#123; if(arr[k] &gt; arr[k+gap]) &#123; int temp = arr[k+gap]; //交换操作 arr[k+gap] = arr[k]; arr[k] = temp; System.out.println(&quot; Sorting: &quot; + Arrays.toString(arr)); &#125; &#125; &#125; &#125;&#125; 注意： ①. 第一层for循环表示一共有多少个增量。增量的序列的个数，就是希尔排序的趟数。上面的增量序列为： arr.length/2, arr.length/2/2, arr.length/2/2/2, …. 2, 1②. 里层的两个for循环，实际上就是以一个gap拆分为一组的组内插入排序。 下面是维基百科官方实现，大家注意gap步长取值部分： 1234567891011121314151617181920212223/** * 希尔排序（Wiki官方版） * * 1. 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；（注意此算法的gap取值） * 2. 按增量序列个数k，对序列进行k 趟排序； * 3. 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。 * 仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 * @param arr 待排序数组 */public static void shell_sort(int[] arr) &#123; int gap = 1, i, j, len = arr.length; int temp; while (gap &lt; len / 3) gap = gap * 3 + 1; // &lt;O(n^(3/2)) by Knuth,1973&gt;: 1, 4, 13, 40, 121, ... for (; gap &gt; 0; gap /= 3) &#123; for (i = gap; i &lt; len; i++) &#123; temp = arr[i]; for (j = i - gap; j &gt;= 0 &amp;&amp; arr[j] &gt; temp; j -= gap) arr[j + gap] = arr[j]; arr[j + gap] = temp; &#125; &#125;&#125; 复杂度 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(nlog2 n) O(nlog2 n) O(nlog2 n) O(1) 选择排序（Selection Sort）从算法逻辑上看，选择排序是一种简单直观的排序算法，在简单选择排序过程中，所需移动记录的次数比较少。 基本思想选择排序的基本思想：比较 + 交换。 在未排序序列中找到最小（大）元素，存放到未排序序列的起始位置。在所有的完全依靠交换去移动元素的排序方法中，选择排序属于非常好的一种。 算法描述①. 从待排序序列中，找到关键字最小的元素；②. 如果最小元素不是待排序序列的第一个元素，将其和第一个元素互换；③. 从余下的 N - 1 个元素中，找出关键字最小的元素，重复①、②步，直到排序结束。 代码实现选择排序比较简单，以下是我自己的实现，跟官方版差不多，所以完全可以参考。 12345678910111213141516171819202122232425/** * 选择排序 * * 1. 从待排序序列中，找到关键字最小的元素； * 2. 如果最小元素不是待排序序列的第一个元素，将其和第一个元素互换； * 3. 从余下的 N - 1 个元素中，找出关键字最小的元素，重复①、②步，直到排序结束。 * 仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 * @param arr 待排序数组 */public static void selectionSort(int[] arr)&#123; for(int i = 0; i &lt; arr.length-1; i++)&#123; int min = i; for(int j = i+1; j &lt; arr.length; j++)&#123; //选出之后待排序中值最小的位置 if(arr[j] &lt; arr[min])&#123; min = j; &#125; &#125; if(min != i)&#123; int temp = arr[min]; //交换操作 arr[min] = arr[i]; arr[i] = temp; System.out.println(&quot;Sorting: &quot; + Arrays.toString(arr)); &#125; &#125;&#125; 复杂度 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(n²) O(n²) O(n²) O(1) 选择排序的简单和直观名副其实，这也造就了它”出了名的慢性子”，无论是哪种情况，哪怕原数组已排序完成，它也将花费将近n²/2次遍历来确认一遍。即便是这样，它的排序结果也还是不稳定的。 唯一值得高兴的是，它并不耗费额外的内存空间。 堆排序（Heap Sort）1991年的计算机先驱奖获得者、斯坦福大学计算机科学系教授罗伯特·弗洛伊德(Robert W．Floyd) 和威廉姆斯(J．Williams) 在1964年共同发明了著名的堆排序算法(Heap Sort). 堆的定义如下：n个元素的序列{k1,k2,···,kn}，当且仅当满足下关系时，称之为堆。 ki &lt;= k(2i) 且 ki &lt;= k(2i+1) 或： ki &gt;= k(2i) 且 ki &gt;= k(2i+1) 把此序列对应的二维数组看成一个完全二叉树。那么堆的含义就是完全二叉树中任何一个非叶子节点的值均不大于（或不小于）其左，右孩子节点的值。由上述性质可知大顶堆的堆顶的关键字肯定是所有关键字中最大的，小顶堆的堆顶的关键字是所有关键字中最小的。因此我们可使用大顶堆进行升序排序, 使用小顶堆进行降序排序。 基本思想此处以大顶堆为例，堆排序的过程就是将待排序的序列构造成一个堆，选出堆中最大的移走，再把剩余的元素调整成堆，找出最大的再移走，重复直至有序。 算法描述①. 先将初始序列K[1..n]建成一个大顶堆, 那么此时第一个元素K1最大, 此堆为初始的无序区.②. 再将关键字最大的记录K1 (即堆顶, 第一个元素)和无序区的最后一个记录 Kn 交换, 由此得到新的无序区K[1..n-1]和有序区K[n], 且满足K[1..n-1].keys &lt;= K[n].key③. 交换K1 和 Kn 后, 堆顶可能违反堆性质, 因此需将K[1..n-1]调整为堆. 然后重复步骤②, 直到无序区只有一个元素时停止. 动图效果如下所示： 代码实现从算法描述来看，堆排序需要两个过程，一是建立堆，二是堆顶与堆的最后一个元素交换位置。所以堆排序有两个函数组成。一是建堆函数，二是反复调用建堆函数以选择出剩余未排元素中最大的数来实现排序的函数。 总结起来就是定义了以下几种操作： 最大堆调整（Max_Heapify）：将堆的末端子节点作调整，使得子节点永远小于父节点创建最大堆（Build_Max_Heap）：将堆所有数据重新排序堆排序（HeapSort）：移除位在第一个数据的根节点，并做最大堆调整的递归运算对于堆节点的访问： 父节点i的左子节点在位置：(2*i+1); 父节点i的右子节点在位置：(2*i+2); 子节点i的父节点在位置：floor((i-1)/2);1234567891011121314151617181920212223242526272829303132333435363738/** * 堆排序 * * 1. 先将初始序列K[1..n]建成一个大顶堆, 那么此时第一个元素K1最大, 此堆为初始的无序区. * 2. 再将关键字最大的记录K1 (即堆顶, 第一个元素)和无序区的最后一个记录 Kn 交换, 由此得到新的无序区K[1..n−1]和有序区K[n], 且满足K[1..n−1].keys⩽K[n].key * 3. 交换K1 和 Kn 后, 堆顶可能违反堆性质, 因此需将K[1..n−1]调整为堆. 然后重复步骤②, 直到无序区只有一个元素时停止. * @param arr 待排序数组 */public static void heapSort(int[] arr)&#123; for(int i = arr.length; i &gt; 0; i--)&#123; max_heapify(arr, i); int temp = arr[0]; //堆顶元素(第一个元素)与Kn交换 arr[0] = arr[i-1]; arr[i-1] = temp; &#125;&#125;private static void max_heapify(int[] arr, int limit)&#123; if(arr.length &lt;= 0 || arr.length &lt; limit) return; int parentIdx = limit / 2; for(; parentIdx &gt;= 0; parentIdx--)&#123; if(parentIdx * 2 &gt;= limit)&#123; continue; &#125; int left = parentIdx * 2; //左子节点位置 int right = (left + 1) &gt;= limit ? left : (left + 1); //右子节点位置，如果没有右节点，默认为左节点位置 int maxChildId = arr[left] &gt;= arr[right] ? left : right; if(arr[maxChildId] &gt; arr[parentIdx])&#123; //交换父节点与左右子节点中的最大值 int temp = arr[parentIdx]; arr[parentIdx] = arr[maxChildId]; arr[maxChildId] = temp; &#125; &#125; System.out.println(&quot;Max_Heapify: &quot; + Arrays.toString(arr));&#125; 注: x&gt;&gt;1 是位运算中的右移运算, 表示右移一位, 等同于x除以2再取整, 即 x&gt;&gt;1 == Math.floor(x/2) . 复杂度以上, ①. 建立堆的过程, 从length/2 一直处理到0, 时间复杂度为O(n); ②. 调整堆的过程是沿着堆的父子节点进行调整, 执行次数为堆的深度, 时间复杂度为O(lgn); ③. 堆排序的过程由n次第②步完成, 时间复杂度为O(nlgn). 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(nlog2 n) O(nlog2 n) O(nlog2 n) O(1) Tips: 由于堆排序中初始化堆的过程比较次数较多, 因此它不太适用于小序列。同时由于多次任意下标相互交换位置, 相同元素之间原本相对的顺序被破坏了, 因此, 它是不稳定的排序. #### 冒泡排序（Bubble Sort） 我想对于它每个学过C语言的都会了解，这可能是很多人接触的第一个排序算法。 基本思想冒泡排序（Bubble Sort）是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。 算法描述冒泡排序算法的运作如下： ①. 比较相邻的元素。如果第一个比第二个大，就交换他们两个。②. 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。③. 针对所有的元素重复以上的步骤，除了最后一个。④. 持续每次对越来越少的元素重复上面的步骤①~③，直到没有任何一对数字需要比较。 代码实现冒泡排序需要两个嵌套的循环. 其中, 外层循环移动游标; 内层循环遍历游标及之后(或之前)的元素, 通过两两交换的方式, 每次只确保该内循环结束位置排序正确, 然后内层循环周期结束, 交由外层循环往后(或前)移动游标, 随即开始下一轮内层循环, 以此类推, 直至循环结束. 123456789101112131415161718192021/** * 冒泡排序 * * ①. 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 * ②. 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。 * ③. 针对所有的元素重复以上的步骤，除了最后一个。 * ④. 持续每次对越来越少的元素重复上面的步骤①~③，直到没有任何一对数字需要比较。 * @param arr 待排序数组 */public static void bubbleSort(int[] arr)&#123; for (int i = arr.length - 1; i &gt; 0; i--) &#123; //外层循环移动游标 for(int j = 0; j &lt; i; j++)&#123; //内层循环遍历游标及之后(或之前)的元素 if(arr[j] &gt; arr[j+1])&#123; int temp = arr[j]; arr[j] = arr[j+1]; arr[j+1] = temp; System.out.println(&quot;Sorting: &quot; + Arrays.toString(arr)); &#125; &#125; &#125;&#125; 复杂度 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(n²) O(n) O(n²) O(1) 冒泡排序是最容易实现的排序, 最坏的情况是每次都需要交换, 共需遍历并交换将近n²/2次, 时间复杂度为O(n²). 最佳的情况是内循环遍历一次后发现排序是对的, 因此退出循环, 时间复杂度为O(n). 平均来讲, 时间复杂度为O(n²). 由于冒泡排序中只有缓存的temp变量需要内存空间, 因此空间复杂度为常量O(1). Tips: 由于冒泡排序只在相邻元素大小不符合要求时才调换他们的位置, 它并不改变相同元素之间的相对顺序, 因此它是稳定的排序算法. 快速排序（Quick Sort）快速排序（Quicksort）是对冒泡排序的一种改进，借用了分治的思想，由C. A. R. Hoare在1962年提出。 基本思想快速排序的基本思想：挖坑填数+分治法。 首先选一个轴值(pivot，也有叫基准的)，通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。 算法描述快速排序使用分治策略来把一个序列（list）分为两个子序列（sub-lists）。步骤为： ①. 从数列中挑出一个元素，称为”基准”（pivot）。②. 重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。③. 递归地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序。 递归到最底部时，数列的大小是零或一，也就是已经排序好了。这个算法一定会结束，因为在每次的迭代（iteration）中，它至少会把一个元素摆到它最后的位置去。 代码实现用伪代码描述如下： ①. i = L; j = R; 将基准数挖出形成第一个坑a[i]。②．j–，由后向前找比它小的数，找到后挖出此数填前一个坑a[i]中。③．i++，由前向后找比它大的数，找到后也挖出此数填到前一个坑a[j]中。④．再重复执行②，③二步，直到i==j，将基准数填入a[i]中 1234567891011121314151617181920212223242526272829303132/** * 快速排序（递归） * * ①. 从数列中挑出一个元素，称为&quot;基准&quot;（pivot）。 * ②. 重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。 * ③. 递归地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序。 * @param arr 待排序数组 * @param low 左边界 * @param high 右边界 */public static void quickSort(int[] arr, int low, int high)&#123; if(arr.length &lt;= 0) return; if(low &gt;= high) return; int left = low; int right = high; int temp = arr[left]; //挖坑1：保存基准的值 while (left &lt; right)&#123; while(left &lt; right &amp;&amp; arr[right] &gt;= temp)&#123; //坑2：从后向前找到比基准小的元素，插入到基准位置坑1中 right--; &#125; arr[left] = arr[right]; while(left &lt; right &amp;&amp; arr[left] &lt;= temp)&#123; //坑3：从前往后找到比基准大的元素，放到刚才挖的坑2中 left++; &#125; arr[right] = arr[left]; &#125; arr[left] = temp; //基准值填补到坑3中，准备分治递归快排 System.out.println(&quot;Sorting: &quot; + Arrays.toString(arr)); quickSort(arr, low, left-1); quickSort(arr, left+1, high);&#125; 上面是递归版的快速排序：通过把基准temp插入到合适的位置来实现分治，并递归地对分治后的两个划分继续快排。那么非递归版的快排如何实现呢？ 因为递归的本质是栈，所以我们非递归实现的过程中，可以借助栈来保存中间变量就可以实现非递归了。在这里中间变量也就是通过Pritation函数划分区间之后分成左右两部分的首尾指针，只需要保存这两部分的首尾指针即可。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 快速排序（非递归） * * ①. 从数列中挑出一个元素，称为&quot;基准&quot;（pivot）。 * ②. 重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。 * ③. 把分区之后两个区间的边界（low和high）压入栈保存，并循环①、②步骤 * @param arr 待排序数组 */public static void quickSortByStack(int[] arr)&#123; if(arr.length &lt;= 0) return; Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); //初始状态的左右指针入栈 stack.push(0); stack.push(arr.length - 1); while(!stack.isEmpty())&#123; int high = stack.pop(); //出栈进行划分 int low = stack.pop(); int pivotIdx = partition(arr, low, high); //保存中间变量 if(pivotIdx &gt; low) &#123; stack.push(low); stack.push(pivotIdx - 1); &#125; if(pivotIdx &lt; high &amp;&amp; pivotIdx &gt;= 0)&#123; stack.push(pivotIdx + 1); stack.push(high); &#125; &#125;&#125;private static int partition(int[] arr, int low, int high)&#123; if(arr.length &lt;= 0) return -1; if(low &gt;= high) return -1; int l = low; int r = high; int pivot = arr[l]; //挖坑1：保存基准的值 while(l &lt; r)&#123; while(l &lt; r &amp;&amp; arr[r] &gt;= pivot)&#123; //坑2：从后向前找到比基准小的元素，插入到基准位置坑1中 r--; &#125; arr[l] = arr[r]; while(l &lt; r &amp;&amp; arr[l] &lt;= pivot)&#123; //坑3：从前往后找到比基准大的元素，放到刚才挖的坑2中 l++; &#125; arr[r] = arr[l]; &#125; arr[l] = pivot; //基准值填补到坑3中，准备分治递归快排 return l;&#125; 复杂度快速排序是通常被认为在同数量级（O(nlog2n)）的排序方法中平均性能最好的。但若初始序列按关键码有序或基本有序时，快排序反而蜕化为冒泡排序。为改进之，通常以“三者取中法”来选取基准记录，即将排序区间的两个端点与中点三个记录关键码居中的调整为支点记录。快速排序是一个不稳定的排序方法。 以下是快速排序算法复杂度:|平均时间复杂度| 最好情况 |最坏情况 |空间复杂度|| — | — | — | — ||O(nlog₂n) |O(nlog₂n) |O(n²) |O(1)（原地分区递归版）| 快速排序排序效率非常高。 虽然它运行最糟糕时将达到O(n²)的时间复杂度, 但通常平均来看, 它的时间复杂为O(nlogn), 比同样为O(nlogn)时间复杂度的归并排序还要快. 快速排序似乎更偏爱乱序的数列, 越是乱序的数列, 它相比其他排序而言, 相对效率更高. Tips: 同选择排序相似, 快速排序每次交换的元素都有可能不是相邻的, 因此它有可能打破原来值为相同的元素之间的顺序. 因此, 快速排序并不稳定. 归并排序（Merging Sort）归并排序是建立在归并操作上的一种有效的排序算法，1945年由约翰·冯·诺伊曼首次提出。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用，且各层分治递归可以同时进行。 基本思想归并排序算法是将两个（或两个以上）有序表合并成一个新的有序表，即把待排序序列分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。 算法描述归并排序可通过两种方式实现： 自上而下的递归自下而上的迭代一、递归法（假设序列共有n个元素）： ①. 将序列每相邻两个数字进行归并操作，形成 floor(n/2)个序列，排序后每个序列包含两个元素；②. 将上述序列再次归并，形成 floor(n/4)个序列，每个序列包含四个元素；③. 重复步骤②，直到所有元素排序完毕。二、迭代法 ①. 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列②. 设定两个指针，最初位置分别为两个已经排序序列的起始位置③. 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置④. 重复步骤③直到某一指针到达序列尾⑤. 将另一序列剩下的所有元素直接复制到合并序列尾 代码实现归并排序其实要做两件事： 分解：将序列每次折半拆分合并：将划分后的序列段两两排序合并因此，归并排序实际上就是两个操作，拆分+合并 如何合并？ L[first…mid]为第一段，L[mid+1…last]为第二段，并且两端已经有序，现在我们要将两端合成达到L[first…last]并且也有序。 首先依次从第一段与第二段中取出元素比较，将较小的元素赋值给temp[]重复执行上一步，当某一段赋值结束，则将另一段剩下的元素赋值给temp[]此时将temp[]中的元素复制给L[]，则得到的L[first…last]有序 如何分解？ 在这里，我们采用递归的方法，首先将待排序列分成A,B两组；然后重复对A、B序列 分组；直到分组后组内只有一个元素，此时我们认为组内所有元素有序，则分组结束。 这里我写了递归算法如下： 12345678910111213141516171819202122232425262728293031323334353637/** * 归并排序（递归） * * ①. 将序列每相邻两个数字进行归并操作，形成 floor(n/2)个序列，排序后每个序列包含两个元素； * ②. 将上述序列再次归并，形成 floor(n/4)个序列，每个序列包含四个元素； * ③. 重复步骤②，直到所有元素排序完毕。 * @param arr 待排序数组 */public static int[] mergingSort(int[] arr)&#123; if(arr.length &lt;= 1) return arr; int num = arr.length &gt;&gt; 1; int[] leftArr = Arrays.copyOfRange(arr, 0, num); int[] rightArr = Arrays.copyOfRange(arr, num, arr.length); System.out.println(&quot;split two array: &quot; + Arrays.toString(leftArr) + &quot; And &quot; + Arrays.toString(rightArr)); return mergeTwoArray(mergingSort(leftArr), mergingSort(rightArr)); //不断拆分为最小单元，再排序合并&#125;private static int[] mergeTwoArray(int[] arr1, int[] arr2)&#123; int i = 0, j = 0, k = 0; int[] result = new int[arr1.length + arr2.length]; //申请额外的空间存储合并之后的数组 while(i &lt; arr1.length &amp;&amp; j &lt; arr2.length)&#123; //选取两个序列中的较小值放入新数组 if(arr1[i] &lt;= arr2[j])&#123; result[k++] = arr1[i++]; &#125;else&#123; result[k++] = arr2[j++]; &#125; &#125; while(i &lt; arr1.length)&#123; //序列1中多余的元素移入新数组 result[k++] = arr1[i++]; &#125; while(j &lt; arr2.length)&#123; //序列2中多余的元素移入新数组 result[k++] = arr2[j++]; &#125; System.out.println(&quot;Merging: &quot; + Arrays.toString(result)); return result;&#125; 由上, 长度为n的数组, 最终会调用mergeSort函数2n-1次。通过自上而下的递归实现的归并排序, 将存在堆栈溢出的风险。 复杂度 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(nlog₂n) O(nlog₂n) O(nlog₂n) O(n) 从效率上看，归并排序可算是排序算法中的”佼佼者”. 假设数组长度为n，那么拆分数组共需logn，, 又每步都是一个普通的合并子数组的过程， 时间复杂度为O(n)， 故其综合时间复杂度为O(nlogn)。另一方面， 归并排序多次递归过程中拆分的子数组需要保存在内存空间， 其空间复杂度为O(n)。 和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是O(n log n）的时间复杂度。代价是需要额外的内存空间。 基数排序（Radix Sort）基数排序的发明可以追溯到1887年赫尔曼·何乐礼在打孔卡片制表机（Tabulation Machine）, 排序器每次只能看到一个列。它是基于元素值的每个位上的字符来排序的。 对于数字而言就是分别基于个位，十位， 百位或千位等等数字来排序。 基数排序（Radix sort）是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数。 基本思想它是这样实现的：将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后，数列就变成一个有序序列。 基数排序按照优先从高位或低位来排序有两种实现方案： MSD（Most significant digital） 从最左侧高位开始进行排序。先按k1排序分组, 同一组中记录, 关键码k1相等, 再对各组按k2排序分成子组, 之后, 对后面的关键码继续这样的排序分组, 直到按最次位关键码kd对各子组排序后. 再将各组连接起来, 便得到一个有序序列。MSD方式适用于位数多的序列。 LSD （Least significant digital）从最右侧低位开始进行排序。先从kd开始排序，再对kd-1进行排序，依次重复，直到对k1排序后便得到一个有序序列。LSD方式适用于位数少的序列。 算法描述我们以LSD为例，从最低位开始，具体算法描述如下： ①. 取得数组中的最大数，并取得位数；②. arr为原始数组，从最低位开始取每个位组成radix数组；③. 对radix进行计数排序（利用计数排序适用于小范围数的特点）； 代码实现基数排序：通过序列中各个元素的值，对排序的N个元素进行若干趟的“分配”与“收集”来实现排序。 分配：我们将L[i]中的元素取出，首先确定其个位上的数字，根据该数字分配到与之序号相同的桶中 收集：当序列中所有的元素都分配到对应的桶中，再按照顺序依次将桶中的元素收集形成新的一个待排序列L[]。对新形成的序列L[]重复执行分配和收集元素中的十位、百位…直到分配完该序列中的最高位，则排序结束 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 基数排序（LSD 从低位开始） * * 基数排序适用于： * (1)数据范围较小，建议在小于1000 * (2)每个数值都要大于等于0 * * ①. 取得数组中的最大数，并取得位数； * ②. arr为原始数组，从最低位开始取每个位组成radix数组； * ③. 对radix进行计数排序（利用计数排序适用于小范围数的特点）； * @param arr 待排序数组 */public static void radixSort(int[] arr)&#123; if(arr.length &lt;= 1) return; //取得数组中的最大数，并取得位数 int max = 0; for(int i = 0; i &lt; arr.length; i++)&#123; if(max &lt; arr[i])&#123; max = arr[i]; &#125; &#125; int maxDigit = 1; while(max / 10 &gt; 0)&#123; maxDigit++; max = max / 10; &#125; System.out.println(&quot;maxDigit: &quot; + maxDigit); //申请一个桶空间 int[][] buckets = new int[10][arr.length]; int base = 10; //从低位到高位，对每一位遍历，将所有元素分配到桶中 for(int i = 0; i &lt; maxDigit; i++)&#123; int[] bktLen = new int[10]; //存储各个桶中存储元素的数量 //分配：将所有元素分配到桶中 for(int j = 0; j &lt; arr.length; j++)&#123; int whichBucket = (arr[j] % base) / (base / 10); buckets[whichBucket][bktLen[whichBucket]] = arr[j]; bktLen[whichBucket]++; &#125; //收集：将不同桶里数据挨个捞出来,为下一轮高位排序做准备,由于靠近桶底的元素排名靠前,因此从桶底先捞 int k = 0; for(int b = 0; b &lt; buckets.length; b++)&#123; for(int p = 0; p &lt; bktLen[b]; p++)&#123; arr[k++] = buckets[b][p]; &#125; &#125; System.out.println(&quot;Sorting: &quot; + Arrays.toString(arr)); base *= 10; &#125;&#125; 复杂度 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(d*(n+r)) O(d*(n+r)) O(d*(n+r)) O(n+r) 其中，d 为位数，r 为基数，n 为原数组个数。在基数排序中，因为没有比较操作，所以在复杂上，最好的情况与最坏的情况在时间上是一致的，均为 O(d*(n + r))。 基数排序更适合用于对时间, 字符串等这些整体权值未知的数据进行排序。 Tips: 基数排序不改变相同元素之间的相对顺序，因此它是稳定的排序算法。 基数排序 vs 计数排序 vs 桶排序 这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异： 基数排序：根据键值的每位数字来分配桶 计数排序：每个桶只存储单一键值 桶排序：每个桶存储一定范围的数值 总结 排序类型 平均情况 最好情况 最坏情况 辅助空间 稳定性 冒泡排序 O(n²) O(n) O(n²) O(1) 稳定 选择排序 O(n²) O(n²) O(n²) O(1) 不稳定 直接插入排序 O(n²) O(n) O(n²) O(1) 稳定 折半插入排序 O(n²) O(n) O(n²) O(1) 稳定 希尔排序 O(n^1.3) O(nlogn) O(n²) O(1) 不稳定 归并排序 O(nlog₂n) O(nlog₂n) O(nlog₂n) O(n) 稳定 快速排序 O(nlog₂n) O(nlog₂n) O(n²) O(nlog₂n) 不稳定 堆排序 O(nlog₂n) O(nlog₂n) O(nlog₂n) O(1) 不稳定 计数排序 O(n+k) O(n+k) O(n+k) O(k) 稳定 桶排序 O(n+k) O(n+k) O(n²) O(n+k) (不)稳定 基数排序 O(d(n+k)) O(d(n+k)) O(d(n+kd)) O(n+kd) 稳定 从时间复杂度来说： (1). 平方阶O(n²)排序：各类简单排序：直接插入、直接选择和冒泡排序； (2). 线性对数阶O(nlog₂n)排序： 快速排序、堆排序和归并排序； (3). O(n1+§))排序，§是介于0和1之间的常数：希尔排序 (4). 线性阶O(n)排序：基数排序，此外还有桶、箱排序。 到此，很多人会注意到基数排序的时间复杂度是最小的，那么为什么却没有快排、堆排序流行呢？我们看看下图算法导论的相关说明： 基数排序只适用于有基数的情况，而基于比较的排序适用范围就广得多。另一方面是内存上的考虑。作为一种通用的排序方法，最好不要带来意料之外的内存开销，所以各语言的默认实现都没有用基数排序，但是不能否认基数排序在各领域的应用。 时间复杂度极限当被排序的数有一些性质的时候（比如是整数，比如有一定的范围），排序算法的复杂度是可以小于O(nlgn)的。比如： 计数排序 复杂度O( k+n) 要求：被排序的数是0~k范围内的整数 基数排序 复杂度O( d(k+n) ) 要求：d位数，每个数位有k个取值 桶排序 复杂度 O( n ) （平均） 要求：被排序数在某个范围内，并且服从均匀分布 但是，当被排序的数不具有任何性质的时候，一般使用基于比较的排序算法，而基于比较的排序算法时间复杂度的下限必须是O(nlgn)。 参考很多高效排序算法的代价是 nlogn，难道这是排序算法的极限了吗？ 说明 当原表有序或基本有序时，直接插入排序和冒泡排序将大大减少比较次数和移动记录的次数，时间复杂度可降至O（n）； 而快速排序则相反，当原表基本有序时，将蜕化为冒泡排序，时间复杂度提高为O（n2）； 原表是否有序，对简单选择排序、堆排序、归并排序和基数排序的时间复杂度影响不大。]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java-HashMap、Hashtable、ConcurrentHashMap的区别]]></title>
    <url>%2F2019%2F05%2F12%2FJava-HashMap%E3%80%81Hashtable%E3%80%81ConcurrentHashMap%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[以下是基于java1.8源码进行对比： 类型 HashMap Hashtable ConcurrentHashMap 数据结构 数组+链表+红黑树 数组+链表 数组+链表+红黑树 数组容量 默认容量为16，且要求底层数组的容量一定为2的整数次幂 默认容量为11，且不要求底层数组的容量一定为2的整数次幂 默认容量为16，且要求底层数组的容量一定为2的整数次幂 是否支持NULL值 支持 不支持 不支持 size获取 size字段值 count字段值 通过累加baseCount和CounterCell数组中的数量，得到元素的总个数 hash计算方式 key.hashCode() ^ (key.hashCode() &gt;&gt;&gt; 16) key.hashCode() (key.hashCode() ^ (key.hashCode() &gt;&gt;&gt; 16)) &amp; 0x7fffffff index计算方式 (n - 1) &amp; hash (hash &amp; 0x7FFFFFFF) % tab.length (hash &amp; 0x7FFFFFFF) % tab.length 是否线程安全 否 是 是 性能高低 高 低 中 线程安全实现方式 无 synchronized对象锁，get、add、remove等方法不能同时进行 CAS + synchronized保证多线程安全，可以同时执行多个方法 扩容方式 单线程进行扩容（多线程进行扩容，可能会导致死循环造成CPU100%） 单线程进行扩容 单线程对新数组进行初始化，可多线程同步复制不同节点数据到新数组 总结： HashTable是已过时的类，不建议再使用; 需要线程安全的场景，使用ConcurrentHashMap; 无需线程安全，使用HashMap;]]></content>
      <categories>
        <category>Java集合</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java-ConcurrentHashMap在JDK1.7和JDK1.8的差异]]></title>
    <url>%2F2019%2F05%2F12%2FJava-ConCurrentHashMap%E5%9C%A8JDK1-7%E5%92%8CJDK1-8%E7%9A%84%E5%B7%AE%E5%BC%82%2F</url>
    <content type="text"><![CDATA[版本 JDK1.7 JDK1.8 概览 同步机制 分段锁，每个segment继承ReentrantLock CAS + synchronized保证并发更新 数据结构 数组+链表 数组+链表+红黑树 键值对 HashEntry Node put操作 当执行put方法插入数据时，根据key的hash值，在Segment数组中找到相应的位置，如果相应位置的Segment还未初始化，则通过CAS进行赋值，接着执行Segment对象的put方法通过加锁机制插入数据。多个线程同时竞争获取同一个segment锁，获取成功的线程更新map；失败的线程尝试多次获取锁仍未成功，则挂起线程，等待释放锁 访问相应的bucket时，使用sychronizeded关键字，防止多个线程同时操作同一个bucket，如果该节点的hash不小于0，则遍历链表更新节点或插入新节点；如果该节点是TreeBin类型的节点，说明是红黑树结构，则通过putTreeVal方法往红黑树中插入节点；更新了节点数量，还要考虑扩容和链表转红黑树 size实现 统计每个Segment对象中的元素个数，然后进行累加，但是这种方式计算出来的结果并不一样的准确的。先采用不加锁的方式，连续计算元素的个数，最多计算3次：如果前后两次计算结果相同，则说明计算出来的元素个数是准确的；如果前后两次计算结果都不同，则给每个Segment进行加锁，再计算一次元素的个数； 使用一个volatile类型的变量baseCount记录元素的个数，当插入新数据或者删除数据时，会通过addCount()方法更新baseCount。通过累加baseCount和CounterCell数组中的数量，即可得到元素的总个数； 扩容实现 某个线程获得了锁之后，单线程执行扩容操作。将数组大小翻倍，复制数据到新数组。 支持并发迁移节点，遍历table的每一个节点。如果该节点被其他线程处理过了，就会创建一个 ForwardingNode 放到该节点原位置，hash值为-1。其他线程通过判断是 ForwardingNode 就知道是否已被处理过。在复制节点数据的过程中，会通过 synchronized 锁防止多个线程同时复制同一个节点的数据。 参考链接：https://www.jianshu.com/p/e694f1e868ec]]></content>
      <categories>
        <category>Java集合</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java-ConcurrentHashMap工作原理及实现]]></title>
    <url>%2F2019%2F05%2F12%2FJava-ConCurrentHashMap%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[概述关于Java集合的小抄是这么描述： 并发优化的HashMap。 在JDK5里的经典设计，默认16把写锁（可以设置更多），有效分散了阻塞的概率。数据结构为Segment[]，每个Segment一把锁。Segment里面才是哈希桶数组。Key先算出它在哪个Segment里，再去算它在哪个哈希桶里。 也没有读锁，因为put/remove动作是个原子动作（比如put的整个过程是一个对数组元素/Entry 指针的赋值操作），读操作不会看到一个更新动作的中间状态。 但在JDK8里，Segment[]的设计被抛弃了，改为精心设计的，只在需要锁的时候加锁。 支持ConcurrentMap接口，如putIfAbsent（key，value）与相反的replace（key，value）与以及实现CAS的replace（key, oldValue, newValue）。 成员变量 table：默认为null，初始化发生在第一次插入操作，默认大小为16的数组，用来存储Node节点数据，扩容时大小总是2的幂次方。 nextTable：默认为null，扩容时新生成的数组，其大小为原数组的两倍。 sizeCtl ：默认为0，用来控制table的初始化和扩容操作，具体应用在后续会体现出来。 1234等于-1时，代表 table 正在初始化 等于-N时，表示有N-1个线程正在进行扩容操作 如果table未初始化，表示table需要初始化的大小。 如果table初始化完成，表示table的容量，默认是table大小的0.75倍，居然用这个公式算0.75（n - (n &gt;&gt;&gt; 2)）。 Node：保存key，value及key的hash值的数据结构。 其中value和next都用volatile修饰，保证并发的可见性。 1234567class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; //... 省略部分代码&#125; ForwardingNode：一个特殊的Node节点，hash值为-1，其中存储nextTable的引用。 只有table发生扩容的时候，ForwardingNode才会发挥作用，作为一个占位符放在table中表示当前节点为null或则已经被移动。 1234567final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; super(MOVED, null, null, null); this.nextTable = tab; &#125;&#125; 初始化数组初始化数组的时候需要判断是否有其他线程正在执行初始化，采用CAS操作更新 sizeCtl 的值。具体代码如下： 1234567891011121314151617181920212223242526private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; //如果一个线程发现sizeCtl&lt;0，意味着另外的线程执行CAS操作成功正在初始化表，当前线程只需要让出cpu时间片 if ((sc = sizeCtl) &lt; 0) Thread.yield(); //SIZECTL：表示当前对象的内存偏移量，sc表示期望值，-1表示要替换的值，设定为-1表示要初始化表了。执行CAS操作 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; //没有指定初始化容量大小，则默认为16 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; //0.75 * capacity sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; put函数与 HashMap 的 put 操作类似，主要增加多线程情况的判断。具体实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public V put(K key, V value) &#123; return putVal(key, value, false);&#125;final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; //如果tab为空则初始化table if (tab == null || (n = tab.length) == 0) tab = initTable(); //如果对应数组位置为空，则通过CAS操作进行赋值（这时候是不会加锁的）。 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; // 当前hash为MOVED表示Map在扩容，先协助扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; //hash冲突，通过 synchronized 加锁当前位置对象防止多线程更新 V oldVal = null; synchronized (f) &#123; //再次判断是否已被其他线程更新值 if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; //从链表头节点开始遍历 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; // 节点已经存在，修改链表节点的值 oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; // 节点不存在，新增节点到链表末尾 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; //链表节点 &gt;= 8个则已经转换为红黑树，遍历寻找进行替换值或新增节点 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; //如果链表节点个数 &gt;= 8，则转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; // 统计节点个数，检查是否需要扩容 addCount(1L, binCount); return null;&#125; size与mappingCount为了更好地统计size，ConcurrentHashMap提供了baseCount、counterCells两个辅助变量和一个CounterCell辅助内部类。 123456789@sun.misc.Contended static final class CounterCell &#123; volatile long value; CounterCell(long x) &#123; value = x; &#125; &#125; //ConcurrentHashMap中元素个数,但返回的不一定是当前Map的真实元素个数。基于CAS无锁更新 private transient volatile long baseCount; private transient volatile CounterCell[] counterCells; mappingCount与size方法的类似 从Java工程师给出的注释来看，应该使用mappingCount代替size方法 两个方法都没有直接返回basecount 而是统计一次这个值，而这个值其实也是一个大概的数值，因此可能在统计的时候有其他线程正在执行插入或删除操作。 12345678910111213141516171819202122232425public int size() &#123; long n = sumCount(); return ((n &lt; 0L) ? 0 : (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n);&#125;//返回容器的大小。这个方法应该被用来代替size()方法，因为 ConcurrentHashMap的容量大小可能会大于int的最大值。public long mappingCount() &#123; long n = sumCount(); return (n &lt; 0L) ? 0L : n;&#125;//迭代counterCells来统计sum的过程final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value;//所有counter的值求和 &#125; &#125; return sum;&#125; 数组扩容当ConcurrentHashMap中table元素个数达到了容量阈值（sizeCtl）时，则需要进行扩容操作。在put操作时最后一个会调用addCount(long x, int check)，该方法主要做两个工作：1.更新baseCount；2.检测是否需要扩容操作。 12345678910111213141516171819202122232425262728293031323334353637383940414243private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; // s = b + x，完成baseCount++操作； if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; // 多线程CAS发生失败时执行 fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; s = sumCount(); &#125; if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; //判断是否进行扩容 while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n); if (sc &lt; 0) &#123; //有线程正在进行扩容初始化nextTable操作，直接break if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; //nextTable已经初始化，协助扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; //扩容，对nextTable进行初始化 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); &#125; &#125; &#125; addCount 函数保证只有单线程对 nextTable 进行初始化操作。 transfer()方法为ConcurrentHashMap扩容操作的核心方法。由于ConcurrentHashMap支持多线程扩容，而且也没有进行加锁，所以实现会变得有点儿复杂。整个扩容分为两部分： 构建一个nextTable，大小为table的两倍。 把table的数据复制到nextTable中。(这里允许多线程同时复制)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; // 每核处理的量小于16，则强制赋值16 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) &#123; // initiating try &#123; @SuppressWarnings(&quot;unchecked&quot;) //构建一个nextTable对象，其容量为原来容量的两倍 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; int nextn = nextTab.length; // 连接点指针，用于标志位（fwd的hash值为-1，fwd.nextTable=nextTab） ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); // 当advance == true时，表明该节点已经处理过了 boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; // 控制 --i ,遍历原hash表中的节点 while (advance) &#123; int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; // 用CAS计算得到的transferIndex else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; // 已经完成所有节点复制了 if (finishing) &#123; nextTable = null; table = nextTab; // table 指向nextTable sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); //扩容阈值设置为原来容量的1.5倍 依然相当于现在容量的0.75倍 return; // 跳出死循环， &#125; // CAS 更扩容阈值，在这里面sizectl值减一，说明新加入一个线程参与到扩容操作 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit &#125; &#125; // 遍历的节点为null，则放入到ForwardingNode 指针节点 else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // f.hash == -1 表示遍历到了ForwardingNode节点，意味着该节点已经处理过了 // 这里是控制并发扩容的核心 else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; // 节点加锁,避免多线程复制同一个节点 synchronized (f) &#123; // 节点复制工作 if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; // fh &gt;= 0 ,表示为链表节点 if (fh &gt;= 0) &#123; // 构造两个链表 一个是原链表 另一个是原链表的反序排列 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; // 在nextTable i 位置处插上链表 setTabAt(nextTab, i, ln); // 在nextTable i + n 位置处插上链表 setTabAt(nextTab, i + n, hn); // 在table i 位置处插上ForwardingNode 表示该节点已经处理过了 setTabAt(tab, i, fwd); // advance = true 可以执行--i动作，遍历节点 advance = true; &#125; // 如果是TreeBin，则按照红黑树进行处理，处理逻辑与上面一致 else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; // 扩容后树节点个数若&lt;=6，将树转链表 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125; &#125; 上面的源码有点儿长，稍微复杂了一些，在这里我们抛弃它多线程环境，我们从单线程角度来看： 为每个内核分任务，并保证其不小于16 检查nextTable是否为null，如果是，则初始化nextTable，使其容量为table的两倍 循环变量直到finished，利用tabAt方法获得i位置的元素（支持多线程复制） 如果这个位置为空，就在原table中的i位置放入forwardNode节点，这个也是触发并发扩容的关键点； 如果这个位置是Node节点（fh&gt;=0），如果它是一个链表的头节点，就构造一个反序链表，把他们分别放在nextTable的i和i+n的位置上。并将ForwardingNode 插入原节点位置，代表已经处理过了 如果这个位置是TreeBin节点（fh&lt;0），也做一个反序处理，并且判断是否需要unTreeify()操作，把处理的结果分别放在nextTable的i和i+n的位置上。并插入ForwardingNode 节点 遍历过所有的节点以后就完成了复制工作，这时让nextTable作为新的table，并且更新sizeCtl为新容量的0.75倍 ，完成扩容。 在多线程环境下，ConcurrentHashMap用两点来保证正确性：ForwardingNode和synchronized。 当一个线程遍历到的节点如果是ForwardingNode，则继续往后遍历。 如果不是，则将该节点加锁，防止其他线程进入，完成后设置ForwardingNode节点。 当其他线程处理该节点时可以看到已经处理过了，如此交叉进行，高效而又安全。 helpTransfer在添加、删除等方法里面都会调用，当前优先协助扩容。helpTransfer()方法为协助扩容方法，当调用该方法的时候，nextTable一定已经创建了，所以该方法主要则是进行复制工作。 12345678910111213141516171819final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; int rs = resizeStamp(tab.length); while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table; &#125; 转换红黑树用于将过长的链表转换为TreeBin对象。但是他并不是直接转换，而是进行一次容量判断。 如果容量没有达到转换的要求(table.length&lt;64)，直接进行扩容操作并返回； 如果满足条件才链表的结构抓换为TreeBin ，这与HashMap不同的是： 1.根据table中index位置Node链表，重新生成一个hd为头结点的TreeNode 2.根据hd头结点，生成TreeBin树结构，并用TreeBin替换掉原来的Node对象。 123456789101112131415161718192021222324252627private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; int n, sc; if (tab != null) &#123; if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY)//如果table.length&lt;64 就扩大一倍 返回 tryPresize(n &lt;&lt; 1); else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; synchronized (b) &#123; if (tabAt(tab, index) == b) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; //构造了一个TreeBin对象 把所有Node节点包装成TreeNode放进去 for (Node&lt;K,V&gt; e = b; e != null; e = e.next) &#123; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val, null, null);//这里只是利用了TreeNode封装 而没有利用TreeNode的next域和parent域 if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; &#125; //在原来index的位置 用TreeBin替换掉原来的Node对象 setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd)); &#125; &#125; &#125; &#125; &#125; get函数读取操作，不需要同步控制，比较简单 空tab，直接返回null 计算hash值，找到相应的bucket位置，为node节点直接返回，否则返回null12345678910111213141516171819public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; 参考链接：https://blog.csdn.net/programmer_at/article/details/79715177#141-addcounthttps://blog.csdn.net/u010723709/article/details/48007881https://www.jianshu.com/p/c0642afe03e0http://cmsblogs.com/?p=2283]]></content>
      <categories>
        <category>Java集合</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java-HashSet工作原理及实现]]></title>
    <url>%2F2019%2F05%2F12%2FJava-HashSet%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[Set概述关于Java集合的小抄是这么描述：所有Set几乎都是内部用一个Map来实现, 因为Map里的KeySet就是一个Set，而value是假值，全部使用同一个Object即可。 Set的特征也继承了那些内部的Map实现的特征。 HashSet：内部是HashMap。 LinkedHashSet：内部是LinkedHashMap。 TreeSet：内部是TreeMap的SortedSet。 ConcurrentSkipListSet：内部是ConcurrentSkipListMap的并发优化的SortedSet。 CopyOnWriteArraySet：内部是CopyOnWriteArrayList的并发优化的Set，利用其addIfAbsent（）方法实现元素去重，如前所述该方法的性能很一般。 基本操作我们可以看到HashSet类有这么一个属性 1private transient HashMap&lt;E,Object&gt; map; HashSet 所有的操作都是基于这个 map 展开的，map 的 value 值是空的 Object 对象。 1234567891011121314private static final Object PRESENT = new Object();public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125;public boolean remove(Object o) &#123; return map.remove(o)==PRESENT;&#125;public boolean contains(Object o) &#123; return map.containsKey(o);&#125;public int size() &#123; return map.size();&#125; 总结HashSet 利用 HashMap 的 key 不能重复特性实现，所有操作都是基于 HashMap 实现的。其他 Set 的实现方法也都是基于不同的 Map 实现的，就不一一讲述了。]]></content>
      <categories>
        <category>Java集合</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java-TreeMap工作原理及实现]]></title>
    <url>%2F2019%2F05%2F09%2FJava-TreeMap%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[TreeMap概述以红黑树实现，红黑树又叫自平衡二叉树： 对于任一节点而言，其到叶节点的每一条路径都包含相同数目的黑结点。 上面的规定，使得树的层数不会差的太远，使得所有操作的复杂度不超过 O（lgn），但也使得插入，修改时要复杂的左旋右旋来保持树的平衡。 支持iterator（）时按Key值排序，可按实现了Comparable接口的Key的升序排序，或由传入的Comparator控制。可想象的，在树上插入/删除元素的代价一定比HashMap的大。 支持SortedMap接口，如firstKey（），lastKey（）取得最大最小的key，或sub（fromKey, toKey）, tailMap（fromKey）剪取Map的某一段。 put函数如果存在的话，old value被替换；如果不存在的话，则新添一个节点，然后对做红黑树的平衡操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public V put(K key, V value) &#123; //获取根节点 TreeMap.Entry&lt;K,V&gt; t = root; //如果根节点为空则新建树 if (t == null) &#123; compare(key, key); // type (and possibly null) check root = new TreeMap.Entry&lt;&gt;(key, value, null); size = 1; modCount++; return null; &#125; int cmp; TreeMap.Entry&lt;K,V&gt; parent; // 根据comparator获取key的父节点 Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) &#123; do &#123; parent = t; cmp = cpr.compare(key, t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; else &#123; if (key == null) throw new NullPointerException(); @SuppressWarnings(&quot;unchecked&quot;) Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; do &#123; parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; //节点不存在则新建 TreeMap.Entry&lt;K,V&gt; e = new TreeMap.Entry&lt;&gt;(key, value, parent); if (cmp &lt; 0) parent.left = e; else parent.right = e; //红黑树平衡调整 fixAfterInsertion(e); size++; modCount++; return null;&#125; get函数通过Comparable对比节点，当比较值等于0时就是key值对应的Entry。get函数则相对来说比较简单，以log(n)的复杂度进行get。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public V get(Object key) &#123; Entry&lt;K,V&gt; p = getEntry(key); return (p==null ? null : p.value);&#125;final Entry&lt;K,V&gt; getEntry(Object key) &#123; // Offload comparator-based version for sake of performance if (comparator != null) return getEntryUsingComparator(key); if (key == null) throw new NullPointerException(); @SuppressWarnings(&quot;unchecked&quot;) Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; Entry&lt;K,V&gt; p = root; while (p != null) &#123; int cmp = k.compareTo(p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; &#125; return null;&#125;final Entry&lt;K,V&gt; getEntryUsingComparator(Object key) &#123; @SuppressWarnings(&quot;unchecked&quot;) K k = (K) key; Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) &#123; Entry&lt;K,V&gt; p = root; while (p != null) &#123; int cmp = cpr.compare(k, p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; &#125; &#125; return null;&#125; successor后继TreeMap是如何保证其迭代输出是有序的呢？其实从宏观上来讲，就相当于树的中序遍历(LDR)。我们先看一下迭代输出的步骤 123for(Entry&lt;Integer, String&gt; entry : tmap.entrySet()) &#123; System.out.println(entry.getKey() + &quot;: &quot; + entry.getValue());&#125; 根据The enhanced for statement，for语句会做如下转换为： 1234for(Iterator&lt;Map.Entry&lt;String, String&gt;&gt; it = tmap.entrySet().iterator() ; tmap.hasNext(); ) &#123; Entry&lt;Integer, String&gt; entry = it.next(); System.out.println(entry.getKey() + &quot;: &quot; + entry.getValue());&#125; 在it.next()的调用中会使用nextEntry调用successor这个是过的后继的重点，具体实现如下： 1234567891011121314151617181920212223static &lt;K,V&gt; TreeMap.Entry&lt;K,V&gt; successor(Entry&lt;K,V&gt; t) &#123; if (t == null) return null; else if (t.right != null) &#123; // 有右子树的节点，后继节点就是右子树的“最左节点” // 因为“最左子树”是右子树的最小节点 Entry&lt;K,V&gt; p = t.right; while (p.left != null) p = p.left; return p; &#125; else &#123; // 如果右子树为空，则寻找当前节点所在左子树的第一个祖先节点 // 因为左子树找完了，根据LDR该D了 Entry&lt;K,V&gt; p = t.parent; Entry&lt;K,V&gt; ch = t; // 保证左子树 while (p != null &amp;&amp; ch == p.right) &#123; ch = p; p = p.parent; &#125; return p; &#125;&#125; 怎么理解这个successor呢？只要记住，这个是中序遍历就好了，L-D-R。具体细节如下： a. 空节点，没有后继b. 有右子树的节点，后继就是右子树的“最左节点”c. 无右子树的节点，后继就是该节点所在左子树的第一个祖先节点 a.好理解，不过b, c，有点像绕口令啊，没关系，上图举个例子就懂了！ 有右子树的节点，节点的下一个节点，肯定在右子树中，而右子树中“最左”的那个节点则是右子树中最小的一个，那么当然是右子树的“最左节点”，就好像下图所示：无右子树的节点，先找到这个节点所在的左子树(右图)，那么这个节点所在的左子树的父节点(绿色节点)，就是下一个节点。 参考博客：https://yikun.github.io/2015/04/06/Java-TreeMap%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/http://calvin1978.blogcn.com/articles/collection.html]]></content>
      <categories>
        <category>Java集合</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java-LinkedList工作原理及实现]]></title>
    <url>%2F2019%2F05%2F09%2FJava-LinkedList%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[LinkedList概述以双向链表实现。链表无容量限制，但双向链表本身使用了更多空间，也需要额外的链表指针操作。 按下标访问元素—get(i)/set(i,e) 要悲剧的遍历链表将指针移动到位(如果i&gt;数组大小的一半，会从末尾移起)。 插入、删除元素时修改前后节点的指针即可，但还是要遍历部分链表的指针才能移动到下标所指的位置，只有在链表两头的操作—add(), addFirst(),removeLast()或用iterator()上的remove()能省掉指针的移动。 LinkedList是一个简单的数据结构，与ArrayList不同的是，他是基于链表实现的。 Node类LinkedList的Node类是一个基本的双向链表 1234567891011private static class Node&lt;E&gt; &#123; E item; LinkedList.Node&lt;E&gt; next; LinkedList.Node&lt;E&gt; prev; Node(LinkedList.Node&lt;E&gt; prev, E element, LinkedList.Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; add函数将新增的Node关联到链表最后的位置，实现如下： 123456789101112131415public boolean add(E e) &#123; linkLast(e); return true;&#125;void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125; get函数12345678910111213141516171819public E get(int index) &#123; //判断是否下标越界 checkElementIndex(index); return node(index).item;&#125;Node&lt;E&gt; node(int index) &#123; //判断index是前半部分还是后半部分，找到对应位置数据 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; remove函数主要是通过prev.next = next;next.prev = prev;将前后Node关联起来，将index对应的Node从链表内移除。 12345678910111213141516171819202122232425262728public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125;E unlink(Node&lt;E&gt; x) &#123; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element;&#125; 参考博客：http://calvin1978.blogcn.com/articles/collection.html]]></content>
      <categories>
        <category>Java集合</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java-ArrayList工作原理及实现]]></title>
    <url>%2F2019%2F05%2F09%2FJava-ArrayList%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[ArrayList描述以数组实现。节约空间，但数组有容量限制。超出限制时会增加50%容量，用System.arraycopy()复制到新的数组，因此最好能给出数组大小的预估值。默认第一次插入元素时创建大小为10的数组。 按数组下标访问元素—get(i)/set(i,e) 的性能很高，这是数组的基本优势。 直接在数组末尾加入元素—add(e)的性能也高，但如果按下标插入、删除元素—add(i,e), remove(i), remove(e)，则要用System.arraycopy()来移动部分受影响的元素，性能就变差了，这是基本劣势。 add函数add函数代码如下： 12345public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125; ensureCapacityInternal自动扩容核心代码，具体实现如下： 123456789101112131415161718192021222324252627282930private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; //判断elementData是否等于空数组 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; //需求容量和默认容量相比，返回比较大的 return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity;&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // 需求容量超过了数组容量，进行扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; // 扩展为原来的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 如果扩为1.5倍还不满足需求，直接扩为需求容量 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // 将数据拷贝到新数组上 elementData = Arrays.copyOf(elementData, newCapacity);&#125; ArrayList大小不满足需求时，大小将会自动扩容为原来的1.5倍。 get函数实现就比较简单，直接获取数组指定下标的元素返回即可。代码实现如下： 12345678910public E get(int index) &#123; //判断是否下标越界 rangeCheck(index); return elementData(index);&#125;E elementData(int index) &#123; //直接返回下标对应数据 return (E) elementData[index];&#125; remove函数12345678910111213141516public E remove(int index) &#123; //判断是否下标越界 rangeCheck(index); modCount++; //获取对应下标数据 E oldValue = elementData(index); //将下标后的数据前进一格 int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;&#125; 其他函数还有一些其他函数，就简单说明下其实现。 contains：遍历数组，判断是否存在indexOf：遍历数组，返回下标addAll：判断数组大小是否满足需求，不满足则自动进行扩容。 参考博客：http://yikun.github.io/2015/04/04/Java-ArrayList%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/]]></content>
      <categories>
        <category>Java集合</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java-HashMap工作原理及实现]]></title>
    <url>%2F2019%2F05%2F09%2FHashMap%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[概述 从本文你可以学习到： 什么时候会使用HashMap？他有什么特点？ 你知道HashMap的工作原理吗？ 你知道get和put的原理吗？equals()和hashCode()的都有什么作用？ 你知道hash的实现吗？为什么要这样实现？ 如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？ 当我们执行下面的操作时： 123456789101112HashMap&amp;lt;String, Integer&amp;gt; map = new HashMap&amp;lt;String, Integer&amp;gt;();map.put(&quot;语文&quot;, 1);map.put(&quot;数学&quot;, 2);map.put(&quot;英语&quot;, 3);map.put(&quot;历史&quot;, 4);map.put(&quot;政治&quot;, 5);map.put(&quot;地理&quot;, 6);map.put(&quot;生物&quot;, 7);map.put(&quot;化学&quot;, 8);for(Entry&amp;lt;String, Integer&amp;gt; entry : map.entrySet()) &#123;System.out.println(entry.getKey() + &quot;: &quot; + entry.getValue());&#125; 运行结果是 12345678政治: 5生物: 7历史: 4数学: 2化学: 8语文: 1英语: 3地理: 6 发生了什么呢？下面是一个大致的结构，希望我们对HashMap的结构有一个感性的认识： 在官方文档中是这样描述HashMap的：Hash table based implementation of the Map interface. This implementation provides all of the optional map operations, and permits null values and the null key. (The HashMap class is roughly equivalent to Hashtable, except that it is unsynchronized and permits nulls.) This class makes no guarantees as to the order of the map; in particular, it does not guarantee that the order will remain constant over time. 几个关键的信息：基于Map接口实现、允许null键/值、非同步、不保证有序(比如插入的顺序)、也不保证序不随时间变化。 两个重要的参数 在HashMap中有两个很重要的参数，容量(Capacity)和负载因子(Load factor)Initial capacity The capacity is the number of buckets in the hash table, The initial capacity is simply the capacity at the time the hash table is created.Load factor The load factor is a measure of how full the hash table is allowed to get before its capacity is automatically increased.简单的说，Capacity就是buckets的数目，Load factor就是buckets填满程度的最大比例。如果对迭代性能要求很高的话不要把capacity设置过大，也不要把load factor设置过小。当bucket填充的数目（即hashmap中元素的个数）大于capacity * load factor时就需要调整buckets的数目为当前的2倍。 put函数的实现 put函数大致的思路为： 对key的hashCode()做hash，然后再计算index; 如果没碰撞直接放到bucket里； 如果碰撞了，以链表的形式存在buckets后； 如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)，就把链表转换成红黑树； 如果节点已经存在就替换old value(保证key的唯一性) 如果bucket满了(超过load factor * current capacity)，就要resize。具体代码的实现如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public V put(K key, V value) &#123; // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 如果tab为空则创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 计算key对应的index if ((p = tab[i = (n - 1) &amp; hash]) == null) //节点不存在，直接添加到哈希桶数组 tab[i] = newNode(hash, key, value, null); else &#123; // 节点存在（哈希碰撞） Node&lt;K,V&gt; e; K k; //如果链表的第一个就是查询值则直接返回 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 该链表转化为红黑树（jdk1.8之后） else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 依然是链表，链表数据没有超过8个 else &#123; //单向链表，一直向后获取直到查询到对应key值 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 覆盖旧值并返回 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 超过 容量*负载因子(0.75)，调用 resize() 容量扩容为原来的两倍 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; get函数的实现在理解了put之后，get就很简单了。大致思路如下： bucket里的第一个节点，直接命中； 如果有冲突，则通过key.equals(k)去查找对应的entry若为树，则在树中通过key.equals(k)查找，O(logn)；若为链表，则在链表中通过key.equals(k)查找，O(n)。 具体代码的实现如下： 1234567891011121314151617181920212223242526272829public V get(Object key) &#123; Node&lt;K,V&gt; e; // 对key的hashCode()做hash return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //tab如果为空直接返回null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 直接命中对应index上的值 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 未命中 if ((e = first.next) != null) &#123; // 在树中get if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 在链表中get do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; hash函数的实现 在get和put的过程中，计算下标时，先对hashCode进行hash操作，然后再通过hash值进一步计算下标，如下图所示： 在对hashCode()计算hash时具体实现是这样的： 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &amp;gt;&amp;gt;&amp;gt; 16);&#125; 可以看到这个函数大概的作用就是：高16bit不变，低16bit和高16bit做了一个异或。其中代码注释是这样写的：Computes key.hashCode() and spreads (XORs) higher bits of hash to lower. Because the table uses power-of-two masking, sets of hashes that vary only in bits above the current mask will always collide. (Among known examples are sets of Float keys holding consecutive whole numbers in small tables.) So we apply a transform that spreads the impact of higher bits downward. There is a tradeoff between speed, utility, and quality of bit-spreading. Because many common sets of hashes are already reasonably distributed (so don’t benefit from spreading), and because we use trees to handle large sets of collisions in bins, we just XOR some shifted bits in the cheapest possible way to reduce systematic lossage, as well as to incorporate impact of the highest bits that would otherwise never be used in index calculations because of table bounds.在设计hash函数时，因为目前的table长度n为2的幂，而计算下标的时候，是这样实现的(使用&amp;位操作，而非%求余)： 1(n - 1) &amp;amp; hash 设计者认为这方法很容易发生碰撞。为什么这么说呢？不妨思考一下，在n - 1为15(0x1111)时，其实散列真正生效的只是低4bit的有效位，当然容易碰撞了。因此，设计者想了一个顾全大局的方法(综合考虑了速度、作用、质量)，就是把高16bit和低16bit异或了一下。设计者还解释到因为现在大多数的hashCode的分布已经很不错了，就算是发生了碰撞也用O(logn)的tree去做了。仅仅异或一下，既减少了系统的开销，也不会造成的因为高位没有参与下标的计算(table长度比较小时)，从而引起的碰撞。如果还是产生了频繁的碰撞，会发生什么问题呢？作者注释说，他们使用树来处理频繁的碰撞(we use trees to handle large sets of collisions in bins)，在JEP-180中，描述了这个问题：Improve the performance of java.util.HashMap under high hash-collision conditions by using balanced trees rather than linked lists to store map entries. Implement the same improvement in the LinkedHashMap class. 之前已经提过，在获取HashMap的元素时，基本分两步： 首先根据hashCode()做hash，然后确定bucket的index； 如果bucket的节点的key不是我们需要的，则通过keys.equals()在链中找。 在Java 8之前的实现中是用链表解决冲突的，在产生碰撞的情况下，进行get时，两步的时间复杂度是O(1)+O(n)。因此，当碰撞很厉害的时候n很大，O(n)的速度显然是影响速度的。因此在Java 8中，利用红黑树替换链表，这样复杂度就变成了O(1)+O(logn)了，这样在n很大的时候，能够比较理想的解决这个问题，在Java 8：HashMap的性能提升一文中有性能测试的结果。 RESIZE的实现 当put时，如果发现目前的bucket占用程度已经超过了Load Factor所希望的比例，那么就会发生resize。在resize的过程，简单的说就是把bucket扩充为2倍，之后重新计算index，把节点再放到新的bucket中。resize的注释是这样描述的：Initializes or doubles table size. If null, allocates in accord with initial capacity target held in field threshold. Otherwise, because we are using power-of-two expansion, the elements from each bin must either stay at same index, or move with a power of two offset in the new table.大致意思就是说，当超过限制的时候会resize，然而又因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。怎么理解呢？例如我们从16扩展为32时，具体的变化如下所示： 因此元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 因此，我们在扩充HashMap的时候，不需要重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”。可以看看下图为16扩充为32的resize示意图： 这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。 下面是代码的具体实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了，就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //如果有设置初始容量大小 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults //创建默认capacity = 16的初始容量大小 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的resize上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 总结 我们现在可以回答开始的几个问题，加深对HashMap的理解： 什么时候会使用HashMap？他有什么特点？ 是基于Map接口的实现，存储键值对时，它可以接收null的键值，是非同步的，HashMap存储着Entry(hash, key, value, next)对象。 你知道HashMap的工作原理吗？ 通过hash的方法，通过put和get存储和获取对象。存储对象时，我们将K/V传给put方法时，它调用hashCode计算hash从而得到bucket位置，进一步存储，HashMap会根据当前bucket的占用情况自动调整容量(超过Load Facotr则resize为原来的2倍)。获取对象时，我们将K传给get，它调用hashCode计算hash从而得到bucket位置，并进一步调用equals()方法确定键值对。如果发生碰撞的时候，Hashmap通过链表将产生碰撞冲突的元素组织起来，在Java 8中，如果一个bucket中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，从而提高速度。 你知道get和put的原理吗？equals()和hashCode()的都有什么作用？ 通过对key的hashCode()进行hashing，并计算下标( n-1 &amp; hash)，从而获得buckets的位置。如果产生碰撞，则利用key.equals()方法去链表或树中去查找对应的节点 你知道hash的实现吗？为什么要这样实现？ 在Java 1.8的实现中，是通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在bucket的n比较小的时候，也能保证考虑到高低bit都参与到hash的计算中，同时不会有太大的开销。 如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？ 如果超过了负载因子(默认0.75)，则会重新resize一个原来长度两倍的HashMap，并且重新调用hash方法。 关于Java集合的小抄中是这样描述的： 12345678910111213以Entry[]数组实现的哈希桶数组，用Key的哈希值取模桶数组的大小可得到数组下标。插入元素时，如果两条Key落在同一个桶（比如哈希值1和17取模16后都属于第一个哈希桶），我们称之为哈希冲突。JDK的做法是链表法，Entry用一个next属性实现多个Entry以单向链表存放。查找哈希值为17的key时，先定位到哈希桶，然后链表遍历桶里所有元素，逐个比较其Hash值然后key值。在JDK8里，新增默认为8的阈值，当一个桶里的Entry超过閥值，就不以单向链表而以红黑树来存放以加快Key的查找速度。当然，最好还是桶里只有一个元素，不用去比较。所以默认当Entry数量达到桶数量的75%时，哈希冲突已比较严重，就会成倍扩容桶数组，并重新分配所有原来的Entry。扩容成本不低，所以也最好有个预估值。取模用与操作（hash &amp; （arrayLength-1））会比较快，所以数组的大小永远是2的N次方， 你随便给一个初始值比如17会转为32。默认第一次放入元素时的初始值是16。iterator（）时顺着哈希桶数组来遍历，看起来是个乱序 本文转载自：https://yikun.github.io/2015/04/01/Java-HashMap%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/]]></content>
      <categories>
        <category>Java集合</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot生产环境快速禁用Swagger2]]></title>
    <url>%2F2019%2F05%2F08%2FSpringBoot%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E5%BF%AB%E9%80%9F%E7%A6%81%E7%94%A8Swagger2%2F</url>
    <content type="text"><![CDATA[方法一使用注解@Profile({&quot;dev&quot;,&quot;test&quot;}) 表示在开发或测试环境开启，而在生产关闭。@Profile使用的值是根据spring.profiles.active指定的环境参数，可以参考上一篇博客SpringBoot入门篇之多环境配置文件。 简单介绍下@Profile注解@Profile 注解的作用在不同的场景下，给出不同的类实例。比如在生产环境中给出的 DataSource 实例和测试环境给出的 DataSource 实例是不同的。 @Profile 的使用时，一般是在@Configuration 下使用，标注在类或者方法上，标注的时候填入一个字符串（例如”dev”），作为一个场景,或者一个区分。 实际上，很少通过上面的方式激活 Spring 容器中的 Profile，通常都是让 Spring 容器自动去读取 Profile 的值，然后自动设置。这些实现通常是具体框架实现或者虚拟机参数/环境变量等相关。 方法二使用注解@ConditionalOnProperty(name = &quot;swagger.enable&quot;, havingValue = &quot;true&quot;) 然后在对应的application.properties/application.yml配置文件中添加 swagger.enable = true即可开启，生产环境不填则默认关闭Swagger。 以上两种方法都可以成功根据当前环境禁用swagger2,效果如下： 参考博客：https://cloud.tencent.com/developer/article/1362768https://www.jb51.net/article/153492.htm]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot入门篇之多环境配置文件]]></title>
    <url>%2F2019%2F05%2F08%2FSpringBoot%E5%85%A5%E9%97%A8%E7%AF%87%E4%B9%8B%E5%A4%9A%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[大多数系统都具有2个及以上的环境，测试和生产的最低配置吧。那我们如何在不同环境下使用不同的配置文件？ 使用spring.profiles.active来分区配置spring boot允许你通过命名约定按照一定的格式(application-{profile}.properties)来定义多个配置文件，然后在application.properties通过 spring.profiles.active来具体激活一个或者多个配置文件，如果没有没有指定任何profile的配置文件的话，spring boot默认会启动application-default.properties。 配置文件的优先级application.properties和application.yml文件可以放在一下四个位置： 外置，在相对于应用程序运行目录的/congfig子目录里。 外置，在应用程序运行的目录里 内置，在config包内 内置，在Classpath根目录 这个列表按照优先级排序，也就是说，src/main/resources/config下application.properties覆盖src/main/resources下application.properties中相同的属性，如图：此外，如果你在相同优先级位置同时有application.properties和application.yml，那么application.yml里面的属性就会覆盖application.properties里的属性。 通过命令行设置属性值给不同的环境添加不同的端口属性server.port，然后根据指定不同的spring.profiles.active来切换使用。java -jar xxx.jar –spring.profiles.active=test在命令行运行时，连续的两个减号–就是对application.properties中的属性值进行赋值的标识。所以，java -jar xxx.jar –spring.profiles.active=test 命令，等价于我们在application.properties/application.yml中添加属性spring.profiles.active=test。 参考博客：https://www.toutiao.com/i6392145028591911425/?group_id=6392140402656805122&amp;group_flags=0]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Markdown语法笔记]]></title>
    <url>%2F2019%2F05%2F07%2FMarkdown%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[快速入门MarkDown语法，常用的格式。 标题 1 到 6 个 # ，对应到标题 1 到 6 阶 列表* - + 都可以，格式如下 123* Candy.* Gum.* Booze. 效果： Candy. Gum. Booze. 有序列表1231. Red2. Green3. Blue 效果： Red Green Blue 链接格式：[链接](地址) 效果：博客 图片格式：![](图片地址)效果： 代码格式：使用``进行包围 代码块格式：使用前后各四个`包围 加粗格式：**加粗**效果：加粗 斜体格式：*斜体*效果：斜体 下划线格式：&lt;u&gt;下划线&lt;/u&gt;效果：下划线 水平线格式：* * *效果： 任务格式：* [ ] 任务效果： 任务 表格格式：| 1 | 2 || --- | --- || 3 | 4 |效果: 1 2 3 4]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
  </entry>
</search>
