<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hello,word!">










<meta name="description" content="为什么需要 Redis 集群？性能Redis 本身的 QPS 已经很高了，但是如果在一些并发量非常高的情况下，性能还是会受到影响。这个时候我们希望有更多的 Redis 服务来完成工作。 扩展第二个是出于存储的考虑。因为 Redis 所有的数据都放在内存中，如果数据量大，很容易受到硬件的限制。升级硬件收效和成本比太低，所以我们需要有一种横向扩展的方法。 可用性第三个是可用性和安全的问题。如果只有一个">
<meta property="og:type" content="article">
<meta property="og:title" content="深入理解Redis-集群篇">
<meta property="og:url" content="http://magicj.top/2019/11/25/深入理解Redis-集群篇/index.html">
<meta property="og:site_name" content="技术博客">
<meta property="og:description" content="为什么需要 Redis 集群？性能Redis 本身的 QPS 已经很高了，但是如果在一些并发量非常高的情况下，性能还是会受到影响。这个时候我们希望有更多的 Redis 服务来完成工作。 扩展第二个是出于存储的考虑。因为 Redis 所有的数据都放在内存中，如果数据量大，很容易受到硬件的限制。升级硬件收效和成本比太低，所以我们需要有一种横向扩展的方法。 可用性第三个是可用性和安全的问题。如果只有一个">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://magicj.top/images/20191125/1.png">
<meta property="og:image" content="http://magicj.top/images/20191125/2.png">
<meta property="og:image" content="http://magicj.top/images/20191125/3.png">
<meta property="og:image" content="http://magicj.top/images/20191125/4.png">
<meta property="og:image" content="http://magicj.top/images/20191125/5.png">
<meta property="og:image" content="http://magicj.top/images/20191125/6.png">
<meta property="og:image" content="http://magicj.top/images/20191125/7.png">
<meta property="og:image" content="http://magicj.top/images/20191125/8.png">
<meta property="og:image" content="http://magicj.top/images/20191125/9.png">
<meta property="og:image" content="http://magicj.top/images/20191125/10.png">
<meta property="og:image" content="http://magicj.top/images/20191125/11.png">
<meta property="og:image" content="http://magicj.top/images/20191125/12.png">
<meta property="og:image" content="http://magicj.top/images/20191125/13.png">
<meta property="og:image" content="http://magicj.top/images/20191125/14.png">
<meta property="og:updated_time" content="2019-11-25T14:00:55.780Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深入理解Redis-集群篇">
<meta name="twitter:description" content="为什么需要 Redis 集群？性能Redis 本身的 QPS 已经很高了，但是如果在一些并发量非常高的情况下，性能还是会受到影响。这个时候我们希望有更多的 Redis 服务来完成工作。 扩展第二个是出于存储的考虑。因为 Redis 所有的数据都放在内存中，如果数据量大，很容易受到硬件的限制。升级硬件收效和成本比太低，所以我们需要有一种横向扩展的方法。 可用性第三个是可用性和安全的问题。如果只有一个">
<meta name="twitter:image" content="http://magicj.top/images/20191125/1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://magicj.top/2019/11/25/深入理解Redis-集群篇/">





  <title>深入理解Redis-集群篇 | 技术博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">技术博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://magicj.top/2019/11/25/深入理解Redis-集群篇/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen Jun">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/1.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">深入理解Redis-集群篇</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-25T21:54:57+08:00">
                2019-11-25
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-11-25T22:00:55+08:00">
                2019-11-25
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/" itemprop="url" rel="index">
                    <span itemprop="name">Redis</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/25/深入理解Redis-集群篇/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count gitment-comments-count" data-xid="/2019/11/25/深入理解Redis-集群篇/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 阅读数
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>次
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  6.3k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  24
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="为什么需要-Redis-集群？"><a href="#为什么需要-Redis-集群？" class="headerlink" title="为什么需要 Redis 集群？"></a>为什么需要 Redis 集群？</h2><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p>Redis 本身的 QPS 已经很高了，但是如果在一些并发量非常高的情况下，性能还是会受到影响。这个时候我们希望有更多的 Redis 服务来完成工作。</p>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><p>第二个是出于存储的考虑。因为 Redis 所有的数据都放在内存中，如果数据量大，很容易受到硬件的限制。升级硬件收效和成本比太低，所以我们需要有一种横向扩展的方法。</p>
<h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h3><p>第三个是可用性和安全的问题。如果只有一个 Redis 服务，一旦服务宕机，那么所有的客户端都无法访问，会对业务造成很大的影响。另一个，如果硬件发生故障，而单 机的数据无法恢复的话，带来的影响也是灾难性的。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>可用性、数据安全、性能都可以通过搭建多个 Reids 服务实现。其中有一个是主节点(master)，可以有多个从节点(slave)。主从之间通过数据同步，存储完全相同的数据。如果主节点发生故障，则把某个从节点改成主节点，访问新的主节点。</p>
<h2 id="Redis-主从复制-replication"><a href="#Redis-主从复制-replication" class="headerlink" title="Redis 主从复制(replication)"></a>Redis 主从复制(replication)</h2><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>例如一主多从,203 是主节点，在每个 slave 节点的 redis.conf 配置文件增加一行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">slaveof 192.168.8.203 6379</span><br></pre></td></tr></table></figure>

<p>在主从切换的时候，这个配置会被重写成:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Generated by CONFIG REWRITE</span><br><span class="line">replicaof 192.168.8.203 6379</span><br></pre></td></tr></table></figure>

<p>或者在启动服务时通过参数指定 master 节点:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./redis-server --slaveof 192.168.8.203 6379</span><br></pre></td></tr></table></figure>

<p>或在客户端直接执行 slaveof xx xx，使该 Redis 实例成为从节点。<br>启动后，查看集群状态:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; info replication</span><br></pre></td></tr></table></figure>

<p>从节点不能写入数据(只读)，只能从 master 节点同步数据。get 成功，set 失败。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set test 666</span><br><span class="line">(error) READONLY You can&apos;t write against a read only replica.</span><br></pre></td></tr></table></figure>

<p>主节点写入后，slave 会自动从 master 同步数据。<br>断开主节点:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; slaveof no one</span><br></pre></td></tr></table></figure>

<p>此时从节点会变成自己的主节点，不再复制数据。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><h4 id="连接阶段"><a href="#连接阶段" class="headerlink" title="连接阶段"></a>连接阶段</h4><p>1、slave node 启动时(执行 slaveof 命令)，会在自己本地保存 master node 的信息，包括 master node 的 host 和 ip。<br>2、slave node 内部有个定时任务 replicationCron(源码 replication.c)，每隔 1 秒钟检查是否有新的 master node 要连接和复制，如果发现，就跟 master node 建立 socket 网络接，如果连接成功，从节点为该 socket 建立一个专门处理复制工作的文件 事件处理器，负责后续的复制工作，如接收 RDB 文件、接收命令传播等。<br>当从节点变成了主节点的一个客户端之后，会给主节点发送 ping 请求。</p>
<h4 id="数据同步阶段"><a href="#数据同步阶段" class="headerlink" title="数据同步阶段"></a>数据同步阶段</h4><p>3、master node 第一次执行全量复制，通过 bgsave 命令在本地生成一份 RDB 快照，将 RDB 快照文件发给 slave node(如果超时会重连，可以调大 repl-timeout 的值)。 slave node 首先清除自己的旧数据，然后用 RDB 文件加载数据。</p>
<p><strong>生成 RDB 期间，master 接收到的命令怎么处理?</strong><br>开始生成 RDB 文件时，master 会把所有新的写命令缓存在内存中。在 slave node 保存了 RDB 之后，再将新的写命令复制给 slave node。</p>
<h4 id="命令传播阶段"><a href="#命令传播阶段" class="headerlink" title="命令传播阶段"></a>命令传播阶段</h4><p>4、master node 持续将写命令，异步复制给 slave node<br>延迟是不可避免的，只能通过优化网络。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">repl-disable-tcp-nodelay no</span><br></pre></td></tr></table></figure>

<p>当设置为 yes 时，TCP 会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差;具体发送频率与 Linux 内核的配置有关，默认配置为 40ms。当设置为 no 时，TCP 会立马将主节点的数据发送给从节点，带宽增加但延迟变小。<br>一般来说，只有当应用对 Redis 数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为 yes;多数情况使用默认值 no。<br><strong>如果从节点有一段时间断开了与主节点的连接是不是要重新全量复制一遍? 如果可以增量复制，怎么知道上次复制到哪里?</strong><br>通过 master_repl_offset 记录的偏移量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; info replication</span><br><span class="line">master_repl_offset:7324993</span><br></pre></td></tr></table></figure>

<h3 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h3><p>主从模式解决了数据备份和性能(通过读写分离)的问题，但是还是存在一些不足:</p>
<ol>
<li>RDB 文件过大的情况下，同步非常耗时。</li>
<li>在一主一从或者一主多从的情况下，如果主服务器挂了，对外提供的服务就不可 用了，单点问题没有得到解决。如果每次都是手动把之前的从服务器切换成主服务器， 这个比较费时费力，还会造成一定时间的服务不可用。</li>
</ol>
<h2 id="Sentinel"><a href="#Sentinel" class="headerlink" title="Sentinel"></a>Sentinel</h2><h3 id="Sentinel原理"><a href="#Sentinel原理" class="headerlink" title="Sentinel原理"></a>Sentinel原理</h3><p><strong>如何实现主从的自动切换?我们的思路:</strong><br>创建一台监控服务器来监控所有 Redis 服务节点的状态，比如，master 节点超过一定时间没有给监控服务器发送心跳报文，就把 master 标记为下线，然后把某一个 slave 变成 master。应用每一次都是从这个监控服务器拿到 master 的地址。<br>问题是:如果监控服务器本身出问题了怎么办?那我们就拿不到 master 的地址了，应用也没有办法访问。<br>那我们再创建一个监控服务器，来监控监控服务器……似乎陷入死循环了，这个问题 怎么解决?这个问题先放着。<br>Redis 的 Sentinel 就是这种思路:通过运行监控服务器来保证服务的可用性。<br>从 Redis2.8 版本起，提供了一个稳定版本的 Sentinel(哨兵)，用来解决高可用的问题。它是一个特殊状态的 redis 实例。<br>我们会启动一个或者多个 Sentinel 的服务(通过 src/redis-sentinel)，它本质上只是一个运行在特殊模式之下的 Redis，Sentinel 通过 info 命令得到被监听 Redis 机器的 master，slave 等信息。<br><img src="/images/20191125/1.png" alt><br>为了保证监控服务器的可用性，我们会对 Sentinel 做集群的部署。Sentinel 既监控所有的 Redis 服务，Sentinel 之间也相互监控。<br>注意:Sentinel 本身没有主从之分，只有 Redis 服务节点有主从之分。<br>概念梳理:master，slave(redis group)，sentinel，sentinel 集合</p>
<h4 id="服务下线"><a href="#服务下线" class="headerlink" title="服务下线"></a>服务下线</h4><p>Sentinel 默认以每秒钟 1 次的频率向 Redis 服务节点发送 PING 命令。如果在 down-after-milliseconds 内都没有收到有效回复，Sentinel 会将该服务器标记为下线 (主观下线)。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># sentinel.conf</span><br><span class="line">sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;</span><br></pre></td></tr></table></figure>

<p>这个时候 Sentinel 节点会继续询问其他的 Sentinel 节点，确认这个节点是否下线，如果多数 Sentinel 节点都认为 master 下线，master 才真正确认被下线(客观下线)，这个时候就需要重新选举 master。</p>
<h4 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h4><p>如果 master 被标记为下线，就会开始故障转移流程。<br>既然有这么多的 Sentinel 节点，由谁来做故障转移的事情呢?<br>故障转移流程的第一步就是在 Sentinel 集群选择一个 Leader，由 Leader 完成故障转移流程。Sentinle 通过 Raft 算法，实现 Sentinel 选举。</p>
<h5 id="Ratf-算法"><a href="#Ratf-算法" class="headerlink" title="Ratf 算法"></a>Ratf 算法</h5><p>在分布式存储系统中，通常通过维护多个副本来提高系统的可用性，那么多个节点之间必须要面对数据一致性的问题。Raft 的目的就是通过复制的方式，使所有节点达成一致，但是这么多节点，以哪个节点的数据为准呢?所以必须选出一个 Leader。<br>大体上有两个步骤:领导选举，数据复制。<br>Raft 是一个共识算法(consensus algorithm)。比如比特币之类的加密货币，就 需要共识算法。Spring Cloud 的注册中心解决方案 Consul 也用到了 Raft 协议。<br><strong>Raft 的核心思想:先到先得，少数服从多数。</strong><br>Raft 算法演示:<br><a href="http://thesecretlivesofdata.com/raft/" target="_blank" rel="noopener">http://thesecretlivesofdata.com/raft/</a><br>Sentinle 的 Raft 算法和 Raft 论文略有不同。</p>
<ol>
<li>master 客观下线触发选举，而不是过了 election timeout 时间开始选举。 </li>
<li>Leader 并不会把自己成为 Leader 的消息发给其他 Sentinel。其他 Sentinel 等待 Leader 从 slave 选出 master 后，检测到新的 master 正常工作后，就会去掉客观下线的标识，从而不需要进入故障转移流程。</li>
</ol>
<p><strong>问题:怎么让一个原来的 slave 节点成为主节点?</strong></p>
<ol>
<li>选出 Sentinel Leader 之后，由 Sentinel Leader 向某个节点发送 slaveof no one 命令，让它成为独立节点。</li>
<li>然后向其他节点发送 slaveof x.x.x.x xxxx(本机服务)，让它们成为这个节点的子节点，故障转移完成。</li>
</ol>
<p><strong>问题:这么多从节点，选谁成为主节点?</strong><br>关于从节点选举，一共有四个因素影响选举的结果，分别是断开连接时长、优先级 排序、复制数量、进程id。<br>如果与哨兵连接断开的比较久，超过了某个阈值，就直接失去了选举权。如果拥有选举权，那就看谁的优先级高，这个在配置文件里可以设置(replica-priority 100)， 数值越小优先级越高。<br>如果优先级相同，就看谁从 master 中复制的数据最多(复制偏移量最大)，选最多的那个，如果复制数量也相同，就选择进程 id 最小的那个。</p>
<h3 id="功能总结"><a href="#功能总结" class="headerlink" title="功能总结"></a>功能总结</h3><ol>
<li>监控:Sentinel 会不断检查主服务器和从服务器是否正常运行。</li>
<li>通知:如果某一个被监控的实例出现问题，Sentinel 可以通过 API 发出通知。</li>
<li>自动故障转移(failover):如果主服务器发生故障，Sentinel 可以启动故障转移过程。把某台服务器升级为主服务器，并发出通知。</li>
<li>配置管理:客户端连接到 Sentinel，获取当前的 Redis 主服务器的地址。</li>
</ol>
<h3 id="Sentinel实战"><a href="#Sentinel实战" class="headerlink" title="Sentinel实战"></a>Sentinel实战</h3><h4 id="Sentinel-配置"><a href="#Sentinel-配置" class="headerlink" title="Sentinel 配置"></a>Sentinel 配置</h4><p>为了保证 Sentinel 的高可用，Sentinel 也需要做集群部署，集群中至少需要三个 Sentinel 实例(推荐奇数个，防止脑裂)。</p>
<table>
<thead>
<tr>
<th>hostname</th>
<th>IP 地址</th>
<th>节点角色&amp;端口</th>
</tr>
</thead>
<tbody><tr>
<td>master</td>
<td>192.168.8.203</td>
<td>Master:6379 / Sentinel : 26379</td>
</tr>
<tr>
<td>slave1</td>
<td>192.168.8.204</td>
<td>Slave :6379 / Sentinel : 26379</td>
</tr>
<tr>
<td>Slave2</td>
<td>192.168.8.205</td>
<td>Slave :6379 / Sentinel : 26379</td>
</tr>
</tbody></table>
<p>以 Redis 安装路径/usr/local/soft/redis-5.0.5/为例。 在 204 和 205 的 src/redis.conf 配置文件中添加</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">slaveof 192.168.8.203 6379</span><br></pre></td></tr></table></figure>

<p>在203、204、205 创建 sentinel 配置文件( 安装后根目录下默认有 sentinel.conf ):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/soft/redis-5.0.5 mkdir logs</span><br><span class="line">mkdir rdbs</span><br><span class="line">mkdir sentinel-tmp</span><br><span class="line">vim sentinel.conf</span><br></pre></td></tr></table></figure>

<p>三台服务器内容相同:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">daemonize yes</span><br><span class="line">port 26379</span><br><span class="line">protected-mode no</span><br><span class="line">dir &quot;/usr/local/soft/redis-5.0.5/sentinel-tmp&quot;</span><br><span class="line">sentinel monitor redis-master 192.168.8.203 6379 2 sentinel down-after-milliseconds redis-master 30000 sentinel failover-timeout redis-master 180000 sentinel parallel-syncs redis-master 1</span><br></pre></td></tr></table></figure>

<p>上面出现了 4 个’redis-master’，这个名称要统一，并且使用客户端(比如 Jedis) 连接的时候名称要正确。</p>
<table>
<thead>
<tr>
<th>hostname</th>
<th>IP 地址</th>
</tr>
</thead>
<tbody><tr>
<td>protected-mode</td>
<td>是否允许外部网络访问</td>
</tr>
<tr>
<td>dir</td>
<td>sentinel 的工作目录</td>
</tr>
<tr>
<td>sentinel monitor</td>
<td>sentinel 监控的 redis 主节点</td>
</tr>
<tr>
<td>down-after-milliseconds(毫秒)</td>
<td>master 宕机多久，才会被 Sentinel 主观认为下线</td>
</tr>
<tr>
<td>sentinel failover-timeout(毫秒)</td>
<td>1 同一个 sentinel 对同一个 master 两次 failover 之间的间隔时间。<br>2. 当一个 slave 从一个错误的 master 那里同步数据开始计算时间。直到 slave 被纠正为向正确的 master 那里同步数据时。<br>3.当想要取消一个正在进行的 failover 所需要的时间。<br>4.当进行 failover 时，配置所有 slaves 指向新的 master 所需的最大时间。</td>
</tr>
<tr>
<td>parallel-syncs</td>
<td>这个配置项指定了在发生 failover 主备切换时最多可以有多少个 slave 同 时对新的 master 进行 同步，这个数字越小，完成 failover 所需的时间就 越长，但是如果这个数字越大，就意味着越 多的 slave 因为 replication 而 不可用。可以通过将这个值设为 1 来保证每次只有一个 slave 处于不能处 理命令请求的状态。</td>
</tr>
<tr>
<td>#### Sentinel 验证</td>
<td></td>
</tr>
<tr>
<td>启动 Redis 服务和 Sentinel</td>
<td></td>
</tr>
<tr>
<td><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/soft/redis-5.0.5/src </span><br><span class="line"># 启动 Redis 节点 </span><br><span class="line">./redis-server ../redis.conf</span><br><span class="line"># 启动 Sentinel 节点 </span><br><span class="line">./redis-sentinel ../sentinel.conf </span><br><span class="line"># 或者</span><br><span class="line">./redis-server ../sentinel.conf --sentinel</span><br></pre></td></tr></table></figure></td>
<td></td>
</tr>
</tbody></table>
<p>查看集群状态:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; info replication</span><br></pre></td></tr></table></figure>

<p>模拟 master 宕机，在 203 执行:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; shutdown</span><br></pre></td></tr></table></figure>

<p>205 被选为新的 Master，只有一个 Slave 节点。<br><img src="/images/20191125/2.png" alt><br>注意看 sentinel.conf 里面的 redis-master 被修改了!
模拟原 master 恢复，在 203 启动 redis-server。它还是 slave，但是 master 又有 两个 slave 了。</p>
<h4 id="Sentinel-连接使用"><a href="#Sentinel-连接使用" class="headerlink" title="Sentinel 连接使用"></a>Sentinel 连接使用</h4><p>Jedis 连接 Sentinel， 来自于 sentinel.conf 的配置。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">private static JedisSentinelPool createJedisPool() &#123;</span><br><span class="line">    String masterName = &quot;redis-master&quot;;</span><br><span class="line">    Set&lt;String&gt; sentinels = new HashSet&lt;String&gt;();                    </span><br><span class="line">    sentinels.add(&quot;192.168.8.203:26379&quot;); </span><br><span class="line">    sentinels.add(&quot;192.168.8.204:26379&quot;); </span><br><span class="line">    sentinels.add(&quot;192.168.8.205:26379&quot;);</span><br><span class="line">    pool = new JedisSentinelPool(masterName, sentinels);</span><br><span class="line">    return pool; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Spring Boot 连接 Sentinel</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spring.redis.sentinel.master=redis-master spring.redis.sentinel.nodes=192.168.8.203:26379,192.168.8.204:26379,192.168.8.205:26379</span><br></pre></td></tr></table></figure>

<p>无论是 Jedis 还是 Spring Boot(2.x 版本默认是 Lettuce)，都只需要配置全部哨 兵的地址，由哨兵返回当前的 master 节点地址。</p>
<h3 id="哨兵机制的不足"><a href="#哨兵机制的不足" class="headerlink" title="哨兵机制的不足"></a>哨兵机制的不足</h3><ul>
<li>主从切换的过程中会丢失数据，因为只有一个 master。 </li>
<li>只能单点写，没有解决水平扩容的问题。 </li>
<li>如果数据量非常大，这个时候我们需要多个 master-slave 的 group，把数据分布到不同的 group 中。</li>
</ul>
<h2 id="Redis-分布式方案"><a href="#Redis-分布式方案" class="headerlink" title="Redis 分布式方案"></a>Redis 分布式方案</h2><p>如果要实现 Redis 数据的分片，我们有三种方案。<br>第一种是在客户端实现相关的逻辑，例如用取模或者一致性哈希对 key 进行分片，查询和修改都先判断 key 的路由。<br>第二种是把做分片处理的逻辑抽取出来，运行一个独立的代理服务，客户端连接到这个代理服务，代理服务做请求的转发。<br>第三种就是基于服务端实现。</p>
<h3 id="客户端-Sharding"><a href="#客户端-Sharding" class="headerlink" title="客户端 Sharding"></a>客户端 Sharding</h3><p>Jedis 客户端提供了 Redis Sharding 的方案，并且支持连接池。<br><img src="/images/20191125/3.png" alt></p>
<h4 id="ShardedJedis"><a href="#ShardedJedis" class="headerlink" title="ShardedJedis"></a>ShardedJedis</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public class ShardingTest &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        JedisPoolConfig poolConfig = new JedisPoolConfig(); ​</span><br><span class="line">        // Redis 服务器</span><br><span class="line">        JedisShardInfo shardInfo1 = new JedisShardInfo(&quot;127.0.0.1&quot;, 6379);</span><br><span class="line">        JedisShardInfo shardInfo2 = new JedisShardInfo(&quot;192.168.8.205&quot;, 6379);</span><br><span class="line">​</span><br><span class="line">        // 连接池</span><br><span class="line">        List&lt;JedisShardInfo&gt; infoList = Arrays.asList(shardInfo1, shardInfo2);</span><br><span class="line">        ShardedJedisPool jedisPool = new ShardedJedisPool(poolConfig, infoList);</span><br><span class="line">        ShardedJedis jedis = null;</span><br><span class="line">        try &#123;</span><br><span class="line">            jedis = jedisPool.getResource();</span><br><span class="line">            for (int i = 0; i &lt; 100; i++) &#123;</span><br><span class="line">                jedis.set(&quot;k&quot; + i, &quot;&quot; + i);</span><br><span class="line">            &#125;</span><br><span class="line">            for (int i = 0; i &lt; 100; i++) &#123;</span><br><span class="line">                System.out.println(jedis.get(&quot;k&quot; + i));</span><br><span class="line">            &#125; ​</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            if (jedis != null) &#123;</span><br><span class="line">                jedis.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用 ShardedJedis 之类的客户端分片代码的优势是配置简单，不依赖于其他中间件，分区的逻辑可以自定义，比较灵活。但是基于客户端的方案，不能实现动态的服务增减，每个客户端需要自行维护分片策略，存在重复代码。</p>
<h3 id="代理-Proxy"><a href="#代理-Proxy" class="headerlink" title="代理 Proxy"></a>代理 Proxy</h3><p>第二种思路就是把分片的代码抽取出来，做成一个公共服务，所有的客户端都连接 到这个代理层。由代理层来实现请求和转发。<br><img src="/images/20191125/4.png" alt><br>典型的代理分区方案有 Twitter 开源的 Twemproxy 和国内的豌豆荚开源的 Codis。</p>
<h4 id="Twemproxy"><a href="#Twemproxy" class="headerlink" title="Twemproxy"></a>Twemproxy</h4><p>two-em-proxy：<br><a href="https://github.com/twitter/twemproxy" target="_blank" rel="noopener">https://github.com/twitter/twemproxy</a><br><img src="/images/20191125/5.png" alt><br>Twemproxy 的优点:比较稳定，可用性高。<br>不足:<br>1、出现故障不能自动转移，架构复杂，需要借助其他组件(LVS/HAProxy + Keepalived)实现 HA<br>2、扩缩容需要修改配置，不能实现平滑地扩缩容(需要重新分布数据)。</p>
<h4 id="Codis"><a href="#Codis" class="headerlink" title="Codis"></a>Codis</h4><p><a href="https://github.com/CodisLabs/codis" target="_blank" rel="noopener">https://github.com/CodisLabs/codis</a><br>Codis 是一个代理中间件，用 Go 语言开发的。<br>功能:客户端连接 Codis 跟连接 Redis 没有区别。</p>
<table>
<thead>
<tr>
<th></th>
<th>Codis</th>
<th>Twemproxy</th>
<th>Redis Cluster</th>
</tr>
</thead>
<tbody><tr>
<td>重新分片不需要重启</td>
<td>Yes</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>pipeline</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td>多 key 操作的 hash tags {}</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>重新分片时的多 key 操作</td>
<td>Yes</td>
<td>-</td>
<td>No</td>
</tr>
<tr>
<td>客户端支持</td>
<td>所有</td>
<td>所有</td>
<td>支持 cluster 协议的客户 端</td>
</tr>
</tbody></table>
<p><img src="/images/20191125/6.png" alt><br>分片原理:Codis 把所有的 key 分成了 N 个槽(例如 1024)，每个槽对应一个分组， 一个分组对应于一个或者一组 Redis 实例。Codis 对 key 进行 CRC32 运算，得到一个 32 位的数字，然后模以 N(槽的个数)，得到余数，这个就是 key 对应的槽，槽后面就 是 Redis 的实例。比如 4 个槽:<br><img src="/images/20191125/7.png" alt><br>Codis 的槽位映射关系是保存在 Proxy 中的，如果要解决单点的问题，Codis 也要做集群部署，多个Codis节点怎么同步槽和实例的关系呢?需要运行一个Zookeepe(r 或者 etcd/本地文件)。<br>在新增节点的时候，可以为节点指定特定的槽位。Codis 也提供了自动均衡策略。<br>Codis 不支持事务，其他的一些命令也不支持。<br>不支持的命令<br><a href="https://github.com/CodisLabs/codis/blob/release3.2/doc/unsupported_cmds.md" target="_blank" rel="noopener">https://github.com/CodisLabs/codis/blob/release3.2/doc/unsupported_cmds.md</a><br>获取数据原理(mget):在 Redis 中的各个实例里获取到符合的 key，然后再汇总 到 Codis 中。<br>Codis 是第三方提供的分布式解决方案，在官方的集群功能稳定之前，Codis 也得到 了大量的应用。</p>
<h4 id="Redis-Cluster"><a href="#Redis-Cluster" class="headerlink" title="Redis Cluster"></a>Redis Cluster</h4><p><a href="https://redis.io/topics/cluster-tutorial/" target="_blank" rel="noopener">https://redis.io/topics/cluster-tutorial/</a><br>Redis Cluster 是在 Redis 3.0 的版本正式推出的，用来解决分布式的需求，同时也 可以实现高可用。跟 Codis 不一样，它是去中心化的，客户端可以连接到任意一个可用节点。<br>数据分片有几个关键的问题需要解决: </p>
<ol>
<li>数据怎么相对均匀地分片 </li>
<li>客户端怎么访问到相应的节点和数据 </li>
<li>重新分片的过程，怎么保证正常服务<h5 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h5>Redis Cluster 可以看成是由多个 Redis 实例组成的数据集合。客户端不需要关注数据的子集到底存储在哪个节点，只需要关注这个集合整体。<br>以 3 主 3 从为例，节点之间两两交互，共享数据分片、节点状态等信息。<h5 id="数据分布"><a href="#数据分布" class="headerlink" title="数据分布"></a>数据分布</h5>如果是希望数据分布相对均匀的话，我们首先可以考虑哈希后取模。<h6 id="哈希后取模"><a href="#哈希后取模" class="headerlink" title="哈希后取模"></a>哈希后取模</h6>例如，hash(key)%N，根据余数，决定映射到那一个节点。这种方式比较简单，属于静态的分片规则。但是一旦节点数量变化，新增或者减少，由于取模的 N 发生变化，数据需要重新分布。<br>为了解决这个问题，我们又有了一致性哈希算法。<h6 id="一致性哈希"><a href="#一致性哈希" class="headerlink" title="一致性哈希"></a>一致性哈希</h6>一致性哈希的原理:<br>把所有的哈希值空间组织成一个虚拟的圆环(哈希环)，整个空间按顺时针方向组 织。因为是环形空间，0 和 2^32-1 是重叠的。<br>假设我们有四台机器要哈希环来实现映射(分布数据)，我们先根据机器的名称或 者 IP 计算哈希值，然后分布到哈希环中(红色圆圈)。<br><img src="/images/20191125/8.png" alt><br>现在有 4 条数据或者 4 个访问请求，对 key 计算后，得到哈希环中的位置(绿色圆圈)。沿哈希环顺时针找到的第一个 Node，就是数据存储的节点。<br><img src="/images/20191125/9.png" alt><br>在这种情况下，新增了一个 Node5 节点，不影响数据的分布。<br><img src="/images/20191125/10.png" alt><br>删除了一个节点 Node4，只影响相邻的一个节点。<br><img src="/images/20191125/11.png" alt><br>谷歌的 MurmurHash 就是一致性哈希算法。在分布式系统中，负载均衡、分库分表 等场景中都有应用。<br>一致性哈希解决了动态增减节点时，所有数据都需要重新分布的问题，它只会影响到下一个相邻的节点，对其他节点没有影响。<br>但是这样的一致性哈希算法有一个缺点，因为节点不一定是均匀地分布的，特别是在节点数比较少的情况下，所以数据不能得到均匀分布。解决这个问题的办法是引入虚 拟节点(Virtual Node)。<br>比如:2 个节点，5 条数据，只有 1 条分布到 Node2，4 条分布到 Node1，不均匀。<br><img src="/images/20191125/12.png" alt><br>Node1 设置了两个虚拟节点，Node2 也设置了两个虚拟节点(虚线圆圈)。 这时候有 3 条数据分布到 Node1，1 条数据分布到 Node2。<br><img src="/images/20191125/13.png" alt><h6 id="Redis-虚拟槽分区"><a href="#Redis-虚拟槽分区" class="headerlink" title="Redis 虚拟槽分区"></a>Redis 虚拟槽分区</h6>Redis 既没有用哈希取模，也没有用一致性哈希，而是用虚拟槽来实现的。<br>Redis 创建了 16384 个槽(slot)，每个节点负责一定区间的 slot。比如 Node1 负责 0-5460，Node2 负责 5461-10922，Node3 负责 10923-16383。<br><img src="/images/20191125/14.png" alt><br>Redis 的每个 master 节点维护一个 16384 位(2048bytes=2KB)的位序列，比如:<br>序列的第 0 位是 1，代表第一个 slot 是它负责;序列的第 1 位是 0，代表第二个 slot 不归它负责。<br>对象分布到 Redis 节点上时，对 key 用 CRC16 算法计算再%16384，得到一个 slot 的值，数据落到负责这个 slot 的 Redis 节点上。<br>查看 key 属于哪个 slot:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; cluster keyslot test</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>注意:key 与 slot 的关系是永远不会变的，会变的只有 slot 和 Redis 节点的关系。<br><strong>问题:怎么让相关的数据落到同一个节点上?</strong><br>比如有些 multi key 操作是不能跨节点的，如果要让某些数据分布到一个节点上，例 如用户 2673 的基本信息和金融信息，怎么办?<br>在 key 里面加入{hash tag}即可。Redis 在计算槽编号的时候只会获取{}之间的字符 串进行槽编号计算，这样由于上面两个不同的键，{}里面的字符串是相同的，因此他们可 以被计算出相同的槽。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set user&#123;2673&#125;base ... </span><br><span class="line">set user&#123;2673&#125;fin ...</span><br></pre></td></tr></table></figure>

<p><strong>问题:客户端连接到哪一台服务器?访问的数据不在当前节点上，怎么办?</strong><br>比如在 7291 端口的 Redis 的 redis-cli 客户端操作:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:7291&gt; set ts 1</span><br><span class="line">(error) MOVED 13724 127.0.0.1:7293</span><br></pre></td></tr></table></figure>

<p>服务端返回 MOVED，也就是根据 key 计算出来的 slot 不归 7191 端口管理，而是 归 7293 端口管理，服务端返回 MOVED 告诉客户端去 7293 端口操作。<br>这个时候更换端口，用 redis-cli –p 7293 操作，才会返回 OK。或者用./redis-cli -c -p port 的命令(c 代表 cluster)。这样客户端需要连接两次。<br>Jedis 等客户端会在本地维护一份 slot——node 的映射关系，大部分时候不需要重 定向，所以叫做 smart jedis(需要客户端支持)。</p>
<h5 id="数据迁移"><a href="#数据迁移" class="headerlink" title="数据迁移"></a>数据迁移</h5><p>因为 key 和 slot 的关系是永远不会变的，当新增了节点的时候，需要把原有的 slot 分配给新的节点负责，并且把相关的数据迁移过来。<br>添加新节点(新增一个 7297):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster add-node 127.0.0.1:7291 127.0.0.1:7297</span><br></pre></td></tr></table></figure>

<p>新增的节点没有哈希槽，不能分布数据，在原来的任意一个节点上执行:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster reshard 127.0.0.1:7291</span><br></pre></td></tr></table></figure>

<p>输入需要分配的哈希槽的数量(比如 500)，和哈希槽的来源节点(可以输入 all 或者 id)。</p>
<h5 id="高可用和主从切换原理"><a href="#高可用和主从切换原理" class="headerlink" title="高可用和主从切换原理"></a>高可用和主从切换原理</h5><p>当 slave 发现自己的 master 变为 FAIL 状态时，便尝试进行 Failover，以期成为新 的 master。由于挂掉的 master 可能会有多个 slave，从而存在多个 slave 竞争成为 master 节点的过程， 其过程如下:</p>
<ol>
<li>slave 发现自己的 master 变为 FAIL</li>
<li>将自己记录的集群 currentEpoch 加 1，并广播 FAILOVER_AUTH_REQUEST 信息 </li>
<li>其他节点收到该信息，只有 master 响应，判断请求者的合法性，并发送 FAILOVER_AUTH_ACK，对每一个 epoch 只发送一次 ack </li>
<li>尝试 failover 的 slave 收集 FAILOVER_AUTH_ACK </li>
<li>超过半数后变成新 Master</li>
<li>广播 Pong 通知其他集群节点。</li>
</ol>
<p>Redis Cluster 既能够实现主从的角色分配，又能够实现主从切换，相当于集成了 Replication 和 Sentinal 的功能。</p>
<h5 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h5><p>优势</p>
<ol>
<li>无中心架构。</li>
<li>数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布。 </li>
<li>可扩展性，可线性扩展到 1000 个节点(官方推荐不超过 1000 个)，节点可动态添加或删除。</li>
<li>高可用性，部分节点不可用时，集群仍可用。通过增加 Slave 做 standby 数据副本，能够实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制 完成 Slave 到 Master 的角色提升。</li>
<li>降低运维成本，提高系统的扩展性和可用性。</li>
</ol>
<p>不足</p>
<ol>
<li>Client 实现复杂，驱动要求实现 Smart Client，缓存 slots mapping 信息并及时 更新，提高了开发难度，客户端的不成熟影响业务的稳定性。</li>
<li>节点会因为某些原因发生阻塞(阻塞时间大于 clutser-node-timeout)，被判断下线，这种 failover 是没有必要的。</li>
<li>数据通过异步复制，不保证数据的强一致性。</li>
<li>多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现相互影响的情况。</li>
</ol>

      
    </div>
    
    
    
    
    

    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    Chen Jun
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://magicj.top/2019/11/25/深入理解Redis-集群篇/" title="深入理解Redis-集群篇">http://magicj.top/2019/11/25/深入理解Redis-集群篇/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      

      
      
        <div class="post-widgets">
        

        

        
          
          <div id="needsharebutton-postbottom">
            <span class="btn">
              <i class="fa fa-share-alt" aria-hidden="true"></i>
            </span>
          </div>
        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/11/19/深入理解Redis-进阶篇/" rel="next" title="深入理解Redis-进阶篇">
                <i class="fa fa-chevron-left"></i> 深入理解Redis-进阶篇
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      
        <div id="gitment-container"></div>
      
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/1.png" alt="Chen Jun">
            
              <p class="site-author-name" itemprop="name">Chen Jun</p>
              <p class="site-description motion-element" itemprop="description">行走在Java边缘，写点自己的博客技术文。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">22</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/magicCJ" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:13599462529@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://blog.csdn.net/baidu_38083619" target="_blank" title="CSDN">
                      
                        <i class="fa fa-fw fa-globe"></i>CSDN</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#为什么需要-Redis-集群？"><span class="nav-number">1.</span> <span class="nav-text">为什么需要 Redis 集群？</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#性能"><span class="nav-number">1.1.</span> <span class="nav-text">性能</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#扩展"><span class="nav-number">1.2.</span> <span class="nav-text">扩展</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#可用性"><span class="nav-number">1.3.</span> <span class="nav-text">可用性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#总结"><span class="nav-number">1.4.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis-主从复制-replication"><span class="nav-number">2.</span> <span class="nav-text">Redis 主从复制(replication)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#配置"><span class="nav-number">2.1.</span> <span class="nav-text">配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#原理"><span class="nav-number">2.2.</span> <span class="nav-text">原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#连接阶段"><span class="nav-number">2.2.1.</span> <span class="nav-text">连接阶段</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数据同步阶段"><span class="nav-number">2.2.2.</span> <span class="nav-text">数据同步阶段</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#命令传播阶段"><span class="nav-number">2.2.3.</span> <span class="nav-text">命令传播阶段</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#不足"><span class="nav-number">2.3.</span> <span class="nav-text">不足</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sentinel"><span class="nav-number">3.</span> <span class="nav-text">Sentinel</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Sentinel原理"><span class="nav-number">3.1.</span> <span class="nav-text">Sentinel原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#服务下线"><span class="nav-number">3.1.1.</span> <span class="nav-text">服务下线</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#故障转移"><span class="nav-number">3.1.2.</span> <span class="nav-text">故障转移</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Ratf-算法"><span class="nav-number">3.1.2.1.</span> <span class="nav-text">Ratf 算法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#功能总结"><span class="nav-number">3.2.</span> <span class="nav-text">功能总结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sentinel实战"><span class="nav-number">3.3.</span> <span class="nav-text">Sentinel实战</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Sentinel-配置"><span class="nav-number">3.3.1.</span> <span class="nav-text">Sentinel 配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sentinel-连接使用"><span class="nav-number">3.3.2.</span> <span class="nav-text">Sentinel 连接使用</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#哨兵机制的不足"><span class="nav-number">3.4.</span> <span class="nav-text">哨兵机制的不足</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis-分布式方案"><span class="nav-number">4.</span> <span class="nav-text">Redis 分布式方案</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#客户端-Sharding"><span class="nav-number">4.1.</span> <span class="nav-text">客户端 Sharding</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ShardedJedis"><span class="nav-number">4.1.1.</span> <span class="nav-text">ShardedJedis</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#代理-Proxy"><span class="nav-number">4.2.</span> <span class="nav-text">代理 Proxy</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Twemproxy"><span class="nav-number">4.2.1.</span> <span class="nav-text">Twemproxy</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Codis"><span class="nav-number">4.2.2.</span> <span class="nav-text">Codis</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Redis-Cluster"><span class="nav-number">4.2.3.</span> <span class="nav-text">Redis Cluster</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#架构"><span class="nav-number">4.2.3.1.</span> <span class="nav-text">架构</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#数据分布"><span class="nav-number">4.2.3.2.</span> <span class="nav-text">数据分布</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#哈希后取模"><span class="nav-number">4.2.3.2.1.</span> <span class="nav-text">哈希后取模</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#一致性哈希"><span class="nav-number">4.2.3.2.2.</span> <span class="nav-text">一致性哈希</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Redis-虚拟槽分区"><span class="nav-number">4.2.3.2.3.</span> <span class="nav-text">Redis 虚拟槽分区</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#数据迁移"><span class="nav-number">4.2.3.3.</span> <span class="nav-text">数据迁移</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#高可用和主从切换原理"><span class="nav-number">4.2.3.4.</span> <span class="nav-text">高可用和主从切换原理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#总结-1"><span class="nav-number">4.2.3.5.</span> <span class="nav-text">总结</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chen Jun</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">59.1k</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  







<!-- LOCAL: You can save these files to your site and update links -->
    
        
        <link rel="stylesheet" href="http://cjblog-test.oss-cn-hangzhou.aliyuncs.com/blog/gitmint-default.css">
        <script src="http://cjblog-test.oss-cn-hangzhou.aliyuncs.com/blog/gitmint.browser.js"></script>
    
<!-- END LOCAL -->

    

    
      <script type="text/javascript">
      function renderGitment(){
        var gitment = new Gitmint({
            id: decodeURI(window.location.pathname), 
            owner: 'magicCJ',
            repo: 'magicCJ.github.io',
            
            lang: "" || navigator.language || navigator.systemLanguage || navigator.userLanguage,
            
            oauth: {
            
            
                client_secret: '99d7314e336092874e2fef5a888602f1a59860e0',
            
                client_id: 'dbb9d7e720b6135ad997'
            }});
        gitment.render('gitment-container');
      }

      
      renderGitment();
      
      </script>
    







  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
      pbOptions = {};
      
          pbOptions.iconStyle = "box";
      
          pbOptions.boxForm = "horizontal";
      
          pbOptions.position = "bottomCenter";
      
          pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
    
    
  </script>

  

  

  

  

</body>
</html>
